{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "864cc267",
      "metadata": {
        "id": "864cc267"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FYbS3JGQJo8",
        "outputId": "3239d82a-1f24-4ee1-bd8a-567ed76b69ed"
      },
      "id": "8FYbS3JGQJo8",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/New_Alteration_zones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "soIrvbCNQOC0",
        "outputId": "27758e29-c10a-41fc-aa66-bef061ca8b00"
      },
      "id": "soIrvbCNQOC0",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/New_Alteration_zones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contextily\n",
        "!pip install pyrsgis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TZ8js3PQYxV",
        "outputId": "40e26f03-537b-49cc-877b-0597b7f163cd"
      },
      "id": "_TZ8js3PQYxV",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contextily\n",
            "  Downloading contextily-1.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from contextily) (7.1.2)\n",
            "Collecting xyzservices\n",
            "  Downloading xyzservices-2022.9.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from contextily) (3.2.2)\n",
            "Collecting mercantile\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from contextily) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from contextily) (1.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from contextily) (2.23.0)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->contextily) (1.52)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (3.0.9)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->contextily) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->contextily) (1.15.0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.7/dist-packages (from mercantile->contextily) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (57.4.0)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (2022.9.24)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (22.1.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (3.0.4)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, xyzservices, rasterio, mercantile, contextily\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 contextily-1.2.0 mercantile-1.2.1 rasterio-1.2.10 snuggs-1.4.7 xyzservices-2022.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyrsgis\n",
            "  Downloading pyrsgis-0.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyrsgis\n",
            "Successfully installed pyrsgis-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0e0c0e57",
      "metadata": {
        "id": "0e0c0e57"
      },
      "outputs": [],
      "source": [
        "import contextily as cx\n",
        "from ipywidgets import interact\n",
        "from math import floor\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.convert import array_to_table\n",
        "from pyrsgis.ml import imageChipsFromArray\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3255c2ce",
      "metadata": {
        "id": "3255c2ce"
      },
      "source": [
        "### Training the model using MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd train_Landsat9/MLP_Landsat9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rf77jFGvQk2y",
        "outputId": "3875807c-d80f-4535-f1b9-109dd5e30f9d"
      },
      "id": "Rf77jFGvQk2y",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/New_Alteration_zones/train_Landsat9/MLP_Landsat9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "train_x = load('train_x.npy')\n",
        "test_x = load('train_y.npy')\n",
        "train_y = load('test_x.npy')\n",
        "test_y = load('test_y.npy')\n",
        "train_y = pd.get_dummies(train_y, drop_first=False).values\n",
        "test_y = pd.get_dummies(test_y, drop_first=False).values"
      ],
      "metadata": {
        "id": "UnnmkuO5Qkzy"
      },
      "id": "UnnmkuO5Qkzy",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric(history, metric):    #For plotting any graph relating to any model\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()\n",
        "\n",
        "def plot_avg_AUC_ROC(y_pred, test_y, n_classes, label_names, figsize=(6.4, 4.8), average=\"macro\"):\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "\n",
        "  #y_pred = model.predict(test_x, batch_size=64, verbose=1)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  \n",
        "  for i in range(n_classes):\n",
        "    #fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i].astype(int) ,y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "      # roc for each class\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.set_xlim([0.0, 1.0])\n",
        "  ax.set_ylim([0.0, 1.05])\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive Rate')\n",
        "  ax.set_title('Receiver operating characteristic example')\n",
        "  for i in range(n_classes):\n",
        "      ax.plot(fpr[i], tpr[i], label='ROC curve (area = {}) for {}'.format('{0:.2f}'.format(roc_auc[i]), label_names[i]))\n",
        "  ax.legend(loc=\"best\")\n",
        "  ax.grid(alpha=.4)\n",
        "  sns.despine()\n",
        "  plt.show()\n",
        "\n",
        "def roc(model, test_x, test_y, n_classes):\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  roc_auc = {}\n",
        "\n",
        "  y_pred = model.predict(test_x, batch_size=64, verbose=1)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  prediction = pd.get_dummies(y_pred.argmax(axis = 1),drop_first=False).values\n",
        "  print(n_classes)\n",
        "  for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "  return roc_auc\n",
        "\n"
      ],
      "metadata": {
        "id": "PjdTIKbKQkxF"
      },
      "id": "PjdTIKbKQkxF",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "############## ORiginal Model Code ###################\n",
        "def MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y):\n",
        "  best_accuracy = 0\n",
        "  best_model = tf.keras.models.Sequential()\n",
        "  best_history = None\n",
        "\n",
        "  columns = ['Accuracy', 'precision', 'recall', 'F1_score', \"AUC_0\", \"AUC_1\", \"AUC_2\", \"Aggregate_AUC\"]\n",
        "  df = pd.DataFrame(columns = columns)\n",
        "\n",
        "  for i in range(experimental_runs):\n",
        "    #Model_name = \"CNN_RMSPROP\"\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(7, activation='selu', input_shape=(train_x.shape[1], )))\n",
        "    model.add(tf.keras.layers.Dense(5, activation='selu'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    print(model.summary())\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimiser_type, metrics=['accuracy'])\n",
        "    history = model.fit(train_x, train_y, epochs = 80, validation_data = (test_x, test_y))\n",
        "\n",
        "    sum_y_pred = 0\n",
        "    # predict for the test dataset\n",
        "    yTestPredicted = model.predict(test_x)\n",
        "    sum_y_pred = sum_y_pred + yTestPredicted\n",
        "    # calculate and display error metrics\n",
        "    yTestPredicted_ = yTestPredicted.argmax(axis=1)\n",
        "\n",
        "    n_classes = 3\n",
        "    test_y_dummies = test_y.argmax(axis = 1)\n",
        "    Accuracy = accuracy_score(test_y_dummies, yTestPredicted_)\n",
        "    cMatrix = confusion_matrix(test_y_dummies, yTestPredicted_)\n",
        "    pScore = precision_score(test_y_dummies, yTestPredicted_, average='macro')\n",
        "    rScore = recall_score(test_y_dummies, yTestPredicted_, average='macro')\n",
        "    fscore = f1_score(test_y_dummies, yTestPredicted_, average='macro')\n",
        "\n",
        "    #This function calculates all the evaluation metrics for every iteration\n",
        "    roc_auc = roc(model, test_x, test_y_dummies, n_classes)\n",
        "    result_array = [Accuracy, pScore, rScore, fscore]\n",
        "\n",
        "\n",
        "    sum_of_roc_scores = 0\n",
        "    for i in range(n_classes):\n",
        "      result_array.append(roc_auc[i])\n",
        "      sum_of_roc_scores = sum_of_roc_scores + roc_auc[i]\n",
        "\n",
        "    aggregate_roc_score = sum_of_roc_scores/n_classes\n",
        "    result_array.append(aggregate_roc_score)\n",
        "\n",
        "    print(\"Confusion matrix:\\n\", cMatrix)\n",
        "    print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n",
        "    \n",
        "    if best_accuracy < Accuracy:\n",
        "      best_model = model\n",
        "      best_accuracy = Accuracy\n",
        "      best_history = history\n",
        "\n",
        "    print(result_array)\n",
        "    result_dict = {'Accuracy': Accuracy, 'precision': pScore, 'recall' : rScore, 'F1_score': fscore, \"AUC_0\": result_array[4]\n",
        "                   , \"AUC_1\": result_array[5], \"AUC_2\": result_array[6], \"Aggregate_AUC\": result_array[7]}\n",
        "    df = df.append(result_dict, ignore_index = True)\n",
        "  print(df)\n",
        "  return best_model, best_history, sum_y_pred/experimental_runs, df"
      ],
      "metadata": {
        "id": "v2kKh9E8Qkus"
      },
      "id": "v2kKh9E8Qkus",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'MLP_RMSPROP'\n",
        "NAME = 'Landsat9_DATA'\n",
        "optimiser_type = 'rmsprop'\n",
        "experimental_runs = 10\n",
        "\n",
        "best_model, best_history, avg_y_pred, df = MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "best_model.save('Best_model_{}_{}'.format(NAME, Model_name))\n",
        "plot_metric(best_history, \"loss\")\n",
        "print(\"\")\n",
        "plot_metric(best_history, \"accuracy\")\n",
        "# plot_AUC_ROC(best_model, test_x, test_y, 3, label_names)\n",
        "# print(\"\")\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "print(avg_y_pred)\n",
        "test_y_dummies = test_y.argmax(axis = 1)\n",
        "plot_avg_AUC_ROC(avg_y_pred, test_y_dummies, 3, label_names)\n",
        "print(\"\")\n",
        "avg_y_pred = avg_y_pred.argmax(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Qsd4XK0eQkrz",
        "outputId": "cc86fa47-659d-47c4-c2d6-1fd991d05045"
      },
      "id": "Qsd4XK0eQkrz",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1363 - accuracy: 0.2971 - val_loss: 1.1176 - val_accuracy: 0.3533\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1116 - accuracy: 0.3210 - val_loss: 1.1022 - val_accuracy: 0.3222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0945 - accuracy: 0.3514 - val_loss: 1.0852 - val_accuracy: 0.4800\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0772 - accuracy: 0.4867 - val_loss: 1.0679 - val_accuracy: 0.6267\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0606 - accuracy: 0.5933 - val_loss: 1.0511 - val_accuracy: 0.5378\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0414 - accuracy: 0.5667 - val_loss: 1.0292 - val_accuracy: 0.6356\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0151 - accuracy: 0.6333 - val_loss: 1.0045 - val_accuracy: 0.5956\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9833 - accuracy: 0.6800 - val_loss: 0.9691 - val_accuracy: 0.7333\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9504 - accuracy: 0.7248 - val_loss: 0.9387 - val_accuracy: 0.7089\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9200 - accuracy: 0.7133 - val_loss: 0.9169 - val_accuracy: 0.7000\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8932 - accuracy: 0.7133 - val_loss: 0.8856 - val_accuracy: 0.7222\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8655 - accuracy: 0.7152 - val_loss: 0.8614 - val_accuracy: 0.6933\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.7076 - val_loss: 0.8439 - val_accuracy: 0.6578\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8227 - accuracy: 0.7095 - val_loss: 0.8245 - val_accuracy: 0.6689\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8032 - accuracy: 0.7076 - val_loss: 0.8074 - val_accuracy: 0.7222\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7861 - accuracy: 0.7229 - val_loss: 0.7907 - val_accuracy: 0.6911\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7719 - accuracy: 0.7305 - val_loss: 0.7789 - val_accuracy: 0.7133\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.7162 - val_loss: 0.7658 - val_accuracy: 0.7000\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7451 - accuracy: 0.7305 - val_loss: 0.7580 - val_accuracy: 0.6822\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7333 - accuracy: 0.7343 - val_loss: 0.7431 - val_accuracy: 0.7067\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7246 - accuracy: 0.7276 - val_loss: 0.7381 - val_accuracy: 0.7311\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.7448 - val_loss: 0.7270 - val_accuracy: 0.7378\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7065 - accuracy: 0.7410 - val_loss: 0.7208 - val_accuracy: 0.7333\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6975 - accuracy: 0.7352 - val_loss: 0.7160 - val_accuracy: 0.7444\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.7524 - val_loss: 0.7106 - val_accuracy: 0.7444\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.7571 - val_loss: 0.7174 - val_accuracy: 0.7133\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.7410 - val_loss: 0.6956 - val_accuracy: 0.7378\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6725 - accuracy: 0.7486 - val_loss: 0.6907 - val_accuracy: 0.7289\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6675 - accuracy: 0.7495 - val_loss: 0.6894 - val_accuracy: 0.7489\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.7581 - val_loss: 0.6876 - val_accuracy: 0.7400\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7667 - val_loss: 0.6820 - val_accuracy: 0.7489\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6540 - accuracy: 0.7514 - val_loss: 0.6704 - val_accuracy: 0.7422\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6424 - accuracy: 0.7590 - val_loss: 0.6805 - val_accuracy: 0.7267\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.7629 - val_loss: 0.6615 - val_accuracy: 0.7467\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6369 - accuracy: 0.7724 - val_loss: 0.6589 - val_accuracy: 0.7533\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6317 - accuracy: 0.7676 - val_loss: 0.6619 - val_accuracy: 0.7511\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7695 - val_loss: 0.6557 - val_accuracy: 0.7556\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6222 - accuracy: 0.7705 - val_loss: 0.6482 - val_accuracy: 0.7578\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6159 - accuracy: 0.7781 - val_loss: 0.6463 - val_accuracy: 0.7644\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6134 - accuracy: 0.7838 - val_loss: 0.6353 - val_accuracy: 0.7622\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6074 - accuracy: 0.7800 - val_loss: 0.6262 - val_accuracy: 0.7711\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6012 - accuracy: 0.7886 - val_loss: 0.6275 - val_accuracy: 0.7667\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5949 - accuracy: 0.7924 - val_loss: 0.6173 - val_accuracy: 0.7756\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.8010 - val_loss: 0.6198 - val_accuracy: 0.7667\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5839 - accuracy: 0.8010 - val_loss: 0.6071 - val_accuracy: 0.7778\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5761 - accuracy: 0.7943 - val_loss: 0.6245 - val_accuracy: 0.7622\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5715 - accuracy: 0.8095 - val_loss: 0.5999 - val_accuracy: 0.7844\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5640 - accuracy: 0.8105 - val_loss: 0.5859 - val_accuracy: 0.8022\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.8210 - val_loss: 0.5793 - val_accuracy: 0.7978\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.8124 - val_loss: 0.5748 - val_accuracy: 0.8111\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.8219 - val_loss: 0.5706 - val_accuracy: 0.7956\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8190 - val_loss: 0.5842 - val_accuracy: 0.7822\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.8257 - val_loss: 0.5567 - val_accuracy: 0.8156\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.8362 - val_loss: 0.5507 - val_accuracy: 0.8089\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5229 - accuracy: 0.8362 - val_loss: 0.5427 - val_accuracy: 0.8111\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8467 - val_loss: 0.5354 - val_accuracy: 0.8289\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5117 - accuracy: 0.8438 - val_loss: 0.5292 - val_accuracy: 0.8289\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4991 - accuracy: 0.8486 - val_loss: 0.5403 - val_accuracy: 0.8156\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4962 - accuracy: 0.8438 - val_loss: 0.5306 - val_accuracy: 0.8222\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4882 - accuracy: 0.8448 - val_loss: 0.5089 - val_accuracy: 0.8311\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4827 - accuracy: 0.8476 - val_loss: 0.5134 - val_accuracy: 0.8200\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8543 - val_loss: 0.5002 - val_accuracy: 0.8333\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4698 - accuracy: 0.8581 - val_loss: 0.4960 - val_accuracy: 0.8444\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.4628 - accuracy: 0.8590 - val_loss: 0.4926 - val_accuracy: 0.8467\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4582 - accuracy: 0.8590 - val_loss: 0.4787 - val_accuracy: 0.8400\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.8590 - val_loss: 0.4703 - val_accuracy: 0.8378\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.4443 - accuracy: 0.8619 - val_loss: 0.4656 - val_accuracy: 0.8422\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.8695 - val_loss: 0.4584 - val_accuracy: 0.8467\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4321 - accuracy: 0.8638 - val_loss: 0.4584 - val_accuracy: 0.8489\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8695 - val_loss: 0.4488 - val_accuracy: 0.8489\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4193 - accuracy: 0.8733 - val_loss: 0.4409 - val_accuracy: 0.8511\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4141 - accuracy: 0.8752 - val_loss: 0.4424 - val_accuracy: 0.8578\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4118 - accuracy: 0.8733 - val_loss: 0.4273 - val_accuracy: 0.8556\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.4028 - accuracy: 0.8771 - val_loss: 0.4501 - val_accuracy: 0.8511\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3988 - accuracy: 0.8771 - val_loss: 0.4230 - val_accuracy: 0.8444\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3951 - accuracy: 0.8714 - val_loss: 0.4204 - val_accuracy: 0.8622\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 10ms/step - loss: 0.3859 - accuracy: 0.8857 - val_loss: 0.4401 - val_accuracy: 0.8578\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3830 - accuracy: 0.8819 - val_loss: 0.4222 - val_accuracy: 0.8733\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3787 - accuracy: 0.8829 - val_loss: 0.3980 - val_accuracy: 0.8556\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3722 - accuracy: 0.8886 - val_loss: 0.4127 - val_accuracy: 0.8422\n",
            "15/15 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[124   5  19]\n",
            " [ 20 108  15]\n",
            " [ 12   0 147]]\n",
            "\n",
            "P-Score: 0.854, R-Score: 0.839, F-Score: 0.841\n",
            "[0.8422222222222222, 0.8542595677979241, 0.8392036316564618, 0.8414151186790506, 0.8659387864685877, 0.8694790551468076, 0.9038449069571419, 0.8797542495241789]\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 3s 16ms/step - loss: 1.1294 - accuracy: 0.3429 - val_loss: 1.0930 - val_accuracy: 0.3644\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0860 - accuracy: 0.3552 - val_loss: 1.0826 - val_accuracy: 0.4400\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0761 - accuracy: 0.4524 - val_loss: 1.0712 - val_accuracy: 0.4756\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0617 - accuracy: 0.4667 - val_loss: 1.0564 - val_accuracy: 0.4778\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0396 - accuracy: 0.5114 - val_loss: 1.0330 - val_accuracy: 0.5178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 1.0170 - accuracy: 0.5229 - val_loss: 1.0116 - val_accuracy: 0.5044\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9955 - accuracy: 0.5429 - val_loss: 0.9917 - val_accuracy: 0.5200\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.9758 - accuracy: 0.5419 - val_loss: 0.9745 - val_accuracy: 0.5267\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.9573 - accuracy: 0.5362 - val_loss: 0.9567 - val_accuracy: 0.5222\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9404 - accuracy: 0.5438 - val_loss: 0.9411 - val_accuracy: 0.5222\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9221 - accuracy: 0.5476 - val_loss: 0.9235 - val_accuracy: 0.5244\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9034 - accuracy: 0.5390 - val_loss: 0.9072 - val_accuracy: 0.5267\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8857 - accuracy: 0.5600 - val_loss: 0.8918 - val_accuracy: 0.5200\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8684 - accuracy: 0.5848 - val_loss: 0.8740 - val_accuracy: 0.5556\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8526 - accuracy: 0.6029 - val_loss: 0.8601 - val_accuracy: 0.5844\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8377 - accuracy: 0.6638 - val_loss: 0.8445 - val_accuracy: 0.6689\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8228 - accuracy: 0.6638 - val_loss: 0.8321 - val_accuracy: 0.6800\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8089 - accuracy: 0.7076 - val_loss: 0.8183 - val_accuracy: 0.6644\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7969 - accuracy: 0.6676 - val_loss: 0.8078 - val_accuracy: 0.6911\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7841 - accuracy: 0.6857 - val_loss: 0.7973 - val_accuracy: 0.6933\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7732 - accuracy: 0.6876 - val_loss: 0.7863 - val_accuracy: 0.6956\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7631 - accuracy: 0.6981 - val_loss: 0.7791 - val_accuracy: 0.7133\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7532 - accuracy: 0.6914 - val_loss: 0.7745 - val_accuracy: 0.7044\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7439 - accuracy: 0.7000 - val_loss: 0.7607 - val_accuracy: 0.7000\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.7067 - val_loss: 0.7577 - val_accuracy: 0.7089\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7297 - accuracy: 0.7171 - val_loss: 0.7430 - val_accuracy: 0.6800\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7201 - accuracy: 0.7105 - val_loss: 0.7389 - val_accuracy: 0.7267\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.7276 - val_loss: 0.7309 - val_accuracy: 0.7178\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7072 - accuracy: 0.7371 - val_loss: 0.7240 - val_accuracy: 0.7067\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7026 - accuracy: 0.7248 - val_loss: 0.7188 - val_accuracy: 0.7133\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6950 - accuracy: 0.7390 - val_loss: 0.7160 - val_accuracy: 0.7289\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6904 - accuracy: 0.7381 - val_loss: 0.7340 - val_accuracy: 0.6933\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7333 - val_loss: 0.7102 - val_accuracy: 0.6911\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6793 - accuracy: 0.7410 - val_loss: 0.7015 - val_accuracy: 0.7244\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6758 - accuracy: 0.7419 - val_loss: 0.6982 - val_accuracy: 0.7444\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6696 - accuracy: 0.7476 - val_loss: 0.6924 - val_accuracy: 0.7400\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6653 - accuracy: 0.7562 - val_loss: 0.6999 - val_accuracy: 0.7178\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.7448 - val_loss: 0.6793 - val_accuracy: 0.7356\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6554 - accuracy: 0.7524 - val_loss: 0.6742 - val_accuracy: 0.7467\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.7562 - val_loss: 0.6697 - val_accuracy: 0.7511\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.7590 - val_loss: 0.6887 - val_accuracy: 0.7222\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.7619 - val_loss: 0.6785 - val_accuracy: 0.7356\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7657 - val_loss: 0.6658 - val_accuracy: 0.7222\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.7724 - val_loss: 0.6593 - val_accuracy: 0.7356\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6271 - accuracy: 0.7743 - val_loss: 0.6486 - val_accuracy: 0.7600\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.7867 - val_loss: 0.6725 - val_accuracy: 0.7378\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.7714 - val_loss: 0.6383 - val_accuracy: 0.7689\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6119 - accuracy: 0.7838 - val_loss: 0.6435 - val_accuracy: 0.7400\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6052 - accuracy: 0.7771 - val_loss: 0.6312 - val_accuracy: 0.7556\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7924 - val_loss: 0.6323 - val_accuracy: 0.7489\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5963 - accuracy: 0.7914 - val_loss: 0.6211 - val_accuracy: 0.7600\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5914 - accuracy: 0.7924 - val_loss: 0.6170 - val_accuracy: 0.7644\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7962 - val_loss: 0.6070 - val_accuracy: 0.7844\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.7962 - val_loss: 0.6008 - val_accuracy: 0.7911\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.8029 - val_loss: 0.5959 - val_accuracy: 0.7911\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5673 - accuracy: 0.8057 - val_loss: 0.5975 - val_accuracy: 0.7667\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5613 - accuracy: 0.8057 - val_loss: 0.5916 - val_accuracy: 0.7933\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5580 - accuracy: 0.8181 - val_loss: 0.5883 - val_accuracy: 0.8044\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5490 - accuracy: 0.8238 - val_loss: 0.5706 - val_accuracy: 0.7956\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5434 - accuracy: 0.8333 - val_loss: 0.5838 - val_accuracy: 0.7533\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5356 - accuracy: 0.8276 - val_loss: 0.5616 - val_accuracy: 0.8156\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5314 - accuracy: 0.8314 - val_loss: 0.5599 - val_accuracy: 0.7978\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.8352 - val_loss: 0.5499 - val_accuracy: 0.8111\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.8333 - val_loss: 0.5377 - val_accuracy: 0.8200\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8371 - val_loss: 0.5359 - val_accuracy: 0.8133\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5045 - accuracy: 0.8429 - val_loss: 0.5242 - val_accuracy: 0.8200\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4970 - accuracy: 0.8495 - val_loss: 0.5204 - val_accuracy: 0.8311\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.8438 - val_loss: 0.5113 - val_accuracy: 0.8311\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.8590 - val_loss: 0.5181 - val_accuracy: 0.8111\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4787 - accuracy: 0.8486 - val_loss: 0.5078 - val_accuracy: 0.8267\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4729 - accuracy: 0.8638 - val_loss: 0.5018 - val_accuracy: 0.8356\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.8657 - val_loss: 0.4885 - val_accuracy: 0.8311\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8514 - val_loss: 0.4904 - val_accuracy: 0.8356\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4513 - accuracy: 0.8648 - val_loss: 0.4748 - val_accuracy: 0.8400\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8705 - val_loss: 0.4650 - val_accuracy: 0.8444\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4417 - accuracy: 0.8686 - val_loss: 0.4713 - val_accuracy: 0.8467\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8695 - val_loss: 0.4589 - val_accuracy: 0.8400\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4256 - accuracy: 0.8686 - val_loss: 0.4526 - val_accuracy: 0.8400\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4228 - accuracy: 0.8762 - val_loss: 0.4557 - val_accuracy: 0.8311\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4157 - accuracy: 0.8781 - val_loss: 0.4472 - val_accuracy: 0.8511\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[124  14  10]\n",
            " [ 15 122   6]\n",
            " [ 20   2 137]]\n",
            "\n",
            "P-Score: 0.853, R-Score: 0.851, F-Score: 0.851\n",
            "[0.8511111111111112, 0.8531190071507594, 0.8508733037034925, 0.8514500399723023, 0.8609718990513692, 0.9005147946516024, 0.9033262011281852, 0.8882709649437189]\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.3230 - accuracy: 0.3324 - val_loss: 1.1850 - val_accuracy: 0.3200\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1513 - accuracy: 0.2305 - val_loss: 1.1285 - val_accuracy: 0.1444\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1235 - accuracy: 0.2048 - val_loss: 1.1166 - val_accuracy: 0.3178\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1118 - accuracy: 0.3476 - val_loss: 1.1056 - val_accuracy: 0.3178\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1006 - accuracy: 0.3695 - val_loss: 1.1004 - val_accuracy: 0.3178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0915 - accuracy: 0.3438 - val_loss: 1.0850 - val_accuracy: 0.5089\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0823 - accuracy: 0.3800 - val_loss: 1.0752 - val_accuracy: 0.4289\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0732 - accuracy: 0.4171 - val_loss: 1.0675 - val_accuracy: 0.4444\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0627 - accuracy: 0.5429 - val_loss: 1.0568 - val_accuracy: 0.4822\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.4895 - val_loss: 1.0450 - val_accuracy: 0.4911\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0431 - accuracy: 0.5771 - val_loss: 1.0367 - val_accuracy: 0.6733\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0329 - accuracy: 0.5895 - val_loss: 1.0270 - val_accuracy: 0.6444\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.6038 - val_loss: 1.0224 - val_accuracy: 0.4911\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0112 - accuracy: 0.6048 - val_loss: 1.0056 - val_accuracy: 0.6756\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9986 - accuracy: 0.6505 - val_loss: 0.9946 - val_accuracy: 0.6311\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.6705 - val_loss: 0.9799 - val_accuracy: 0.7022\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9711 - accuracy: 0.6705 - val_loss: 0.9671 - val_accuracy: 0.6756\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9564 - accuracy: 0.6924 - val_loss: 0.9517 - val_accuracy: 0.7244\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9415 - accuracy: 0.6771 - val_loss: 0.9358 - val_accuracy: 0.6356\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.6924 - val_loss: 0.9239 - val_accuracy: 0.7222\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9136 - accuracy: 0.7067 - val_loss: 0.9115 - val_accuracy: 0.6956\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8989 - accuracy: 0.7029 - val_loss: 0.8981 - val_accuracy: 0.7022\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8858 - accuracy: 0.6990 - val_loss: 0.8849 - val_accuracy: 0.6978\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8736 - accuracy: 0.7048 - val_loss: 0.8750 - val_accuracy: 0.6844\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8590 - accuracy: 0.7095 - val_loss: 0.8628 - val_accuracy: 0.6800\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8475 - accuracy: 0.6971 - val_loss: 0.8529 - val_accuracy: 0.6800\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8363 - accuracy: 0.7095 - val_loss: 0.8462 - val_accuracy: 0.6800\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8264 - accuracy: 0.6895 - val_loss: 0.8343 - val_accuracy: 0.6867\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8170 - accuracy: 0.6905 - val_loss: 0.8264 - val_accuracy: 0.6844\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8064 - accuracy: 0.7019 - val_loss: 0.8160 - val_accuracy: 0.6911\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7991 - accuracy: 0.6867 - val_loss: 0.8087 - val_accuracy: 0.7000\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.6952 - val_loss: 0.8012 - val_accuracy: 0.7022\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7820 - accuracy: 0.7095 - val_loss: 0.7961 - val_accuracy: 0.6733\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7760 - accuracy: 0.6905 - val_loss: 0.7891 - val_accuracy: 0.6733\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7678 - accuracy: 0.7029 - val_loss: 0.7840 - val_accuracy: 0.7022\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7626 - accuracy: 0.6876 - val_loss: 0.7805 - val_accuracy: 0.6956\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7567 - accuracy: 0.7038 - val_loss: 0.7770 - val_accuracy: 0.6978\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.7152 - val_loss: 0.7772 - val_accuracy: 0.6911\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7470 - accuracy: 0.7210 - val_loss: 0.7700 - val_accuracy: 0.6667\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7429 - accuracy: 0.7095 - val_loss: 0.7610 - val_accuracy: 0.6844\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.7057 - val_loss: 0.7588 - val_accuracy: 0.7067\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.6990 - val_loss: 0.7539 - val_accuracy: 0.6867\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7324 - accuracy: 0.7171 - val_loss: 0.7516 - val_accuracy: 0.7044\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7282 - accuracy: 0.7210 - val_loss: 0.7486 - val_accuracy: 0.6867\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7255 - accuracy: 0.7200 - val_loss: 0.7451 - val_accuracy: 0.6933\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7210 - accuracy: 0.7257 - val_loss: 0.7436 - val_accuracy: 0.7089\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7166 - accuracy: 0.7238 - val_loss: 0.7420 - val_accuracy: 0.7133\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7159 - accuracy: 0.7219 - val_loss: 0.7418 - val_accuracy: 0.7067\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7128 - accuracy: 0.7295 - val_loss: 0.7364 - val_accuracy: 0.7111\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7090 - accuracy: 0.7295 - val_loss: 0.7366 - val_accuracy: 0.7178\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.7305 - val_loss: 0.7332 - val_accuracy: 0.7200\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7314 - val_loss: 0.7296 - val_accuracy: 0.7267\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7030 - accuracy: 0.7371 - val_loss: 0.7262 - val_accuracy: 0.7244\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7010 - accuracy: 0.7390 - val_loss: 0.7288 - val_accuracy: 0.7222\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.7362 - val_loss: 0.7228 - val_accuracy: 0.7311\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.7371 - val_loss: 0.7205 - val_accuracy: 0.7311\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6916 - accuracy: 0.7362 - val_loss: 0.7156 - val_accuracy: 0.7356\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6880 - accuracy: 0.7486 - val_loss: 0.7199 - val_accuracy: 0.7289\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.7448 - val_loss: 0.7175 - val_accuracy: 0.7156\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.7571 - val_loss: 0.7089 - val_accuracy: 0.7356\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6789 - accuracy: 0.7429 - val_loss: 0.7036 - val_accuracy: 0.7511\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6731 - accuracy: 0.7619 - val_loss: 0.7062 - val_accuracy: 0.7111\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6746 - accuracy: 0.7590 - val_loss: 0.6995 - val_accuracy: 0.7511\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.7543 - val_loss: 0.6949 - val_accuracy: 0.7622\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.7676 - val_loss: 0.7019 - val_accuracy: 0.7444\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6614 - accuracy: 0.7695 - val_loss: 0.6932 - val_accuracy: 0.7511\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7733 - val_loss: 0.6845 - val_accuracy: 0.7644\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6513 - accuracy: 0.7771 - val_loss: 0.6814 - val_accuracy: 0.7644\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6488 - accuracy: 0.7819 - val_loss: 0.6761 - val_accuracy: 0.7711\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7886 - val_loss: 0.6805 - val_accuracy: 0.7511\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.7857 - val_loss: 0.6673 - val_accuracy: 0.7711\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.7895 - val_loss: 0.6624 - val_accuracy: 0.7867\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7962 - val_loss: 0.6577 - val_accuracy: 0.7778\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.7981 - val_loss: 0.6576 - val_accuracy: 0.7667\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.8010 - val_loss: 0.6495 - val_accuracy: 0.7778\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6174 - accuracy: 0.8067 - val_loss: 0.6396 - val_accuracy: 0.8000\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.8038 - val_loss: 0.6375 - val_accuracy: 0.7733\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6062 - accuracy: 0.8124 - val_loss: 0.6351 - val_accuracy: 0.7733\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6028 - accuracy: 0.8152 - val_loss: 0.6328 - val_accuracy: 0.7778\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.8257 - val_loss: 0.6164 - val_accuracy: 0.8067\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[117  18  13]\n",
            " [ 18 111  14]\n",
            " [ 15   9 135]]\n",
            "\n",
            "P-Score: 0.806, R-Score: 0.805, F-Score: 0.805\n",
            "[0.8066666666666666, 0.8058937198067633, 0.8052736401793007, 0.8054639939481913, 0.8406345086808663, 0.8441379467438099, 0.8781365493094728, 0.8543030015780498]\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_9 (Dense)             (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1462 - accuracy: 0.3543 - val_loss: 1.1353 - val_accuracy: 0.3244\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1094 - accuracy: 0.3810 - val_loss: 1.1088 - val_accuracy: 0.3911\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.4210 - val_loss: 1.0929 - val_accuracy: 0.4867\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0766 - accuracy: 0.4733 - val_loss: 1.0719 - val_accuracy: 0.3889\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0626 - accuracy: 0.4629 - val_loss: 1.0599 - val_accuracy: 0.4178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0484 - accuracy: 0.5124 - val_loss: 1.0458 - val_accuracy: 0.4111\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0323 - accuracy: 0.5019 - val_loss: 1.0300 - val_accuracy: 0.4022\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0139 - accuracy: 0.5000 - val_loss: 1.0117 - val_accuracy: 0.5178\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9964 - accuracy: 0.5286 - val_loss: 0.9952 - val_accuracy: 0.4667\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9793 - accuracy: 0.5333 - val_loss: 0.9779 - val_accuracy: 0.5289\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9608 - accuracy: 0.5324 - val_loss: 0.9598 - val_accuracy: 0.5311\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9426 - accuracy: 0.5314 - val_loss: 0.9448 - val_accuracy: 0.5422\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9247 - accuracy: 0.5600 - val_loss: 0.9263 - val_accuracy: 0.5000\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9095 - accuracy: 0.5410 - val_loss: 0.9115 - val_accuracy: 0.5422\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8934 - accuracy: 0.5657 - val_loss: 0.8968 - val_accuracy: 0.5356\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8792 - accuracy: 0.5686 - val_loss: 0.8832 - val_accuracy: 0.5444\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8641 - accuracy: 0.5619 - val_loss: 0.8677 - val_accuracy: 0.6267\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8488 - accuracy: 0.6057 - val_loss: 0.8535 - val_accuracy: 0.6933\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8350 - accuracy: 0.6457 - val_loss: 0.8413 - val_accuracy: 0.6489\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8234 - accuracy: 0.6467 - val_loss: 0.8332 - val_accuracy: 0.6511\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8135 - accuracy: 0.6467 - val_loss: 0.8216 - val_accuracy: 0.6711\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8017 - accuracy: 0.6476 - val_loss: 0.8184 - val_accuracy: 0.6778\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7954 - accuracy: 0.6371 - val_loss: 0.8071 - val_accuracy: 0.6689\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7891 - accuracy: 0.6505 - val_loss: 0.8011 - val_accuracy: 0.6711\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7820 - accuracy: 0.6381 - val_loss: 0.7922 - val_accuracy: 0.6600\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7755 - accuracy: 0.6571 - val_loss: 0.7856 - val_accuracy: 0.6733\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7684 - accuracy: 0.6371 - val_loss: 0.7814 - val_accuracy: 0.6556\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7636 - accuracy: 0.6619 - val_loss: 0.7764 - val_accuracy: 0.6556\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.6533 - val_loss: 0.7782 - val_accuracy: 0.6667\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7537 - accuracy: 0.6533 - val_loss: 0.7724 - val_accuracy: 0.6511\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7495 - accuracy: 0.6495 - val_loss: 0.7695 - val_accuracy: 0.6578\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7473 - accuracy: 0.6657 - val_loss: 0.7608 - val_accuracy: 0.6667\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7433 - accuracy: 0.6619 - val_loss: 0.7595 - val_accuracy: 0.6600\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7364 - accuracy: 0.6667 - val_loss: 0.7638 - val_accuracy: 0.6311\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7354 - accuracy: 0.6629 - val_loss: 0.7585 - val_accuracy: 0.6556\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7349 - accuracy: 0.6629 - val_loss: 0.7504 - val_accuracy: 0.6600\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7311 - accuracy: 0.6648 - val_loss: 0.7615 - val_accuracy: 0.6667\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7316 - accuracy: 0.6724 - val_loss: 0.7459 - val_accuracy: 0.6578\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7262 - accuracy: 0.6695 - val_loss: 0.7437 - val_accuracy: 0.6600\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7247 - accuracy: 0.6714 - val_loss: 0.7438 - val_accuracy: 0.6556\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7216 - accuracy: 0.6667 - val_loss: 0.7420 - val_accuracy: 0.6644\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7188 - accuracy: 0.6829 - val_loss: 0.7483 - val_accuracy: 0.6644\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7187 - accuracy: 0.6619 - val_loss: 0.7391 - val_accuracy: 0.6667\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7158 - accuracy: 0.6648 - val_loss: 0.7323 - val_accuracy: 0.6733\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7125 - accuracy: 0.6848 - val_loss: 0.7301 - val_accuracy: 0.6733\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7108 - accuracy: 0.6743 - val_loss: 0.7335 - val_accuracy: 0.6644\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7094 - accuracy: 0.6686 - val_loss: 0.7304 - val_accuracy: 0.6622\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.6886 - val_loss: 0.7271 - val_accuracy: 0.6711\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7063 - accuracy: 0.6895 - val_loss: 0.7244 - val_accuracy: 0.6689\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.6800 - val_loss: 0.7304 - val_accuracy: 0.6733\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7017 - accuracy: 0.6819 - val_loss: 0.7223 - val_accuracy: 0.6667\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6979 - accuracy: 0.6952 - val_loss: 0.7189 - val_accuracy: 0.6667\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.6981 - val_loss: 0.7203 - val_accuracy: 0.6689\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6935 - accuracy: 0.6914 - val_loss: 0.7322 - val_accuracy: 0.6844\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6926 - accuracy: 0.7000 - val_loss: 0.7398 - val_accuracy: 0.6778\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6906 - accuracy: 0.7076 - val_loss: 0.7088 - val_accuracy: 0.6889\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.7010 - val_loss: 0.7067 - val_accuracy: 0.6933\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6852 - accuracy: 0.6914 - val_loss: 0.7096 - val_accuracy: 0.6867\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6816 - accuracy: 0.6981 - val_loss: 0.7099 - val_accuracy: 0.6844\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6833 - accuracy: 0.7086 - val_loss: 0.7073 - val_accuracy: 0.6778\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6787 - accuracy: 0.6971 - val_loss: 0.7006 - val_accuracy: 0.6911\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.7010 - val_loss: 0.7016 - val_accuracy: 0.6756\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6735 - accuracy: 0.7057 - val_loss: 0.6960 - val_accuracy: 0.6911\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6692 - accuracy: 0.7143 - val_loss: 0.6928 - val_accuracy: 0.6978\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.7086 - val_loss: 0.6898 - val_accuracy: 0.7000\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6677 - accuracy: 0.7048 - val_loss: 0.7011 - val_accuracy: 0.6867\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.7190 - val_loss: 0.6872 - val_accuracy: 0.7044\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6604 - accuracy: 0.7238 - val_loss: 0.6882 - val_accuracy: 0.7133\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7314 - val_loss: 0.6798 - val_accuracy: 0.7044\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7267 - val_loss: 0.6796 - val_accuracy: 0.7044\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7295 - val_loss: 0.6921 - val_accuracy: 0.7067\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7238 - val_loss: 0.6717 - val_accuracy: 0.7111\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.7333 - val_loss: 0.6741 - val_accuracy: 0.7111\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.7390 - val_loss: 0.6705 - val_accuracy: 0.7133\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6363 - accuracy: 0.7419 - val_loss: 0.6729 - val_accuracy: 0.7067\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.7476 - val_loss: 0.6589 - val_accuracy: 0.7400\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7533 - val_loss: 0.6577 - val_accuracy: 0.7222\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6301 - accuracy: 0.7543 - val_loss: 0.6496 - val_accuracy: 0.7289\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6210 - accuracy: 0.7495 - val_loss: 0.6684 - val_accuracy: 0.7311\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7610 - val_loss: 0.6500 - val_accuracy: 0.7267\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[110  34   4]\n",
            " [ 11 119  13]\n",
            " [ 10  51  98]]\n",
            "\n",
            "P-Score: 0.758, R-Score: 0.731, F-Score: 0.730\n",
            "[0.7266666666666667, 0.7584006342884537, 0.7305877588896457, 0.7299126318797095, 0.8368534097010918, 0.7776474339992254, 0.7789664786358036, 0.7978224407787069]\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_12 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1958 - accuracy: 0.3286 - val_loss: 1.0900 - val_accuracy: 0.3533\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0908 - accuracy: 0.3848 - val_loss: 1.0827 - val_accuracy: 0.4400\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0824 - accuracy: 0.4067 - val_loss: 1.0773 - val_accuracy: 0.5356\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0792 - accuracy: 0.4238 - val_loss: 1.0714 - val_accuracy: 0.5244\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0746 - accuracy: 0.4590 - val_loss: 1.0689 - val_accuracy: 0.4844\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0702 - accuracy: 0.4581 - val_loss: 1.0634 - val_accuracy: 0.5800\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0636 - accuracy: 0.4829 - val_loss: 1.0564 - val_accuracy: 0.6267\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0564 - accuracy: 0.4819 - val_loss: 1.0510 - val_accuracy: 0.6044\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0505 - accuracy: 0.5448 - val_loss: 1.0484 - val_accuracy: 0.4133\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0439 - accuracy: 0.5495 - val_loss: 1.0430 - val_accuracy: 0.3956\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0360 - accuracy: 0.5819 - val_loss: 1.0276 - val_accuracy: 0.6911\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0274 - accuracy: 0.6029 - val_loss: 1.0206 - val_accuracy: 0.5622\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0199 - accuracy: 0.6838 - val_loss: 1.0116 - val_accuracy: 0.6933\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0118 - accuracy: 0.6476 - val_loss: 1.0016 - val_accuracy: 0.7889\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0019 - accuracy: 0.7000 - val_loss: 0.9962 - val_accuracy: 0.5711\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9912 - accuracy: 0.7305 - val_loss: 0.9825 - val_accuracy: 0.7578\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9809 - accuracy: 0.7181 - val_loss: 0.9728 - val_accuracy: 0.8156\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9698 - accuracy: 0.7476 - val_loss: 0.9601 - val_accuracy: 0.7733\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9572 - accuracy: 0.7771 - val_loss: 0.9690 - val_accuracy: 0.5111\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9470 - accuracy: 0.7638 - val_loss: 0.9355 - val_accuracy: 0.7867\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9299 - accuracy: 0.7829 - val_loss: 0.9174 - val_accuracy: 0.7844\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9107 - accuracy: 0.7790 - val_loss: 0.9067 - val_accuracy: 0.7400\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8932 - accuracy: 0.7762 - val_loss: 0.8991 - val_accuracy: 0.6933\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8807 - accuracy: 0.8010 - val_loss: 0.8722 - val_accuracy: 0.8400\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8654 - accuracy: 0.8143 - val_loss: 0.8610 - val_accuracy: 0.7867\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8531 - accuracy: 0.8324 - val_loss: 0.8564 - val_accuracy: 0.7711\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8372 - accuracy: 0.8343 - val_loss: 0.8324 - val_accuracy: 0.8222\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8230 - accuracy: 0.8429 - val_loss: 0.8150 - val_accuracy: 0.8444\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8078 - accuracy: 0.8305 - val_loss: 0.8075 - val_accuracy: 0.8244\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7955 - accuracy: 0.8467 - val_loss: 0.7873 - val_accuracy: 0.8444\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7784 - accuracy: 0.8438 - val_loss: 0.7746 - val_accuracy: 0.8400\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7644 - accuracy: 0.8562 - val_loss: 0.7645 - val_accuracy: 0.8489\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7518 - accuracy: 0.8533 - val_loss: 0.7566 - val_accuracy: 0.7933\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7391 - accuracy: 0.8438 - val_loss: 0.7348 - val_accuracy: 0.8467\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7236 - accuracy: 0.8543 - val_loss: 0.7204 - val_accuracy: 0.8400\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7130 - accuracy: 0.8457 - val_loss: 0.7100 - val_accuracy: 0.8467\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.8524 - val_loss: 0.6947 - val_accuracy: 0.8400\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6858 - accuracy: 0.8524 - val_loss: 0.6923 - val_accuracy: 0.8222\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6712 - accuracy: 0.8629 - val_loss: 0.6757 - val_accuracy: 0.8244\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6613 - accuracy: 0.8562 - val_loss: 0.6725 - val_accuracy: 0.8089\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6474 - accuracy: 0.8562 - val_loss: 0.6504 - val_accuracy: 0.8333\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6368 - accuracy: 0.8629 - val_loss: 0.6339 - val_accuracy: 0.8489\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6250 - accuracy: 0.8676 - val_loss: 0.6231 - val_accuracy: 0.8400\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6096 - accuracy: 0.8648 - val_loss: 0.6211 - val_accuracy: 0.8244\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.8571 - val_loss: 0.6265 - val_accuracy: 0.8000\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5939 - accuracy: 0.8619 - val_loss: 0.5956 - val_accuracy: 0.8578\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5826 - accuracy: 0.8619 - val_loss: 0.5911 - val_accuracy: 0.8622\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5719 - accuracy: 0.8657 - val_loss: 0.5826 - val_accuracy: 0.8556\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.8695 - val_loss: 0.5691 - val_accuracy: 0.8644\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5535 - accuracy: 0.8743 - val_loss: 0.5540 - val_accuracy: 0.8511\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5449 - accuracy: 0.8676 - val_loss: 0.5531 - val_accuracy: 0.8600\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5350 - accuracy: 0.8724 - val_loss: 0.5620 - val_accuracy: 0.8311\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8743 - val_loss: 0.5325 - val_accuracy: 0.8511\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8714 - val_loss: 0.5336 - val_accuracy: 0.8556\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5084 - accuracy: 0.8686 - val_loss: 0.5100 - val_accuracy: 0.8556\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5008 - accuracy: 0.8705 - val_loss: 0.5047 - val_accuracy: 0.8422\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4938 - accuracy: 0.8771 - val_loss: 0.4948 - val_accuracy: 0.8600\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8752 - val_loss: 0.4865 - val_accuracy: 0.8511\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.8695 - val_loss: 0.5053 - val_accuracy: 0.8467\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.8781 - val_loss: 0.4772 - val_accuracy: 0.8644\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4571 - accuracy: 0.8724 - val_loss: 0.4616 - val_accuracy: 0.8600\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.8743 - val_loss: 0.4598 - val_accuracy: 0.8622\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4359 - accuracy: 0.8810 - val_loss: 0.4441 - val_accuracy: 0.8622\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8752 - val_loss: 0.4401 - val_accuracy: 0.8578\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4205 - accuracy: 0.8857 - val_loss: 0.4564 - val_accuracy: 0.8622\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4172 - accuracy: 0.8819 - val_loss: 0.4227 - val_accuracy: 0.8622\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4063 - accuracy: 0.8876 - val_loss: 0.4160 - val_accuracy: 0.8644\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4035 - accuracy: 0.8800 - val_loss: 0.4102 - val_accuracy: 0.8667\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3956 - accuracy: 0.8829 - val_loss: 0.4245 - val_accuracy: 0.8622\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3919 - accuracy: 0.8838 - val_loss: 0.4026 - val_accuracy: 0.8667\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3865 - accuracy: 0.8867 - val_loss: 0.3988 - val_accuracy: 0.8600\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8867 - val_loss: 0.4116 - val_accuracy: 0.8422\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3746 - accuracy: 0.8943 - val_loss: 0.3895 - val_accuracy: 0.8667\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3736 - accuracy: 0.8924 - val_loss: 0.3911 - val_accuracy: 0.8733\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3702 - accuracy: 0.8933 - val_loss: 0.3766 - val_accuracy: 0.8711\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3623 - accuracy: 0.8829 - val_loss: 0.3765 - val_accuracy: 0.8800\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3572 - accuracy: 0.8914 - val_loss: 0.3721 - val_accuracy: 0.8733\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3558 - accuracy: 0.8943 - val_loss: 0.3651 - val_accuracy: 0.8778\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3513 - accuracy: 0.8952 - val_loss: 0.3615 - val_accuracy: 0.8756\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8924 - val_loss: 0.3615 - val_accuracy: 0.8711\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[124   6  18]\n",
            " [ 16 121   6]\n",
            " [ 12   0 147]]\n",
            "\n",
            "P-Score: 0.876, R-Score: 0.870, F-Score: 0.871\n",
            "[0.8711111111111111, 0.876064834001013, 0.8695066619594921, 0.8712906846240179, 0.8725613030248791, 0.9133049361062391, 0.9210270375413343, 0.9022977588908175]\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_15 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1560 - accuracy: 0.2829 - val_loss: 1.1158 - val_accuracy: 0.1311\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1067 - accuracy: 0.3038 - val_loss: 1.0973 - val_accuracy: 0.3533\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0898 - accuracy: 0.3895 - val_loss: 1.0810 - val_accuracy: 0.4267\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.4762 - val_loss: 1.0640 - val_accuracy: 0.5378\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0526 - accuracy: 0.5638 - val_loss: 1.0437 - val_accuracy: 0.7600\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0334 - accuracy: 0.7124 - val_loss: 1.0299 - val_accuracy: 0.5511\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0143 - accuracy: 0.6057 - val_loss: 1.0065 - val_accuracy: 0.5933\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9924 - accuracy: 0.7076 - val_loss: 0.9864 - val_accuracy: 0.6356\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9723 - accuracy: 0.7743 - val_loss: 0.9667 - val_accuracy: 0.5822\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9507 - accuracy: 0.7695 - val_loss: 0.9447 - val_accuracy: 0.8622\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9297 - accuracy: 0.8190 - val_loss: 0.9252 - val_accuracy: 0.8400\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9087 - accuracy: 0.8114 - val_loss: 0.9037 - val_accuracy: 0.8422\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8878 - accuracy: 0.8533 - val_loss: 0.8834 - val_accuracy: 0.8578\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8662 - accuracy: 0.8771 - val_loss: 0.8659 - val_accuracy: 0.8311\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8437 - accuracy: 0.8352 - val_loss: 0.8411 - val_accuracy: 0.7867\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8217 - accuracy: 0.8505 - val_loss: 0.8231 - val_accuracy: 0.8511\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.8457 - val_loss: 0.8030 - val_accuracy: 0.8489\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7834 - accuracy: 0.8667 - val_loss: 0.7890 - val_accuracy: 0.8444\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7660 - accuracy: 0.8505 - val_loss: 0.7788 - val_accuracy: 0.7489\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.8410 - val_loss: 0.7540 - val_accuracy: 0.8333\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7355 - accuracy: 0.8562 - val_loss: 0.7413 - val_accuracy: 0.8533\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7178 - accuracy: 0.8495 - val_loss: 0.7279 - val_accuracy: 0.8333\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7059 - accuracy: 0.8552 - val_loss: 0.7209 - val_accuracy: 0.7978\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6908 - accuracy: 0.8667 - val_loss: 0.7037 - val_accuracy: 0.8200\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6759 - accuracy: 0.8543 - val_loss: 0.7036 - val_accuracy: 0.8289\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6644 - accuracy: 0.8590 - val_loss: 0.6748 - val_accuracy: 0.8356\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6527 - accuracy: 0.8543 - val_loss: 0.6642 - val_accuracy: 0.8267\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.8676 - val_loss: 0.6577 - val_accuracy: 0.8378\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.8638 - val_loss: 0.6603 - val_accuracy: 0.7778\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.8657 - val_loss: 0.6372 - val_accuracy: 0.8333\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6076 - accuracy: 0.8667 - val_loss: 0.6235 - val_accuracy: 0.8511\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.8762 - val_loss: 0.6172 - val_accuracy: 0.8444\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5873 - accuracy: 0.8705 - val_loss: 0.6147 - val_accuracy: 0.8444\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5792 - accuracy: 0.8752 - val_loss: 0.5967 - val_accuracy: 0.8489\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5663 - accuracy: 0.8800 - val_loss: 0.5878 - val_accuracy: 0.8244\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.8714 - val_loss: 0.5728 - val_accuracy: 0.8444\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5475 - accuracy: 0.8743 - val_loss: 0.5681 - val_accuracy: 0.8356\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.8762 - val_loss: 0.5586 - val_accuracy: 0.8578\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5286 - accuracy: 0.8771 - val_loss: 0.5457 - val_accuracy: 0.8578\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5191 - accuracy: 0.8790 - val_loss: 0.5411 - val_accuracy: 0.8556\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8810 - val_loss: 0.5298 - val_accuracy: 0.8600\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8810 - val_loss: 0.5302 - val_accuracy: 0.8578\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.8800 - val_loss: 0.5181 - val_accuracy: 0.8578\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8857 - val_loss: 0.5064 - val_accuracy: 0.8622\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8857 - val_loss: 0.5072 - val_accuracy: 0.8578\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.8914 - val_loss: 0.4960 - val_accuracy: 0.8556\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4555 - accuracy: 0.8886 - val_loss: 0.4787 - val_accuracy: 0.8667\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4440 - accuracy: 0.8886 - val_loss: 0.4673 - val_accuracy: 0.8711\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4395 - accuracy: 0.8848 - val_loss: 0.4587 - val_accuracy: 0.8733\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8857 - val_loss: 0.4505 - val_accuracy: 0.8644\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4215 - accuracy: 0.8924 - val_loss: 0.4432 - val_accuracy: 0.8644\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4115 - accuracy: 0.8848 - val_loss: 0.4605 - val_accuracy: 0.8444\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4101 - accuracy: 0.8886 - val_loss: 0.4336 - val_accuracy: 0.8733\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3982 - accuracy: 0.8876 - val_loss: 0.4391 - val_accuracy: 0.8622\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3915 - accuracy: 0.8952 - val_loss: 0.4218 - val_accuracy: 0.8733\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3839 - accuracy: 0.8905 - val_loss: 0.4237 - val_accuracy: 0.8644\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3754 - accuracy: 0.8943 - val_loss: 0.4079 - val_accuracy: 0.8689\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3726 - accuracy: 0.8933 - val_loss: 0.4189 - val_accuracy: 0.8622\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8971 - val_loss: 0.3910 - val_accuracy: 0.8756\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3578 - accuracy: 0.9019 - val_loss: 0.3873 - val_accuracy: 0.8778\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8971 - val_loss: 0.3791 - val_accuracy: 0.8800\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3505 - accuracy: 0.8924 - val_loss: 0.3750 - val_accuracy: 0.8733\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.9000 - val_loss: 0.3720 - val_accuracy: 0.8822\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8943 - val_loss: 0.3660 - val_accuracy: 0.8667\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8981 - val_loss: 0.3614 - val_accuracy: 0.8667\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8962 - val_loss: 0.3575 - val_accuracy: 0.8800\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3272 - accuracy: 0.8981 - val_loss: 0.3601 - val_accuracy: 0.8778\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8990 - val_loss: 0.3528 - val_accuracy: 0.8822\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8981 - val_loss: 0.3633 - val_accuracy: 0.8756\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3156 - accuracy: 0.8971 - val_loss: 0.3409 - val_accuracy: 0.8822\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3094 - accuracy: 0.9048 - val_loss: 0.3384 - val_accuracy: 0.8822\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3061 - accuracy: 0.9067 - val_loss: 0.3530 - val_accuracy: 0.8756\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8952 - val_loss: 0.3361 - val_accuracy: 0.8844\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8990 - val_loss: 0.3403 - val_accuracy: 0.8800\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2987 - accuracy: 0.9038 - val_loss: 0.3317 - val_accuracy: 0.8800\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.9048 - val_loss: 0.3274 - val_accuracy: 0.8711\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2909 - accuracy: 0.9048 - val_loss: 0.3242 - val_accuracy: 0.8822\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2881 - accuracy: 0.9105 - val_loss: 0.3479 - val_accuracy: 0.8622\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2877 - accuracy: 0.9076 - val_loss: 0.3162 - val_accuracy: 0.8844\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2832 - accuracy: 0.9029 - val_loss: 0.3316 - val_accuracy: 0.8800\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[127  10  11]\n",
            " [  8 135   0]\n",
            " [ 19   6 134]]\n",
            "\n",
            "P-Score: 0.881, R-Score: 0.882, F-Score: 0.880\n",
            "[0.88, 0.8809509969363818, 0.8816437825871789, 0.8803352989854011, 0.8843520672990872, 0.945969340106148, 0.9024833041561305, 0.9109349038537885]\n",
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_18 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.2159 - accuracy: 0.3886 - val_loss: 1.1480 - val_accuracy: 0.3178\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1121 - accuracy: 0.3410 - val_loss: 1.1029 - val_accuracy: 0.3178\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0916 - accuracy: 0.3476 - val_loss: 1.0877 - val_accuracy: 0.3178\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0805 - accuracy: 0.4105 - val_loss: 1.0765 - val_accuracy: 0.4444\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0677 - accuracy: 0.5010 - val_loss: 1.0619 - val_accuracy: 0.5778\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0565 - accuracy: 0.5448 - val_loss: 1.0526 - val_accuracy: 0.5200\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0454 - accuracy: 0.5505 - val_loss: 1.0415 - val_accuracy: 0.6267\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0344 - accuracy: 0.5943 - val_loss: 1.0318 - val_accuracy: 0.5178\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0223 - accuracy: 0.5800 - val_loss: 1.0197 - val_accuracy: 0.7622\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0103 - accuracy: 0.6752 - val_loss: 1.0093 - val_accuracy: 0.5444\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9962 - accuracy: 0.5790 - val_loss: 0.9934 - val_accuracy: 0.5289\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9814 - accuracy: 0.6438 - val_loss: 0.9804 - val_accuracy: 0.5489\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9666 - accuracy: 0.6124 - val_loss: 0.9646 - val_accuracy: 0.6000\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9526 - accuracy: 0.6629 - val_loss: 0.9512 - val_accuracy: 0.8267\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9392 - accuracy: 0.7143 - val_loss: 0.9400 - val_accuracy: 0.5489\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9250 - accuracy: 0.6657 - val_loss: 0.9255 - val_accuracy: 0.6422\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9103 - accuracy: 0.6695 - val_loss: 0.9115 - val_accuracy: 0.6000\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8958 - accuracy: 0.6924 - val_loss: 0.8977 - val_accuracy: 0.7667\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8816 - accuracy: 0.7410 - val_loss: 0.8840 - val_accuracy: 0.7600\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8674 - accuracy: 0.7762 - val_loss: 0.8738 - val_accuracy: 0.6244\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8520 - accuracy: 0.7343 - val_loss: 0.8643 - val_accuracy: 0.7378\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8405 - accuracy: 0.7714 - val_loss: 0.8471 - val_accuracy: 0.6978\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8254 - accuracy: 0.7962 - val_loss: 0.8333 - val_accuracy: 0.7333\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8135 - accuracy: 0.7457 - val_loss: 0.8209 - val_accuracy: 0.7733\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8019 - accuracy: 0.7695 - val_loss: 0.8150 - val_accuracy: 0.7756\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7887 - accuracy: 0.7600 - val_loss: 0.7972 - val_accuracy: 0.7667\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.7657 - val_loss: 0.7826 - val_accuracy: 0.7422\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7608 - accuracy: 0.7495 - val_loss: 0.7718 - val_accuracy: 0.7400\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7523 - accuracy: 0.7486 - val_loss: 0.7686 - val_accuracy: 0.7556\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7446 - accuracy: 0.7619 - val_loss: 0.7616 - val_accuracy: 0.7044\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7361 - accuracy: 0.7410 - val_loss: 0.7518 - val_accuracy: 0.7333\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7308 - accuracy: 0.7371 - val_loss: 0.7445 - val_accuracy: 0.7378\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.7371 - val_loss: 0.7383 - val_accuracy: 0.7200\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7201 - accuracy: 0.7438 - val_loss: 0.7418 - val_accuracy: 0.7244\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7177 - accuracy: 0.7448 - val_loss: 0.7298 - val_accuracy: 0.7333\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7120 - accuracy: 0.7495 - val_loss: 0.7257 - val_accuracy: 0.7333\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7062 - accuracy: 0.7457 - val_loss: 0.7338 - val_accuracy: 0.7311\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7020 - accuracy: 0.7486 - val_loss: 0.7341 - val_accuracy: 0.7178\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.7505 - val_loss: 0.7138 - val_accuracy: 0.7533\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6932 - accuracy: 0.7448 - val_loss: 0.7135 - val_accuracy: 0.7244\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.7514 - val_loss: 0.7139 - val_accuracy: 0.7400\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6856 - accuracy: 0.7619 - val_loss: 0.7067 - val_accuracy: 0.7267\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.7581 - val_loss: 0.6966 - val_accuracy: 0.7378\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.7619 - val_loss: 0.7029 - val_accuracy: 0.7267\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6717 - accuracy: 0.7619 - val_loss: 0.6922 - val_accuracy: 0.7578\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6646 - accuracy: 0.7724 - val_loss: 0.6867 - val_accuracy: 0.7467\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6632 - accuracy: 0.7714 - val_loss: 0.6837 - val_accuracy: 0.7422\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6574 - accuracy: 0.7724 - val_loss: 0.6744 - val_accuracy: 0.7600\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.7867 - val_loss: 0.6874 - val_accuracy: 0.7422\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6478 - accuracy: 0.7810 - val_loss: 0.6646 - val_accuracy: 0.7644\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 1s 18ms/step - loss: 0.6434 - accuracy: 0.7829 - val_loss: 0.6644 - val_accuracy: 0.7556\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.6363 - accuracy: 0.7800 - val_loss: 0.6590 - val_accuracy: 0.7711\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6353 - accuracy: 0.7800 - val_loss: 0.6526 - val_accuracy: 0.7778\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.7990 - val_loss: 0.6544 - val_accuracy: 0.7622\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6221 - accuracy: 0.7924 - val_loss: 0.6492 - val_accuracy: 0.7667\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6206 - accuracy: 0.7943 - val_loss: 0.6440 - val_accuracy: 0.7578\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6168 - accuracy: 0.7914 - val_loss: 0.6347 - val_accuracy: 0.7778\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6112 - accuracy: 0.7990 - val_loss: 0.6356 - val_accuracy: 0.7756\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6025 - accuracy: 0.8114 - val_loss: 0.6225 - val_accuracy: 0.7956\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.8067 - val_loss: 0.6244 - val_accuracy: 0.7844\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5926 - accuracy: 0.8181 - val_loss: 0.6151 - val_accuracy: 0.7933\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5892 - accuracy: 0.8152 - val_loss: 0.6016 - val_accuracy: 0.7867\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.8181 - val_loss: 0.5994 - val_accuracy: 0.7822\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5732 - accuracy: 0.8162 - val_loss: 0.6020 - val_accuracy: 0.7911\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.8152 - val_loss: 0.5833 - val_accuracy: 0.7933\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.8229 - val_loss: 0.5779 - val_accuracy: 0.8067\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.8333 - val_loss: 0.5858 - val_accuracy: 0.7933\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.8314 - val_loss: 0.5681 - val_accuracy: 0.8000\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.8343 - val_loss: 0.5676 - val_accuracy: 0.7978\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5391 - accuracy: 0.8438 - val_loss: 0.5534 - val_accuracy: 0.8200\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5321 - accuracy: 0.8448 - val_loss: 0.5524 - val_accuracy: 0.8133\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5253 - accuracy: 0.8448 - val_loss: 0.5446 - val_accuracy: 0.8378\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5201 - accuracy: 0.8505 - val_loss: 0.5385 - val_accuracy: 0.8156\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5175 - accuracy: 0.8448 - val_loss: 0.5329 - val_accuracy: 0.8311\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5084 - accuracy: 0.8590 - val_loss: 0.5344 - val_accuracy: 0.8222\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8590 - val_loss: 0.5199 - val_accuracy: 0.8333\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4969 - accuracy: 0.8657 - val_loss: 0.5331 - val_accuracy: 0.8333\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4933 - accuracy: 0.8648 - val_loss: 0.5113 - val_accuracy: 0.8400\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4892 - accuracy: 0.8648 - val_loss: 0.5032 - val_accuracy: 0.8467\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.8619 - val_loss: 0.5091 - val_accuracy: 0.8378\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[127  13   8]\n",
            " [ 12 129   2]\n",
            " [ 24  14 121]]\n",
            "\n",
            "P-Score: 0.843, R-Score: 0.840, F-Score: 0.838\n",
            "[0.8377777777777777, 0.8432427677849867, 0.8404040998380621, 0.8380264233453394, 0.8694514050474316, 0.9070750096808727, 0.8633210140698957, 0.8799491429327334]\n",
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_21 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.3503 - accuracy: 0.3352 - val_loss: 1.1891 - val_accuracy: 0.3289\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1332 - accuracy: 0.3352 - val_loss: 1.0941 - val_accuracy: 0.3244\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0823 - accuracy: 0.4162 - val_loss: 1.0721 - val_accuracy: 0.5911\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0657 - accuracy: 0.5257 - val_loss: 1.0626 - val_accuracy: 0.4844\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0524 - accuracy: 0.5343 - val_loss: 1.0445 - val_accuracy: 0.5978\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0394 - accuracy: 0.5581 - val_loss: 1.0326 - val_accuracy: 0.6000\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0267 - accuracy: 0.5952 - val_loss: 1.0213 - val_accuracy: 0.5933\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0102 - accuracy: 0.5514 - val_loss: 1.0005 - val_accuracy: 0.4711\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9906 - accuracy: 0.6114 - val_loss: 0.9811 - val_accuracy: 0.6711\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9709 - accuracy: 0.6533 - val_loss: 0.9689 - val_accuracy: 0.6578\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9524 - accuracy: 0.6971 - val_loss: 0.9530 - val_accuracy: 0.6689\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9299 - accuracy: 0.7219 - val_loss: 0.9269 - val_accuracy: 0.7467\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9075 - accuracy: 0.7324 - val_loss: 0.9103 - val_accuracy: 0.7467\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8893 - accuracy: 0.7476 - val_loss: 0.8933 - val_accuracy: 0.7333\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8717 - accuracy: 0.7438 - val_loss: 0.8678 - val_accuracy: 0.7489\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8535 - accuracy: 0.7552 - val_loss: 0.8483 - val_accuracy: 0.7044\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8385 - accuracy: 0.7448 - val_loss: 0.8343 - val_accuracy: 0.7444\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.7495 - val_loss: 0.8198 - val_accuracy: 0.7444\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8083 - accuracy: 0.7467 - val_loss: 0.8061 - val_accuracy: 0.7089\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7945 - accuracy: 0.7476 - val_loss: 0.7974 - val_accuracy: 0.7733\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7815 - accuracy: 0.7581 - val_loss: 0.7824 - val_accuracy: 0.7600\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.7638 - val_loss: 0.7690 - val_accuracy: 0.7467\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7560 - accuracy: 0.7590 - val_loss: 0.7625 - val_accuracy: 0.7711\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7438 - accuracy: 0.7610 - val_loss: 0.7479 - val_accuracy: 0.7533\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7324 - accuracy: 0.7619 - val_loss: 0.7384 - val_accuracy: 0.7378\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7221 - accuracy: 0.7724 - val_loss: 0.7353 - val_accuracy: 0.7711\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7126 - accuracy: 0.7790 - val_loss: 0.7292 - val_accuracy: 0.7578\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7040 - accuracy: 0.7800 - val_loss: 0.7141 - val_accuracy: 0.7422\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.7781 - val_loss: 0.7101 - val_accuracy: 0.7733\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6871 - accuracy: 0.7733 - val_loss: 0.6970 - val_accuracy: 0.7800\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6777 - accuracy: 0.7819 - val_loss: 0.7049 - val_accuracy: 0.7578\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7819 - val_loss: 0.6951 - val_accuracy: 0.7511\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6676 - accuracy: 0.7867 - val_loss: 0.6764 - val_accuracy: 0.7867\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.7829 - val_loss: 0.6738 - val_accuracy: 0.7800\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.7819 - val_loss: 0.6651 - val_accuracy: 0.7822\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.7971 - val_loss: 0.6615 - val_accuracy: 0.7800\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.8000 - val_loss: 0.6546 - val_accuracy: 0.7956\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.7990 - val_loss: 0.6504 - val_accuracy: 0.7978\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.8057 - val_loss: 0.6460 - val_accuracy: 0.7956\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6210 - accuracy: 0.8114 - val_loss: 0.6498 - val_accuracy: 0.7778\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6185 - accuracy: 0.8086 - val_loss: 0.6355 - val_accuracy: 0.7911\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6109 - accuracy: 0.8124 - val_loss: 0.6300 - val_accuracy: 0.8000\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.8229 - val_loss: 0.6208 - val_accuracy: 0.8022\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5999 - accuracy: 0.8152 - val_loss: 0.6199 - val_accuracy: 0.8022\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.8143 - val_loss: 0.6116 - val_accuracy: 0.8044\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5877 - accuracy: 0.8257 - val_loss: 0.6112 - val_accuracy: 0.8067\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5842 - accuracy: 0.8190 - val_loss: 0.5997 - val_accuracy: 0.8156\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5785 - accuracy: 0.8276 - val_loss: 0.6096 - val_accuracy: 0.7911\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5739 - accuracy: 0.8267 - val_loss: 0.5910 - val_accuracy: 0.8133\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5674 - accuracy: 0.8305 - val_loss: 0.5840 - val_accuracy: 0.8200\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.8352 - val_loss: 0.5824 - val_accuracy: 0.8267\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.8333 - val_loss: 0.5763 - val_accuracy: 0.8178\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5522 - accuracy: 0.8371 - val_loss: 0.5723 - val_accuracy: 0.8178\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5466 - accuracy: 0.8333 - val_loss: 0.5639 - val_accuracy: 0.8311\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5393 - accuracy: 0.8400 - val_loss: 0.5841 - val_accuracy: 0.8022\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5379 - accuracy: 0.8457 - val_loss: 0.5528 - val_accuracy: 0.8378\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.8448 - val_loss: 0.5500 - val_accuracy: 0.8244\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5238 - accuracy: 0.8524 - val_loss: 0.5419 - val_accuracy: 0.8400\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5204 - accuracy: 0.8505 - val_loss: 0.5545 - val_accuracy: 0.8200\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5143 - accuracy: 0.8448 - val_loss: 0.5325 - val_accuracy: 0.8467\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5098 - accuracy: 0.8505 - val_loss: 0.5282 - val_accuracy: 0.8489\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5040 - accuracy: 0.8590 - val_loss: 0.5221 - val_accuracy: 0.8489\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.8524 - val_loss: 0.5200 - val_accuracy: 0.8444\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4953 - accuracy: 0.8552 - val_loss: 0.5153 - val_accuracy: 0.8422\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4896 - accuracy: 0.8629 - val_loss: 0.5107 - val_accuracy: 0.8444\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4845 - accuracy: 0.8590 - val_loss: 0.5050 - val_accuracy: 0.8444\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.8495 - val_loss: 0.5255 - val_accuracy: 0.8222\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4746 - accuracy: 0.8629 - val_loss: 0.4946 - val_accuracy: 0.8444\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.8619 - val_loss: 0.4866 - val_accuracy: 0.8511\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4636 - accuracy: 0.8562 - val_loss: 0.4832 - val_accuracy: 0.8511\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4583 - accuracy: 0.8638 - val_loss: 0.4957 - val_accuracy: 0.8356\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8686 - val_loss: 0.4770 - val_accuracy: 0.8489\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4478 - accuracy: 0.8629 - val_loss: 0.4712 - val_accuracy: 0.8622\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4473 - accuracy: 0.8619 - val_loss: 0.4635 - val_accuracy: 0.8533\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8705 - val_loss: 0.5005 - val_accuracy: 0.8356\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.8686 - val_loss: 0.4611 - val_accuracy: 0.8467\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8714 - val_loss: 0.4516 - val_accuracy: 0.8533\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8733 - val_loss: 0.4525 - val_accuracy: 0.8600\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.8743 - val_loss: 0.4417 - val_accuracy: 0.8489\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4179 - accuracy: 0.8676 - val_loss: 0.4437 - val_accuracy: 0.8556\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[128  12   8]\n",
            " [ 16 120   7]\n",
            " [ 22   0 137]]\n",
            "\n",
            "P-Score: 0.860, R-Score: 0.855, F-Score: 0.856\n",
            "[0.8555555555555555, 0.8604970119713302, 0.8552203080504968, 0.856347611945949, 0.8695185251476643, 0.9000364456390515, 0.9050444141866043, 0.89153312832444]\n",
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_24 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0947 - accuracy: 0.3867 - val_loss: 1.0877 - val_accuracy: 0.5444\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0854 - accuracy: 0.5400 - val_loss: 1.0804 - val_accuracy: 0.5356\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0781 - accuracy: 0.5524 - val_loss: 1.0732 - val_accuracy: 0.5778\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0696 - accuracy: 0.5857 - val_loss: 1.0649 - val_accuracy: 0.7400\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0607 - accuracy: 0.6514 - val_loss: 1.0545 - val_accuracy: 0.7267\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0495 - accuracy: 0.6895 - val_loss: 1.0421 - val_accuracy: 0.7400\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0362 - accuracy: 0.7019 - val_loss: 1.0289 - val_accuracy: 0.7511\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0198 - accuracy: 0.7219 - val_loss: 1.0142 - val_accuracy: 0.6889\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0044 - accuracy: 0.7286 - val_loss: 0.9984 - val_accuracy: 0.7556\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9884 - accuracy: 0.7714 - val_loss: 0.9837 - val_accuracy: 0.7400\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9708 - accuracy: 0.7724 - val_loss: 0.9666 - val_accuracy: 0.7333\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9520 - accuracy: 0.7533 - val_loss: 0.9459 - val_accuracy: 0.7400\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9322 - accuracy: 0.7181 - val_loss: 0.9287 - val_accuracy: 0.7467\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9128 - accuracy: 0.7448 - val_loss: 0.9104 - val_accuracy: 0.7489\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8905 - accuracy: 0.7238 - val_loss: 0.8865 - val_accuracy: 0.7356\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8688 - accuracy: 0.7124 - val_loss: 0.8611 - val_accuracy: 0.6689\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8445 - accuracy: 0.6867 - val_loss: 0.8438 - val_accuracy: 0.7311\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8276 - accuracy: 0.7095 - val_loss: 0.8270 - val_accuracy: 0.7289\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8112 - accuracy: 0.7295 - val_loss: 0.8107 - val_accuracy: 0.7267\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7964 - accuracy: 0.7276 - val_loss: 0.8050 - val_accuracy: 0.7400\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.7657 - val_loss: 0.7816 - val_accuracy: 0.7133\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7679 - accuracy: 0.7467 - val_loss: 0.7692 - val_accuracy: 0.7311\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7538 - accuracy: 0.7562 - val_loss: 0.7583 - val_accuracy: 0.7200\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7405 - accuracy: 0.7543 - val_loss: 0.7455 - val_accuracy: 0.7422\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7283 - accuracy: 0.7629 - val_loss: 0.7416 - val_accuracy: 0.7489\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7181 - accuracy: 0.7648 - val_loss: 0.7364 - val_accuracy: 0.7511\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.7657 - val_loss: 0.7156 - val_accuracy: 0.7578\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6920 - accuracy: 0.7810 - val_loss: 0.7009 - val_accuracy: 0.7511\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.7810 - val_loss: 0.6909 - val_accuracy: 0.7622\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6689 - accuracy: 0.7819 - val_loss: 0.6786 - val_accuracy: 0.7622\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.7876 - val_loss: 0.6666 - val_accuracy: 0.7667\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6390 - accuracy: 0.7962 - val_loss: 0.6607 - val_accuracy: 0.7644\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6243 - accuracy: 0.8057 - val_loss: 0.6476 - val_accuracy: 0.7733\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.8124 - val_loss: 0.6274 - val_accuracy: 0.7889\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6062 - accuracy: 0.8162 - val_loss: 0.6203 - val_accuracy: 0.7800\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5912 - accuracy: 0.8257 - val_loss: 0.6091 - val_accuracy: 0.7889\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.8248 - val_loss: 0.5975 - val_accuracy: 0.7867\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5699 - accuracy: 0.8324 - val_loss: 0.5927 - val_accuracy: 0.7911\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5596 - accuracy: 0.8305 - val_loss: 0.5852 - val_accuracy: 0.7911\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.8257 - val_loss: 0.5724 - val_accuracy: 0.7933\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5386 - accuracy: 0.8324 - val_loss: 0.5717 - val_accuracy: 0.8000\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5311 - accuracy: 0.8314 - val_loss: 0.5485 - val_accuracy: 0.8200\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5209 - accuracy: 0.8419 - val_loss: 0.5419 - val_accuracy: 0.8178\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.8486 - val_loss: 0.5370 - val_accuracy: 0.8067\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5035 - accuracy: 0.8438 - val_loss: 0.5235 - val_accuracy: 0.8178\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4898 - accuracy: 0.8486 - val_loss: 0.5235 - val_accuracy: 0.8067\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4807 - accuracy: 0.8590 - val_loss: 0.5084 - val_accuracy: 0.8200\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4732 - accuracy: 0.8590 - val_loss: 0.5064 - val_accuracy: 0.8156\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.8543 - val_loss: 0.4947 - val_accuracy: 0.8244\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8543 - val_loss: 0.4822 - val_accuracy: 0.8311\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4469 - accuracy: 0.8667 - val_loss: 0.4805 - val_accuracy: 0.8311\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4405 - accuracy: 0.8629 - val_loss: 0.4668 - val_accuracy: 0.8267\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4314 - accuracy: 0.8562 - val_loss: 0.4805 - val_accuracy: 0.8311\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4259 - accuracy: 0.8581 - val_loss: 0.4522 - val_accuracy: 0.8333\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4176 - accuracy: 0.8657 - val_loss: 0.4543 - val_accuracy: 0.8356\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4121 - accuracy: 0.8676 - val_loss: 0.4555 - val_accuracy: 0.8333\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4085 - accuracy: 0.8590 - val_loss: 0.4341 - val_accuracy: 0.8511\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4014 - accuracy: 0.8648 - val_loss: 0.4397 - val_accuracy: 0.8400\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3949 - accuracy: 0.8610 - val_loss: 0.4376 - val_accuracy: 0.8400\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8667 - val_loss: 0.4311 - val_accuracy: 0.8467\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3838 - accuracy: 0.8667 - val_loss: 0.4176 - val_accuracy: 0.8489\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8752 - val_loss: 0.4103 - val_accuracy: 0.8511\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3708 - accuracy: 0.8667 - val_loss: 0.4145 - val_accuracy: 0.8489\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3675 - accuracy: 0.8733 - val_loss: 0.4055 - val_accuracy: 0.8422\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8800 - val_loss: 0.3930 - val_accuracy: 0.8511\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3581 - accuracy: 0.8733 - val_loss: 0.3907 - val_accuracy: 0.8600\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3548 - accuracy: 0.8724 - val_loss: 0.3920 - val_accuracy: 0.8511\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3523 - accuracy: 0.8733 - val_loss: 0.3864 - val_accuracy: 0.8556\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3467 - accuracy: 0.8762 - val_loss: 0.3910 - val_accuracy: 0.8533\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.8819 - val_loss: 0.3765 - val_accuracy: 0.8578\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3357 - accuracy: 0.8724 - val_loss: 0.3759 - val_accuracy: 0.8600\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3409 - accuracy: 0.8752 - val_loss: 0.3715 - val_accuracy: 0.8533\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8819 - val_loss: 0.3653 - val_accuracy: 0.8578\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3288 - accuracy: 0.8886 - val_loss: 0.3666 - val_accuracy: 0.8533\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3278 - accuracy: 0.8771 - val_loss: 0.3586 - val_accuracy: 0.8622\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3232 - accuracy: 0.8800 - val_loss: 0.3705 - val_accuracy: 0.8622\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3201 - accuracy: 0.8781 - val_loss: 0.3792 - val_accuracy: 0.8511\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.8867 - val_loss: 0.3548 - val_accuracy: 0.8600\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3182 - accuracy: 0.8838 - val_loss: 0.3511 - val_accuracy: 0.8600\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3137 - accuracy: 0.8829 - val_loss: 0.3646 - val_accuracy: 0.8600\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[127  11  10]\n",
            " [ 10 132   1]\n",
            " [ 20  11 128]]\n",
            "\n",
            "P-Score: 0.862, R-Score: 0.862, F-Score: 0.860\n",
            "[0.86, 0.8623077879825348, 0.8620721592419706, 0.8602453922731182, 0.8793851798818687, 0.9257078426459534, 0.8836153796278285, 0.8962361340518835]\n",
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_27 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 2s 26ms/step - loss: 1.0770 - accuracy: 0.2724 - val_loss: 1.0660 - val_accuracy: 0.3956\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0569 - accuracy: 0.4295 - val_loss: 1.0566 - val_accuracy: 0.4044\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0447 - accuracy: 0.5143 - val_loss: 1.0413 - val_accuracy: 0.4822\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0312 - accuracy: 0.5229 - val_loss: 1.0276 - val_accuracy: 0.5089\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0181 - accuracy: 0.5333 - val_loss: 1.0149 - val_accuracy: 0.5178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0040 - accuracy: 0.5352 - val_loss: 1.0007 - val_accuracy: 0.5111\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.5819 - val_loss: 0.9891 - val_accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9746 - accuracy: 0.5638 - val_loss: 0.9712 - val_accuracy: 0.6978\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9580 - accuracy: 0.6305 - val_loss: 0.9542 - val_accuracy: 0.6467\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9401 - accuracy: 0.6257 - val_loss: 0.9368 - val_accuracy: 0.7378\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9206 - accuracy: 0.6524 - val_loss: 0.9180 - val_accuracy: 0.6756\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9008 - accuracy: 0.6543 - val_loss: 0.9007 - val_accuracy: 0.7156\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8848 - accuracy: 0.6848 - val_loss: 0.8847 - val_accuracy: 0.6822\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8697 - accuracy: 0.6838 - val_loss: 0.8718 - val_accuracy: 0.6689\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8549 - accuracy: 0.6733 - val_loss: 0.8597 - val_accuracy: 0.6867\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8418 - accuracy: 0.6857 - val_loss: 0.8443 - val_accuracy: 0.6578\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8285 - accuracy: 0.6857 - val_loss: 0.8330 - val_accuracy: 0.6533\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8164 - accuracy: 0.6762 - val_loss: 0.8252 - val_accuracy: 0.6867\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8050 - accuracy: 0.6819 - val_loss: 0.8200 - val_accuracy: 0.6644\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7955 - accuracy: 0.6848 - val_loss: 0.8041 - val_accuracy: 0.6933\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7856 - accuracy: 0.6895 - val_loss: 0.7964 - val_accuracy: 0.6867\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7773 - accuracy: 0.6933 - val_loss: 0.7962 - val_accuracy: 0.6800\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7696 - accuracy: 0.6990 - val_loss: 0.7849 - val_accuracy: 0.6756\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7650 - accuracy: 0.6914 - val_loss: 0.7799 - val_accuracy: 0.6756\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.6914 - val_loss: 0.7739 - val_accuracy: 0.6667\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.7057 - val_loss: 0.7725 - val_accuracy: 0.6622\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7465 - accuracy: 0.7010 - val_loss: 0.7628 - val_accuracy: 0.7000\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7406 - accuracy: 0.7029 - val_loss: 0.7584 - val_accuracy: 0.7022\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7348 - accuracy: 0.7114 - val_loss: 0.7603 - val_accuracy: 0.6756\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7316 - accuracy: 0.7019 - val_loss: 0.7508 - val_accuracy: 0.6978\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7279 - accuracy: 0.7114 - val_loss: 0.7477 - val_accuracy: 0.7000\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7248 - accuracy: 0.7029 - val_loss: 0.7432 - val_accuracy: 0.7044\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7206 - accuracy: 0.7029 - val_loss: 0.7532 - val_accuracy: 0.6822\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7170 - accuracy: 0.7219 - val_loss: 0.7405 - val_accuracy: 0.6822\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7127 - accuracy: 0.7295 - val_loss: 0.7385 - val_accuracy: 0.6889\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.7152 - val_loss: 0.7321 - val_accuracy: 0.7022\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.7200 - val_loss: 0.7331 - val_accuracy: 0.7022\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7013 - accuracy: 0.7219 - val_loss: 0.7250 - val_accuracy: 0.7133\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6979 - accuracy: 0.7276 - val_loss: 0.7247 - val_accuracy: 0.7156\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6958 - accuracy: 0.7248 - val_loss: 0.7199 - val_accuracy: 0.7133\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6923 - accuracy: 0.7362 - val_loss: 0.7296 - val_accuracy: 0.6933\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6894 - accuracy: 0.7333 - val_loss: 0.7105 - val_accuracy: 0.7267\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6853 - accuracy: 0.7476 - val_loss: 0.7084 - val_accuracy: 0.7267\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6813 - accuracy: 0.7438 - val_loss: 0.7078 - val_accuracy: 0.7311\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6763 - accuracy: 0.7610 - val_loss: 0.7041 - val_accuracy: 0.7244\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6731 - accuracy: 0.7562 - val_loss: 0.6987 - val_accuracy: 0.7267\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6699 - accuracy: 0.7457 - val_loss: 0.6943 - val_accuracy: 0.7444\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6658 - accuracy: 0.7590 - val_loss: 0.6899 - val_accuracy: 0.7489\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.7610 - val_loss: 0.7077 - val_accuracy: 0.7022\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6564 - accuracy: 0.7590 - val_loss: 0.6810 - val_accuracy: 0.7533\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.7724 - val_loss: 0.6749 - val_accuracy: 0.7644\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.7686 - val_loss: 0.6783 - val_accuracy: 0.7311\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6407 - accuracy: 0.7762 - val_loss: 0.6667 - val_accuracy: 0.7600\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6399 - accuracy: 0.7829 - val_loss: 0.6612 - val_accuracy: 0.7667\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6311 - accuracy: 0.7886 - val_loss: 0.6622 - val_accuracy: 0.7467\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7762 - val_loss: 0.6527 - val_accuracy: 0.7711\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6243 - accuracy: 0.7886 - val_loss: 0.6467 - val_accuracy: 0.7711\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6171 - accuracy: 0.8076 - val_loss: 0.6438 - val_accuracy: 0.7689\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6137 - accuracy: 0.8029 - val_loss: 0.6385 - val_accuracy: 0.7756\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6032 - accuracy: 0.8095 - val_loss: 0.6382 - val_accuracy: 0.7733\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5994 - accuracy: 0.8067 - val_loss: 0.6313 - val_accuracy: 0.7711\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5975 - accuracy: 0.8048 - val_loss: 0.6202 - val_accuracy: 0.7778\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5898 - accuracy: 0.8133 - val_loss: 0.6198 - val_accuracy: 0.7733\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5836 - accuracy: 0.8124 - val_loss: 0.6091 - val_accuracy: 0.7889\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.8162 - val_loss: 0.6131 - val_accuracy: 0.7733\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5727 - accuracy: 0.8181 - val_loss: 0.6007 - val_accuracy: 0.7844\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5643 - accuracy: 0.8200 - val_loss: 0.6190 - val_accuracy: 0.7378\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5593 - accuracy: 0.8248 - val_loss: 0.5796 - val_accuracy: 0.8000\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.8295 - val_loss: 0.5832 - val_accuracy: 0.7822\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.8381 - val_loss: 0.5655 - val_accuracy: 0.8044\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5359 - accuracy: 0.8324 - val_loss: 0.5700 - val_accuracy: 0.7889\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.8381 - val_loss: 0.5530 - val_accuracy: 0.8044\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5228 - accuracy: 0.8419 - val_loss: 0.5456 - val_accuracy: 0.8178\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5124 - accuracy: 0.8390 - val_loss: 0.5387 - val_accuracy: 0.8156\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5099 - accuracy: 0.8476 - val_loss: 0.5327 - val_accuracy: 0.8222\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5013 - accuracy: 0.8533 - val_loss: 0.5481 - val_accuracy: 0.7911\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4932 - accuracy: 0.8467 - val_loss: 0.5357 - val_accuracy: 0.8000\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4905 - accuracy: 0.8533 - val_loss: 0.5304 - val_accuracy: 0.8000\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.8610 - val_loss: 0.5136 - val_accuracy: 0.8222\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8571 - val_loss: 0.5027 - val_accuracy: 0.8267\n",
            "15/15 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[115  23  10]\n",
            " [ 13 113  17]\n",
            " [ 13   2 144]]\n",
            "\n",
            "P-Score: 0.826, R-Score: 0.824, F-Score: 0.824\n",
            "[0.8266666666666667, 0.8255162265824908, 0.8242990648651025, 0.8242818287419255, 0.8454671558976194, 0.8543882827270449, 0.9064384361019258, 0.8687646249088634]\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.842222   0.854260  0.839204  0.841415  0.865939  0.869479  0.903845   \n",
            "1  0.851111   0.853119  0.850873  0.851450  0.860972  0.900515  0.903326   \n",
            "2  0.806667   0.805894  0.805274  0.805464  0.840635  0.844138  0.878137   \n",
            "3  0.726667   0.758401  0.730588  0.729913  0.836853  0.777647  0.778966   \n",
            "4  0.871111   0.876065  0.869507  0.871291  0.872561  0.913305  0.921027   \n",
            "5  0.880000   0.880951  0.881644  0.880335  0.884352  0.945969  0.902483   \n",
            "6  0.837778   0.843243  0.840404  0.838026  0.869451  0.907075  0.863321   \n",
            "7  0.855556   0.860497  0.855220  0.856348  0.869519  0.900036  0.905044   \n",
            "8  0.860000   0.862308  0.862072  0.860245  0.879385  0.925708  0.883615   \n",
            "9  0.826667   0.825516  0.824299  0.824282  0.845467  0.854388  0.906438   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.879754  \n",
            "1       0.888271  \n",
            "2       0.854303  \n",
            "3       0.797822  \n",
            "4       0.902298  \n",
            "5       0.910935  \n",
            "6       0.879949  \n",
            "7       0.891533  \n",
            "8       0.896236  \n",
            "9       0.868765  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.6263859e-02 4.8990872e-02 4.7452664e-03]\n",
            " [9.4615779e-04 9.0840720e-02 8.2131308e-03]\n",
            " [8.1326596e-02 1.5675958e-02 2.9974501e-03]\n",
            " ...\n",
            " [6.0714344e-03 2.0742193e-02 7.3186383e-02]\n",
            " [4.5632558e-05 5.4841959e-03 9.4470166e-02]\n",
            " [2.9340828e-02 2.6167195e-02 4.4491984e-02]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'MLP_ADAM'\n",
        "NAME = 'Landsat9_DATA'\n",
        "optimiser_type = 'adam'\n",
        "experimental_runs = 10\n",
        "\n",
        "best_model, best_history, avg_y_pred, df = MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "best_model.save('Best_model_{}_{}'.format(NAME, Model_name))\n",
        "plot_metric(best_history, \"loss\")\n",
        "print(\"\")\n",
        "plot_metric(best_history, \"accuracy\")\n",
        "# plot_AUC_ROC(best_model, test_x, test_y, 3, label_names)\n",
        "# print(\"\")\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "print(avg_y_pred)\n",
        "test_y_dummies = test_y.argmax(axis = 1)\n",
        "plot_avg_AUC_ROC(avg_y_pred, test_y_dummies, 3, label_names)\n",
        "print(\"\")\n",
        "avg_y_pred = avg_y_pred.argmax(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EgPKeKebQknW",
        "outputId": "3c4e0719-6315-4ee6-c80b-1a04709fd048"
      },
      "id": "EgPKeKebQknW",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_30 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1283 - accuracy: 0.3314 - val_loss: 1.0927 - val_accuracy: 0.3800\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0858 - accuracy: 0.3152 - val_loss: 1.0751 - val_accuracy: 0.2200\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0670 - accuracy: 0.3800 - val_loss: 1.0603 - val_accuracy: 0.4867\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0476 - accuracy: 0.5152 - val_loss: 1.0421 - val_accuracy: 0.5356\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0277 - accuracy: 0.5476 - val_loss: 1.0231 - val_accuracy: 0.5067\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0074 - accuracy: 0.5762 - val_loss: 1.0036 - val_accuracy: 0.5356\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9877 - accuracy: 0.5762 - val_loss: 0.9827 - val_accuracy: 0.5356\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9676 - accuracy: 0.6181 - val_loss: 0.9633 - val_accuracy: 0.5511\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9457 - accuracy: 0.5990 - val_loss: 0.9426 - val_accuracy: 0.5622\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9237 - accuracy: 0.6562 - val_loss: 0.9206 - val_accuracy: 0.6356\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9012 - accuracy: 0.7086 - val_loss: 0.9009 - val_accuracy: 0.6778\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8795 - accuracy: 0.6933 - val_loss: 0.8798 - val_accuracy: 0.6533\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8591 - accuracy: 0.6981 - val_loss: 0.8608 - val_accuracy: 0.6800\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8401 - accuracy: 0.7200 - val_loss: 0.8435 - val_accuracy: 0.6978\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8242 - accuracy: 0.7162 - val_loss: 0.8277 - val_accuracy: 0.7133\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8076 - accuracy: 0.7324 - val_loss: 0.8157 - val_accuracy: 0.6756\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7944 - accuracy: 0.7124 - val_loss: 0.8033 - val_accuracy: 0.7133\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7812 - accuracy: 0.7276 - val_loss: 0.7947 - val_accuracy: 0.7111\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7708 - accuracy: 0.7333 - val_loss: 0.7835 - val_accuracy: 0.7156\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7592 - accuracy: 0.7171 - val_loss: 0.7755 - val_accuracy: 0.6956\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7504 - accuracy: 0.7305 - val_loss: 0.7686 - val_accuracy: 0.7044\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7414 - accuracy: 0.7448 - val_loss: 0.7596 - val_accuracy: 0.7044\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7328 - accuracy: 0.7371 - val_loss: 0.7541 - val_accuracy: 0.7222\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7269 - accuracy: 0.7390 - val_loss: 0.7458 - val_accuracy: 0.7200\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.7400 - val_loss: 0.7438 - val_accuracy: 0.7156\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7134 - accuracy: 0.7438 - val_loss: 0.7408 - val_accuracy: 0.7111\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7087 - accuracy: 0.7571 - val_loss: 0.7325 - val_accuracy: 0.7222\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7052 - accuracy: 0.7438 - val_loss: 0.7242 - val_accuracy: 0.7333\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6983 - accuracy: 0.7581 - val_loss: 0.7204 - val_accuracy: 0.7289\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6907 - accuracy: 0.7571 - val_loss: 0.7139 - val_accuracy: 0.7422\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6848 - accuracy: 0.7600 - val_loss: 0.7086 - val_accuracy: 0.7444\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6817 - accuracy: 0.7867 - val_loss: 0.7020 - val_accuracy: 0.7556\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6738 - accuracy: 0.7771 - val_loss: 0.7003 - val_accuracy: 0.7333\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.7800 - val_loss: 0.6904 - val_accuracy: 0.7689\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6639 - accuracy: 0.7781 - val_loss: 0.6845 - val_accuracy: 0.7778\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6588 - accuracy: 0.8029 - val_loss: 0.6844 - val_accuracy: 0.7822\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.8029 - val_loss: 0.6742 - val_accuracy: 0.7622\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.8076 - val_loss: 0.6650 - val_accuracy: 0.7978\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6374 - accuracy: 0.8076 - val_loss: 0.6689 - val_accuracy: 0.7711\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.8162 - val_loss: 0.6484 - val_accuracy: 0.8000\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.8210 - val_loss: 0.6688 - val_accuracy: 0.7578\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6128 - accuracy: 0.8286 - val_loss: 0.6386 - val_accuracy: 0.7711\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6020 - accuracy: 0.8333 - val_loss: 0.6273 - val_accuracy: 0.8044\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5938 - accuracy: 0.8324 - val_loss: 0.6157 - val_accuracy: 0.8200\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5829 - accuracy: 0.8448 - val_loss: 0.6076 - val_accuracy: 0.8111\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5782 - accuracy: 0.8390 - val_loss: 0.6038 - val_accuracy: 0.8133\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5651 - accuracy: 0.8410 - val_loss: 0.5868 - val_accuracy: 0.8200\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5557 - accuracy: 0.8581 - val_loss: 0.5847 - val_accuracy: 0.8311\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5453 - accuracy: 0.8533 - val_loss: 0.5703 - val_accuracy: 0.8333\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5358 - accuracy: 0.8676 - val_loss: 0.5700 - val_accuracy: 0.8222\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.8667 - val_loss: 0.5573 - val_accuracy: 0.8378\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8610 - val_loss: 0.5605 - val_accuracy: 0.8222\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.8562 - val_loss: 0.5319 - val_accuracy: 0.8378\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4993 - accuracy: 0.8695 - val_loss: 0.5196 - val_accuracy: 0.8467\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8781 - val_loss: 0.5204 - val_accuracy: 0.8467\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4782 - accuracy: 0.8752 - val_loss: 0.5006 - val_accuracy: 0.8444\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4683 - accuracy: 0.8752 - val_loss: 0.4918 - val_accuracy: 0.8511\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4627 - accuracy: 0.8771 - val_loss: 0.4818 - val_accuracy: 0.8533\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4536 - accuracy: 0.8857 - val_loss: 0.4768 - val_accuracy: 0.8622\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4413 - accuracy: 0.8800 - val_loss: 0.4818 - val_accuracy: 0.8578\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8790 - val_loss: 0.4592 - val_accuracy: 0.8489\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8838 - val_loss: 0.4753 - val_accuracy: 0.8378\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8800 - val_loss: 0.4500 - val_accuracy: 0.8489\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4141 - accuracy: 0.8848 - val_loss: 0.4341 - val_accuracy: 0.8556\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4053 - accuracy: 0.8933 - val_loss: 0.4277 - val_accuracy: 0.8533\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8933 - val_loss: 0.4267 - val_accuracy: 0.8444\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3917 - accuracy: 0.8876 - val_loss: 0.4253 - val_accuracy: 0.8422\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3921 - accuracy: 0.8933 - val_loss: 0.4249 - val_accuracy: 0.8711\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3822 - accuracy: 0.8857 - val_loss: 0.4130 - val_accuracy: 0.8467\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3758 - accuracy: 0.8981 - val_loss: 0.4030 - val_accuracy: 0.8489\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3667 - accuracy: 0.8924 - val_loss: 0.3904 - val_accuracy: 0.8622\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8962 - val_loss: 0.3902 - val_accuracy: 0.8644\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8971 - val_loss: 0.3804 - val_accuracy: 0.8644\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3500 - accuracy: 0.8981 - val_loss: 0.3774 - val_accuracy: 0.8622\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.9029 - val_loss: 0.3724 - val_accuracy: 0.8644\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3472 - accuracy: 0.8952 - val_loss: 0.3674 - val_accuracy: 0.8711\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3397 - accuracy: 0.8990 - val_loss: 0.3669 - val_accuracy: 0.8667\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.9019 - val_loss: 0.3589 - val_accuracy: 0.8733\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3302 - accuracy: 0.9029 - val_loss: 0.3655 - val_accuracy: 0.8778\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.9038 - val_loss: 0.3495 - val_accuracy: 0.8711\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[123   7  18]\n",
            " [ 12 126   5]\n",
            " [ 16   0 143]]\n",
            "\n",
            "P-Score: 0.874, R-Score: 0.871, F-Score: 0.872\n",
            "[0.8711111111111111, 0.8744612468696676, 0.8705236771274508, 0.8719286510590859, 0.8691829246465008, 0.9291587890936426, 0.9101666342475525, 0.9028361159958985]\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_33 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1042 - accuracy: 0.4076 - val_loss: 1.0896 - val_accuracy: 0.3311\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0825 - accuracy: 0.4219 - val_loss: 1.0769 - val_accuracy: 0.4089\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0760 - accuracy: 0.3819 - val_loss: 1.0713 - val_accuracy: 0.4356\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0669 - accuracy: 0.4067 - val_loss: 1.0633 - val_accuracy: 0.4267\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0591 - accuracy: 0.5162 - val_loss: 1.0534 - val_accuracy: 0.5289\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0507 - accuracy: 0.5552 - val_loss: 1.0456 - val_accuracy: 0.5667\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0416 - accuracy: 0.5362 - val_loss: 1.0361 - val_accuracy: 0.5978\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0315 - accuracy: 0.6162 - val_loss: 1.0245 - val_accuracy: 0.6022\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0208 - accuracy: 0.6162 - val_loss: 1.0154 - val_accuracy: 0.6644\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0087 - accuracy: 0.6686 - val_loss: 1.0027 - val_accuracy: 0.6800\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9963 - accuracy: 0.6219 - val_loss: 0.9953 - val_accuracy: 0.6578\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9807 - accuracy: 0.7114 - val_loss: 0.9730 - val_accuracy: 0.6000\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9679 - accuracy: 0.6352 - val_loss: 0.9583 - val_accuracy: 0.6711\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9525 - accuracy: 0.6752 - val_loss: 0.9468 - val_accuracy: 0.7200\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9369 - accuracy: 0.6752 - val_loss: 0.9260 - val_accuracy: 0.6733\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9205 - accuracy: 0.6848 - val_loss: 0.9151 - val_accuracy: 0.7133\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9016 - accuracy: 0.6971 - val_loss: 0.8947 - val_accuracy: 0.7111\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8834 - accuracy: 0.6762 - val_loss: 0.8746 - val_accuracy: 0.6822\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8661 - accuracy: 0.6943 - val_loss: 0.8595 - val_accuracy: 0.7111\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8488 - accuracy: 0.7200 - val_loss: 0.8425 - val_accuracy: 0.7111\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8310 - accuracy: 0.7171 - val_loss: 0.8292 - val_accuracy: 0.7133\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8115 - accuracy: 0.7152 - val_loss: 0.8064 - val_accuracy: 0.6711\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.7048 - val_loss: 0.7850 - val_accuracy: 0.7111\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.7314 - val_loss: 0.7726 - val_accuracy: 0.7133\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7641 - accuracy: 0.7114 - val_loss: 0.7620 - val_accuracy: 0.7222\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.7286 - val_loss: 0.7599 - val_accuracy: 0.7200\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7450 - accuracy: 0.7162 - val_loss: 0.7452 - val_accuracy: 0.7244\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.7295 - val_loss: 0.7371 - val_accuracy: 0.6911\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7197 - accuracy: 0.7400 - val_loss: 0.7405 - val_accuracy: 0.7089\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7149 - accuracy: 0.7219 - val_loss: 0.7297 - val_accuracy: 0.7111\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7076 - accuracy: 0.7352 - val_loss: 0.7219 - val_accuracy: 0.7133\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7016 - accuracy: 0.7390 - val_loss: 0.7120 - val_accuracy: 0.7244\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6938 - accuracy: 0.7295 - val_loss: 0.7052 - val_accuracy: 0.7333\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6851 - accuracy: 0.7552 - val_loss: 0.6941 - val_accuracy: 0.7244\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6805 - accuracy: 0.7486 - val_loss: 0.6889 - val_accuracy: 0.7378\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.7514 - val_loss: 0.6842 - val_accuracy: 0.7400\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6691 - accuracy: 0.7390 - val_loss: 0.6794 - val_accuracy: 0.7422\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6644 - accuracy: 0.7495 - val_loss: 0.6908 - val_accuracy: 0.7178\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6589 - accuracy: 0.7533 - val_loss: 0.6762 - val_accuracy: 0.7378\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6571 - accuracy: 0.7514 - val_loss: 0.6658 - val_accuracy: 0.7378\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6556 - accuracy: 0.7571 - val_loss: 0.6659 - val_accuracy: 0.7333\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.7619 - val_loss: 0.6582 - val_accuracy: 0.7444\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6428 - accuracy: 0.7581 - val_loss: 0.6544 - val_accuracy: 0.7444\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6382 - accuracy: 0.7571 - val_loss: 0.6500 - val_accuracy: 0.7422\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.7619 - val_loss: 0.6489 - val_accuracy: 0.7444\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.7724 - val_loss: 0.6431 - val_accuracy: 0.7467\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7667 - val_loss: 0.6390 - val_accuracy: 0.7467\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7724 - val_loss: 0.6357 - val_accuracy: 0.7622\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7724 - val_loss: 0.6334 - val_accuracy: 0.7511\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6114 - accuracy: 0.7762 - val_loss: 0.6290 - val_accuracy: 0.7511\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.7714 - val_loss: 0.6249 - val_accuracy: 0.7533\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6045 - accuracy: 0.7790 - val_loss: 0.6198 - val_accuracy: 0.7489\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7724 - val_loss: 0.6216 - val_accuracy: 0.7600\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5925 - accuracy: 0.7781 - val_loss: 0.6118 - val_accuracy: 0.7511\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5905 - accuracy: 0.7848 - val_loss: 0.6162 - val_accuracy: 0.7622\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5851 - accuracy: 0.7819 - val_loss: 0.6156 - val_accuracy: 0.7556\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7876 - val_loss: 0.5985 - val_accuracy: 0.7622\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5754 - accuracy: 0.7895 - val_loss: 0.5931 - val_accuracy: 0.7667\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5710 - accuracy: 0.7971 - val_loss: 0.5910 - val_accuracy: 0.7733\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7857 - val_loss: 0.5932 - val_accuracy: 0.7733\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5583 - accuracy: 0.8029 - val_loss: 0.5930 - val_accuracy: 0.7667\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5591 - accuracy: 0.7962 - val_loss: 0.5752 - val_accuracy: 0.7800\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.8038 - val_loss: 0.5876 - val_accuracy: 0.7733\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.8010 - val_loss: 0.5662 - val_accuracy: 0.7867\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5421 - accuracy: 0.8124 - val_loss: 0.5683 - val_accuracy: 0.7800\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.8114 - val_loss: 0.5534 - val_accuracy: 0.7978\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5354 - accuracy: 0.8171 - val_loss: 0.5576 - val_accuracy: 0.7889\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5218 - accuracy: 0.8200 - val_loss: 0.5575 - val_accuracy: 0.7800\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5152 - accuracy: 0.8181 - val_loss: 0.5368 - val_accuracy: 0.8000\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5198 - accuracy: 0.8248 - val_loss: 0.5340 - val_accuracy: 0.8044\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.8267 - val_loss: 0.5484 - val_accuracy: 0.7822\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4998 - accuracy: 0.8257 - val_loss: 0.5221 - val_accuracy: 0.8089\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4936 - accuracy: 0.8352 - val_loss: 0.5125 - val_accuracy: 0.8133\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4908 - accuracy: 0.8429 - val_loss: 0.5115 - val_accuracy: 0.8156\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8286 - val_loss: 0.5193 - val_accuracy: 0.7978\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4769 - accuracy: 0.8410 - val_loss: 0.4975 - val_accuracy: 0.8200\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.8438 - val_loss: 0.4896 - val_accuracy: 0.8267\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.8495 - val_loss: 0.4799 - val_accuracy: 0.8311\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4536 - accuracy: 0.8505 - val_loss: 0.4976 - val_accuracy: 0.8044\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8543 - val_loss: 0.4668 - val_accuracy: 0.8378\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[116  18  14]\n",
            " [ 17 115  11]\n",
            " [ 11   2 146]]\n",
            "\n",
            "P-Score: 0.837, R-Score: 0.835, F-Score: 0.836\n",
            "[0.8377777777777777, 0.8370695256660169, 0.8354061938967599, 0.8355690540966977, 0.8455342759978521, 0.8695246121956219, 0.9161641703948648, 0.8770743528627797]\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_36 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1094 - accuracy: 0.3238 - val_loss: 1.1065 - val_accuracy: 0.3511\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3371 - val_loss: 1.0927 - val_accuracy: 0.3311\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0888 - accuracy: 0.3552 - val_loss: 1.0842 - val_accuracy: 0.3889\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0785 - accuracy: 0.4000 - val_loss: 1.0757 - val_accuracy: 0.4044\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0705 - accuracy: 0.4810 - val_loss: 1.0630 - val_accuracy: 0.4489\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0587 - accuracy: 0.4876 - val_loss: 1.0539 - val_accuracy: 0.4800\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.5838 - val_loss: 1.0392 - val_accuracy: 0.6444\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0303 - accuracy: 0.6676 - val_loss: 1.0270 - val_accuracy: 0.5244\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0127 - accuracy: 0.6543 - val_loss: 1.0050 - val_accuracy: 0.6978\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9934 - accuracy: 0.6790 - val_loss: 0.9858 - val_accuracy: 0.7111\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9730 - accuracy: 0.6943 - val_loss: 0.9693 - val_accuracy: 0.6289\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9489 - accuracy: 0.7057 - val_loss: 0.9434 - val_accuracy: 0.6667\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9199 - accuracy: 0.6819 - val_loss: 0.9084 - val_accuracy: 0.7244\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8889 - accuracy: 0.7152 - val_loss: 0.8844 - val_accuracy: 0.7111\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8657 - accuracy: 0.7124 - val_loss: 0.8621 - val_accuracy: 0.7067\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8449 - accuracy: 0.7029 - val_loss: 0.8439 - val_accuracy: 0.7000\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8249 - accuracy: 0.7076 - val_loss: 0.8291 - val_accuracy: 0.6800\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8062 - accuracy: 0.7200 - val_loss: 0.8116 - val_accuracy: 0.7022\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7900 - accuracy: 0.7219 - val_loss: 0.7969 - val_accuracy: 0.7000\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7761 - accuracy: 0.7200 - val_loss: 0.7844 - val_accuracy: 0.7156\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7649 - accuracy: 0.7048 - val_loss: 0.7751 - val_accuracy: 0.6978\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7531 - accuracy: 0.7076 - val_loss: 0.7672 - val_accuracy: 0.7000\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.7210 - val_loss: 0.7553 - val_accuracy: 0.7089\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7390 - accuracy: 0.7229 - val_loss: 0.7499 - val_accuracy: 0.7111\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7296 - accuracy: 0.7229 - val_loss: 0.7419 - val_accuracy: 0.7156\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7223 - accuracy: 0.7143 - val_loss: 0.7372 - val_accuracy: 0.7133\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7180 - accuracy: 0.7276 - val_loss: 0.7318 - val_accuracy: 0.7156\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7099 - accuracy: 0.7314 - val_loss: 0.7260 - val_accuracy: 0.7222\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7065 - accuracy: 0.7171 - val_loss: 0.7233 - val_accuracy: 0.7133\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7010 - accuracy: 0.7295 - val_loss: 0.7182 - val_accuracy: 0.7044\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.7219 - val_loss: 0.7126 - val_accuracy: 0.7156\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6958 - accuracy: 0.7314 - val_loss: 0.7095 - val_accuracy: 0.7133\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6866 - accuracy: 0.7381 - val_loss: 0.7057 - val_accuracy: 0.7267\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6807 - accuracy: 0.7352 - val_loss: 0.7053 - val_accuracy: 0.7089\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7381 - val_loss: 0.6994 - val_accuracy: 0.7178\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6760 - accuracy: 0.7324 - val_loss: 0.6951 - val_accuracy: 0.7222\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6724 - accuracy: 0.7371 - val_loss: 0.6912 - val_accuracy: 0.7244\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6678 - accuracy: 0.7448 - val_loss: 0.6912 - val_accuracy: 0.7156\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6629 - accuracy: 0.7429 - val_loss: 0.6869 - val_accuracy: 0.7222\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.7467 - val_loss: 0.6850 - val_accuracy: 0.7356\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7533 - val_loss: 0.6767 - val_accuracy: 0.7267\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7667 - val_loss: 0.6659 - val_accuracy: 0.7489\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6375 - accuracy: 0.7610 - val_loss: 0.6618 - val_accuracy: 0.7467\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6341 - accuracy: 0.7790 - val_loss: 0.6573 - val_accuracy: 0.7533\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.7733 - val_loss: 0.6601 - val_accuracy: 0.7333\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6237 - accuracy: 0.7733 - val_loss: 0.6495 - val_accuracy: 0.7622\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6191 - accuracy: 0.7800 - val_loss: 0.6491 - val_accuracy: 0.7467\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7905 - val_loss: 0.6485 - val_accuracy: 0.7311\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7829 - val_loss: 0.6517 - val_accuracy: 0.7422\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7829 - val_loss: 0.6345 - val_accuracy: 0.7578\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7943 - val_loss: 0.6304 - val_accuracy: 0.7689\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.8000 - val_loss: 0.6259 - val_accuracy: 0.7711\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5854 - accuracy: 0.8095 - val_loss: 0.6148 - val_accuracy: 0.7778\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5772 - accuracy: 0.8114 - val_loss: 0.6115 - val_accuracy: 0.7600\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5728 - accuracy: 0.8143 - val_loss: 0.6106 - val_accuracy: 0.7733\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5695 - accuracy: 0.7981 - val_loss: 0.6076 - val_accuracy: 0.7644\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5632 - accuracy: 0.8143 - val_loss: 0.5936 - val_accuracy: 0.7733\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5573 - accuracy: 0.8238 - val_loss: 0.5800 - val_accuracy: 0.7889\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5504 - accuracy: 0.8305 - val_loss: 0.5759 - val_accuracy: 0.7911\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.8343 - val_loss: 0.5768 - val_accuracy: 0.7800\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5431 - accuracy: 0.8314 - val_loss: 0.5655 - val_accuracy: 0.7867\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.8238 - val_loss: 0.5589 - val_accuracy: 0.8044\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5236 - accuracy: 0.8400 - val_loss: 0.5516 - val_accuracy: 0.7956\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.8371 - val_loss: 0.5466 - val_accuracy: 0.7933\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8467 - val_loss: 0.5484 - val_accuracy: 0.7911\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.8429 - val_loss: 0.5365 - val_accuracy: 0.7933\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.8495 - val_loss: 0.5289 - val_accuracy: 0.7956\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.8467 - val_loss: 0.5249 - val_accuracy: 0.8111\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.8571 - val_loss: 0.5155 - val_accuracy: 0.8200\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.8543 - val_loss: 0.5334 - val_accuracy: 0.8000\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4749 - accuracy: 0.8533 - val_loss: 0.5155 - val_accuracy: 0.8133\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.8571 - val_loss: 0.5007 - val_accuracy: 0.8089\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4633 - accuracy: 0.8629 - val_loss: 0.4979 - val_accuracy: 0.8222\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8581 - val_loss: 0.5071 - val_accuracy: 0.8089\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.8514 - val_loss: 0.4872 - val_accuracy: 0.8178\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4507 - accuracy: 0.8600 - val_loss: 0.4830 - val_accuracy: 0.8311\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4458 - accuracy: 0.8629 - val_loss: 0.4814 - val_accuracy: 0.8156\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8619 - val_loss: 0.4972 - val_accuracy: 0.8089\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.8743 - val_loss: 0.4705 - val_accuracy: 0.8311\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.8676 - val_loss: 0.4850 - val_accuracy: 0.8178\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[120  21   7]\n",
            " [ 14 122   7]\n",
            " [ 17  16 126]]\n",
            "\n",
            "P-Score: 0.821, R-Score: 0.819, F-Score: 0.818\n",
            "[0.8177777777777778, 0.8206658614130812, 0.8188034980487812, 0.8178106565667752, 0.8540809020941472, 0.8663128402542082, 0.8721714322764701, 0.8641883915416084]\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_39 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1116 - accuracy: 0.3400 - val_loss: 1.0931 - val_accuracy: 0.3178\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0771 - accuracy: 0.3467 - val_loss: 1.0727 - val_accuracy: 0.3644\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0662 - accuracy: 0.4867 - val_loss: 1.0639 - val_accuracy: 0.5489\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0581 - accuracy: 0.5790 - val_loss: 1.0553 - val_accuracy: 0.6022\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.6314 - val_loss: 1.0458 - val_accuracy: 0.6333\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0373 - accuracy: 0.6381 - val_loss: 1.0340 - val_accuracy: 0.6444\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0245 - accuracy: 0.6467 - val_loss: 1.0201 - val_accuracy: 0.6533\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0110 - accuracy: 0.6210 - val_loss: 1.0049 - val_accuracy: 0.6689\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9950 - accuracy: 0.6352 - val_loss: 0.9901 - val_accuracy: 0.6822\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9754 - accuracy: 0.6543 - val_loss: 0.9693 - val_accuracy: 0.6267\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9596 - accuracy: 0.6495 - val_loss: 0.9560 - val_accuracy: 0.5511\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.6419 - val_loss: 0.9310 - val_accuracy: 0.6800\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9169 - accuracy: 0.6543 - val_loss: 0.9109 - val_accuracy: 0.6822\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8957 - accuracy: 0.6495 - val_loss: 0.8907 - val_accuracy: 0.6689\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8743 - accuracy: 0.6619 - val_loss: 0.8723 - val_accuracy: 0.6933\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8541 - accuracy: 0.6552 - val_loss: 0.8538 - val_accuracy: 0.6333\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8406 - accuracy: 0.6533 - val_loss: 0.8365 - val_accuracy: 0.6711\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8226 - accuracy: 0.6352 - val_loss: 0.8192 - val_accuracy: 0.6622\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8053 - accuracy: 0.6743 - val_loss: 0.8075 - val_accuracy: 0.6444\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7956 - accuracy: 0.6638 - val_loss: 0.7929 - val_accuracy: 0.6933\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7769 - accuracy: 0.6752 - val_loss: 0.7942 - val_accuracy: 0.7044\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7676 - accuracy: 0.6590 - val_loss: 0.7748 - val_accuracy: 0.7000\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7553 - accuracy: 0.6914 - val_loss: 0.7615 - val_accuracy: 0.6844\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.6800 - val_loss: 0.7680 - val_accuracy: 0.6311\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7461 - accuracy: 0.6705 - val_loss: 0.7551 - val_accuracy: 0.6978\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7337 - accuracy: 0.7010 - val_loss: 0.7402 - val_accuracy: 0.6978\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7307 - accuracy: 0.7019 - val_loss: 0.7385 - val_accuracy: 0.7133\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7193 - accuracy: 0.6990 - val_loss: 0.7295 - val_accuracy: 0.7044\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7097 - accuracy: 0.7010 - val_loss: 0.7210 - val_accuracy: 0.7200\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7071 - accuracy: 0.7095 - val_loss: 0.7211 - val_accuracy: 0.7111\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6986 - accuracy: 0.7238 - val_loss: 0.7116 - val_accuracy: 0.7133\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6934 - accuracy: 0.7229 - val_loss: 0.7104 - val_accuracy: 0.7200\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6891 - accuracy: 0.7152 - val_loss: 0.7063 - val_accuracy: 0.7156\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.7171 - val_loss: 0.6992 - val_accuracy: 0.7156\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7210 - val_loss: 0.7003 - val_accuracy: 0.7200\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6785 - accuracy: 0.7190 - val_loss: 0.6938 - val_accuracy: 0.7178\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6727 - accuracy: 0.7276 - val_loss: 0.6900 - val_accuracy: 0.7178\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6683 - accuracy: 0.7248 - val_loss: 0.7084 - val_accuracy: 0.7044\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6682 - accuracy: 0.7238 - val_loss: 0.6819 - val_accuracy: 0.7156\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6626 - accuracy: 0.7362 - val_loss: 0.6783 - val_accuracy: 0.7200\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7362 - val_loss: 0.6762 - val_accuracy: 0.7200\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6541 - accuracy: 0.7362 - val_loss: 0.6800 - val_accuracy: 0.7333\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7381 - val_loss: 0.6815 - val_accuracy: 0.7222\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6545 - accuracy: 0.7295 - val_loss: 0.7334 - val_accuracy: 0.6822\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.7343 - val_loss: 0.6780 - val_accuracy: 0.7200\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7400 - val_loss: 0.6670 - val_accuracy: 0.7356\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.7505 - val_loss: 0.6680 - val_accuracy: 0.7356\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6358 - accuracy: 0.7476 - val_loss: 0.6864 - val_accuracy: 0.7044\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.7467 - val_loss: 0.6723 - val_accuracy: 0.7111\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6329 - accuracy: 0.7486 - val_loss: 0.6600 - val_accuracy: 0.7444\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6329 - accuracy: 0.7467 - val_loss: 0.6489 - val_accuracy: 0.7311\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6260 - accuracy: 0.7486 - val_loss: 0.6485 - val_accuracy: 0.7311\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6220 - accuracy: 0.7619 - val_loss: 0.6458 - val_accuracy: 0.7356\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.7657 - val_loss: 0.6477 - val_accuracy: 0.7467\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6187 - accuracy: 0.7562 - val_loss: 0.6518 - val_accuracy: 0.7400\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6164 - accuracy: 0.7657 - val_loss: 0.6372 - val_accuracy: 0.7444\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6094 - accuracy: 0.7686 - val_loss: 0.6361 - val_accuracy: 0.7467\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6081 - accuracy: 0.7600 - val_loss: 0.6356 - val_accuracy: 0.7178\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.7648 - val_loss: 0.6319 - val_accuracy: 0.7511\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5988 - accuracy: 0.7733 - val_loss: 0.6281 - val_accuracy: 0.7489\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5964 - accuracy: 0.7733 - val_loss: 0.6223 - val_accuracy: 0.7622\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5942 - accuracy: 0.7800 - val_loss: 0.6312 - val_accuracy: 0.7311\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5882 - accuracy: 0.7810 - val_loss: 0.6178 - val_accuracy: 0.7556\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5846 - accuracy: 0.7838 - val_loss: 0.6098 - val_accuracy: 0.7511\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5938 - accuracy: 0.7724 - val_loss: 0.6083 - val_accuracy: 0.7644\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5936 - accuracy: 0.7610 - val_loss: 0.6442 - val_accuracy: 0.7267\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5768 - accuracy: 0.7743 - val_loss: 0.5999 - val_accuracy: 0.7667\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5720 - accuracy: 0.7895 - val_loss: 0.5976 - val_accuracy: 0.7667\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5677 - accuracy: 0.7914 - val_loss: 0.5923 - val_accuracy: 0.7689\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5656 - accuracy: 0.7886 - val_loss: 0.5918 - val_accuracy: 0.7622\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5644 - accuracy: 0.7914 - val_loss: 0.5861 - val_accuracy: 0.7733\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5548 - accuracy: 0.7971 - val_loss: 0.5868 - val_accuracy: 0.7689\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5502 - accuracy: 0.7990 - val_loss: 0.5794 - val_accuracy: 0.7622\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5445 - accuracy: 0.8029 - val_loss: 0.5803 - val_accuracy: 0.7622\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7962 - val_loss: 0.5664 - val_accuracy: 0.7822\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.8019 - val_loss: 0.5634 - val_accuracy: 0.7822\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5330 - accuracy: 0.8048 - val_loss: 0.5656 - val_accuracy: 0.7689\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.8124 - val_loss: 0.5672 - val_accuracy: 0.7756\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.8095 - val_loss: 0.5482 - val_accuracy: 0.7822\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5250 - accuracy: 0.8076 - val_loss: 0.5472 - val_accuracy: 0.7867\n",
            "15/15 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[108  31   9]\n",
            " [ 15 105  23]\n",
            " [  3  15 141]]\n",
            "\n",
            "P-Score: 0.789, R-Score: 0.784, F-Score: 0.784\n",
            "[0.7866666666666666, 0.789178665762519, 0.7835959722752176, 0.7840014908434573, 0.8350635403615537, 0.7922143003576227, 0.8884134085456785, 0.8385637497549516]\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_42 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 11ms/step - loss: 1.1097 - accuracy: 0.3343 - val_loss: 1.0999 - val_accuracy: 0.4244\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0886 - accuracy: 0.4238 - val_loss: 1.0810 - val_accuracy: 0.4422\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0782 - accuracy: 0.5181 - val_loss: 1.0723 - val_accuracy: 0.5022\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0690 - accuracy: 0.5390 - val_loss: 1.0643 - val_accuracy: 0.4822\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0596 - accuracy: 0.5095 - val_loss: 1.0552 - val_accuracy: 0.5067\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0504 - accuracy: 0.5667 - val_loss: 1.0443 - val_accuracy: 0.5178\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0366 - accuracy: 0.5333 - val_loss: 1.0326 - val_accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0221 - accuracy: 0.5686 - val_loss: 1.0166 - val_accuracy: 0.5356\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0058 - accuracy: 0.5733 - val_loss: 1.0004 - val_accuracy: 0.5333\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9879 - accuracy: 0.5714 - val_loss: 0.9828 - val_accuracy: 0.5356\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9684 - accuracy: 0.5771 - val_loss: 0.9646 - val_accuracy: 0.5600\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9472 - accuracy: 0.5743 - val_loss: 0.9432 - val_accuracy: 0.5400\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9262 - accuracy: 0.5895 - val_loss: 0.9220 - val_accuracy: 0.7289\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9062 - accuracy: 0.7162 - val_loss: 0.9056 - val_accuracy: 0.5378\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8827 - accuracy: 0.6895 - val_loss: 0.8812 - val_accuracy: 0.7911\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8633 - accuracy: 0.7714 - val_loss: 0.8640 - val_accuracy: 0.7244\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8403 - accuracy: 0.6924 - val_loss: 0.8432 - val_accuracy: 0.7489\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8205 - accuracy: 0.7610 - val_loss: 0.8258 - val_accuracy: 0.7467\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8052 - accuracy: 0.7686 - val_loss: 0.8127 - val_accuracy: 0.7311\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7888 - accuracy: 0.7495 - val_loss: 0.7982 - val_accuracy: 0.7400\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7777 - accuracy: 0.7476 - val_loss: 0.7862 - val_accuracy: 0.7422\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7610 - accuracy: 0.7600 - val_loss: 0.7839 - val_accuracy: 0.7022\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7509 - accuracy: 0.7448 - val_loss: 0.7647 - val_accuracy: 0.7378\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7387 - accuracy: 0.7562 - val_loss: 0.7652 - val_accuracy: 0.7022\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7310 - accuracy: 0.7514 - val_loss: 0.7490 - val_accuracy: 0.7378\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7194 - accuracy: 0.7476 - val_loss: 0.7395 - val_accuracy: 0.7178\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7117 - accuracy: 0.7619 - val_loss: 0.7345 - val_accuracy: 0.7378\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7049 - accuracy: 0.7543 - val_loss: 0.7310 - val_accuracy: 0.7000\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6946 - accuracy: 0.7571 - val_loss: 0.7185 - val_accuracy: 0.7356\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6895 - accuracy: 0.7438 - val_loss: 0.7160 - val_accuracy: 0.7156\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6814 - accuracy: 0.7629 - val_loss: 0.7060 - val_accuracy: 0.7467\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6746 - accuracy: 0.7638 - val_loss: 0.7000 - val_accuracy: 0.7444\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.7629 - val_loss: 0.6931 - val_accuracy: 0.7578\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6581 - accuracy: 0.7657 - val_loss: 0.6873 - val_accuracy: 0.7511\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.7876 - val_loss: 0.6863 - val_accuracy: 0.7667\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6483 - accuracy: 0.7724 - val_loss: 0.6708 - val_accuracy: 0.7600\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.7848 - val_loss: 0.6662 - val_accuracy: 0.7467\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.7952 - val_loss: 0.6619 - val_accuracy: 0.7556\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6274 - accuracy: 0.7924 - val_loss: 0.6513 - val_accuracy: 0.7733\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.7990 - val_loss: 0.6567 - val_accuracy: 0.7311\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6090 - accuracy: 0.8010 - val_loss: 0.6358 - val_accuracy: 0.7778\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5984 - accuracy: 0.8067 - val_loss: 0.6290 - val_accuracy: 0.7689\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5894 - accuracy: 0.8124 - val_loss: 0.6224 - val_accuracy: 0.7733\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.8124 - val_loss: 0.6130 - val_accuracy: 0.7778\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5718 - accuracy: 0.8295 - val_loss: 0.6020 - val_accuracy: 0.7844\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.8286 - val_loss: 0.6012 - val_accuracy: 0.7978\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.8371 - val_loss: 0.5805 - val_accuracy: 0.8111\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8305 - val_loss: 0.5706 - val_accuracy: 0.8133\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5342 - accuracy: 0.8410 - val_loss: 0.5608 - val_accuracy: 0.8200\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.8448 - val_loss: 0.5624 - val_accuracy: 0.7933\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5154 - accuracy: 0.8562 - val_loss: 0.5424 - val_accuracy: 0.8289\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8533 - val_loss: 0.5329 - val_accuracy: 0.8356\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8543 - val_loss: 0.5305 - val_accuracy: 0.8156\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.8648 - val_loss: 0.5135 - val_accuracy: 0.8422\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4820 - accuracy: 0.8629 - val_loss: 0.5137 - val_accuracy: 0.8400\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4695 - accuracy: 0.8695 - val_loss: 0.5024 - val_accuracy: 0.8333\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.8705 - val_loss: 0.4989 - val_accuracy: 0.8333\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4579 - accuracy: 0.8686 - val_loss: 0.4772 - val_accuracy: 0.8533\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4434 - accuracy: 0.8733 - val_loss: 0.4719 - val_accuracy: 0.8511\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4380 - accuracy: 0.8771 - val_loss: 0.4691 - val_accuracy: 0.8444\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4303 - accuracy: 0.8705 - val_loss: 0.4555 - val_accuracy: 0.8533\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4191 - accuracy: 0.8800 - val_loss: 0.4493 - val_accuracy: 0.8444\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.4125 - accuracy: 0.8857 - val_loss: 0.4563 - val_accuracy: 0.8600\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 0.4046 - accuracy: 0.8905 - val_loss: 0.4414 - val_accuracy: 0.8644\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.3947 - accuracy: 0.8790 - val_loss: 0.4251 - val_accuracy: 0.8600\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3882 - accuracy: 0.8924 - val_loss: 0.4199 - val_accuracy: 0.8622\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.8886 - val_loss: 0.4198 - val_accuracy: 0.8733\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3764 - accuracy: 0.8905 - val_loss: 0.4044 - val_accuracy: 0.8533\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3687 - accuracy: 0.8962 - val_loss: 0.3982 - val_accuracy: 0.8622\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3678 - accuracy: 0.8895 - val_loss: 0.3992 - val_accuracy: 0.8622\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.8933 - val_loss: 0.3872 - val_accuracy: 0.8644\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3549 - accuracy: 0.8943 - val_loss: 0.3871 - val_accuracy: 0.8689\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3478 - accuracy: 0.8943 - val_loss: 0.3826 - val_accuracy: 0.8778\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8924 - val_loss: 0.3803 - val_accuracy: 0.8778\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8971 - val_loss: 0.3672 - val_accuracy: 0.8711\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3337 - accuracy: 0.8933 - val_loss: 0.3678 - val_accuracy: 0.8733\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8981 - val_loss: 0.3574 - val_accuracy: 0.8733\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8990 - val_loss: 0.3522 - val_accuracy: 0.8733\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8924 - val_loss: 0.3502 - val_accuracy: 0.8800\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8971 - val_loss: 0.3497 - val_accuracy: 0.8822\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[125  11  12]\n",
            " [ 11 129   3]\n",
            " [ 16   0 143]]\n",
            "\n",
            "P-Score: 0.883, R-Score: 0.882, F-Score: 0.882\n",
            "[0.8822222222222222, 0.8829534278734812, 0.8820211886249623, 0.8824007708704124, 0.8775953105423304, 0.933133641602697, 0.9239123387149062, 0.9115470969533112]\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_45 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_46 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.0956 - accuracy: 0.3362 - val_loss: 1.0906 - val_accuracy: 0.3200\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0877 - accuracy: 0.3410 - val_loss: 1.0841 - val_accuracy: 0.3711\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0811 - accuracy: 0.3981 - val_loss: 1.0794 - val_accuracy: 0.3289\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0728 - accuracy: 0.4114 - val_loss: 1.0679 - val_accuracy: 0.4311\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.4533 - val_loss: 1.0582 - val_accuracy: 0.5267\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0497 - accuracy: 0.5800 - val_loss: 1.0439 - val_accuracy: 0.6511\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0331 - accuracy: 0.6343 - val_loss: 1.0283 - val_accuracy: 0.6667\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0157 - accuracy: 0.6619 - val_loss: 1.0107 - val_accuracy: 0.6800\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9997 - accuracy: 0.6676 - val_loss: 0.9933 - val_accuracy: 0.6600\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9820 - accuracy: 0.6495 - val_loss: 0.9755 - val_accuracy: 0.6333\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9645 - accuracy: 0.6419 - val_loss: 0.9583 - val_accuracy: 0.6933\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9451 - accuracy: 0.6686 - val_loss: 0.9395 - val_accuracy: 0.6444\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9283 - accuracy: 0.6495 - val_loss: 0.9213 - val_accuracy: 0.6356\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9086 - accuracy: 0.6533 - val_loss: 0.9051 - val_accuracy: 0.7000\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8898 - accuracy: 0.6867 - val_loss: 0.8882 - val_accuracy: 0.6933\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8723 - accuracy: 0.6724 - val_loss: 0.8722 - val_accuracy: 0.6222\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8570 - accuracy: 0.6600 - val_loss: 0.8587 - val_accuracy: 0.7067\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8418 - accuracy: 0.6762 - val_loss: 0.8409 - val_accuracy: 0.6600\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8272 - accuracy: 0.6686 - val_loss: 0.8346 - val_accuracy: 0.6889\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8144 - accuracy: 0.6990 - val_loss: 0.8158 - val_accuracy: 0.6844\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8012 - accuracy: 0.6648 - val_loss: 0.8085 - val_accuracy: 0.7089\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7890 - accuracy: 0.6895 - val_loss: 0.7944 - val_accuracy: 0.7000\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7783 - accuracy: 0.6857 - val_loss: 0.7872 - val_accuracy: 0.7000\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7706 - accuracy: 0.6743 - val_loss: 0.7789 - val_accuracy: 0.7000\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7610 - accuracy: 0.6981 - val_loss: 0.7678 - val_accuracy: 0.7000\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7530 - accuracy: 0.6990 - val_loss: 0.7603 - val_accuracy: 0.6956\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7439 - accuracy: 0.6848 - val_loss: 0.7555 - val_accuracy: 0.7022\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7375 - accuracy: 0.6971 - val_loss: 0.7491 - val_accuracy: 0.7067\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7314 - accuracy: 0.7133 - val_loss: 0.7417 - val_accuracy: 0.7111\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7253 - accuracy: 0.7067 - val_loss: 0.7391 - val_accuracy: 0.6978\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7196 - accuracy: 0.7067 - val_loss: 0.7344 - val_accuracy: 0.7000\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7158 - accuracy: 0.7152 - val_loss: 0.7267 - val_accuracy: 0.6978\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7085 - accuracy: 0.7114 - val_loss: 0.7221 - val_accuracy: 0.7044\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7034 - accuracy: 0.7105 - val_loss: 0.7288 - val_accuracy: 0.6844\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7009 - accuracy: 0.7210 - val_loss: 0.7136 - val_accuracy: 0.7022\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.7190 - val_loss: 0.7242 - val_accuracy: 0.6844\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6973 - accuracy: 0.7171 - val_loss: 0.7064 - val_accuracy: 0.7156\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6859 - accuracy: 0.7229 - val_loss: 0.7020 - val_accuracy: 0.7111\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.7257 - val_loss: 0.7032 - val_accuracy: 0.6956\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6790 - accuracy: 0.7162 - val_loss: 0.6927 - val_accuracy: 0.7089\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6798 - accuracy: 0.7171 - val_loss: 0.6908 - val_accuracy: 0.7111\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6763 - accuracy: 0.7229 - val_loss: 0.7084 - val_accuracy: 0.6933\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6762 - accuracy: 0.7162 - val_loss: 0.6930 - val_accuracy: 0.7089\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.7333 - val_loss: 0.6881 - val_accuracy: 0.7200\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6684 - accuracy: 0.7200 - val_loss: 0.6855 - val_accuracy: 0.7200\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6634 - accuracy: 0.7295 - val_loss: 0.6825 - val_accuracy: 0.7178\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.7257 - val_loss: 0.6872 - val_accuracy: 0.7067\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6595 - accuracy: 0.7343 - val_loss: 0.6791 - val_accuracy: 0.7267\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.7419 - val_loss: 0.6745 - val_accuracy: 0.7200\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.7248 - val_loss: 0.6747 - val_accuracy: 0.7311\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6527 - accuracy: 0.7419 - val_loss: 0.6709 - val_accuracy: 0.7311\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6522 - accuracy: 0.7400 - val_loss: 0.6689 - val_accuracy: 0.7244\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6496 - accuracy: 0.7457 - val_loss: 0.6686 - val_accuracy: 0.7267\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6505 - accuracy: 0.7467 - val_loss: 0.6747 - val_accuracy: 0.7200\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6458 - accuracy: 0.7352 - val_loss: 0.6683 - val_accuracy: 0.7311\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.7562 - val_loss: 0.6582 - val_accuracy: 0.7222\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6397 - accuracy: 0.7476 - val_loss: 0.6553 - val_accuracy: 0.7222\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6420 - accuracy: 0.7400 - val_loss: 0.6548 - val_accuracy: 0.7311\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.7571 - val_loss: 0.6499 - val_accuracy: 0.7267\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.7590 - val_loss: 0.6503 - val_accuracy: 0.7356\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6293 - accuracy: 0.7610 - val_loss: 0.6455 - val_accuracy: 0.7311\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7571 - val_loss: 0.6439 - val_accuracy: 0.7333\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6202 - accuracy: 0.7705 - val_loss: 0.6421 - val_accuracy: 0.7311\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6183 - accuracy: 0.7686 - val_loss: 0.6368 - val_accuracy: 0.7378\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7743 - val_loss: 0.6496 - val_accuracy: 0.7356\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.7714 - val_loss: 0.6317 - val_accuracy: 0.7444\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6094 - accuracy: 0.7695 - val_loss: 0.6326 - val_accuracy: 0.7511\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6032 - accuracy: 0.7781 - val_loss: 0.6398 - val_accuracy: 0.7378\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6016 - accuracy: 0.7762 - val_loss: 0.6264 - val_accuracy: 0.7422\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5971 - accuracy: 0.7724 - val_loss: 0.6180 - val_accuracy: 0.7467\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5961 - accuracy: 0.7857 - val_loss: 0.6211 - val_accuracy: 0.7533\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5901 - accuracy: 0.7838 - val_loss: 0.6307 - val_accuracy: 0.7378\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.7857 - val_loss: 0.6090 - val_accuracy: 0.7556\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5821 - accuracy: 0.7943 - val_loss: 0.6077 - val_accuracy: 0.7667\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5814 - accuracy: 0.7886 - val_loss: 0.6070 - val_accuracy: 0.7578\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7943 - val_loss: 0.5992 - val_accuracy: 0.7622\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5765 - accuracy: 0.7876 - val_loss: 0.6041 - val_accuracy: 0.7622\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5687 - accuracy: 0.8010 - val_loss: 0.5894 - val_accuracy: 0.7733\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5690 - accuracy: 0.7962 - val_loss: 0.5871 - val_accuracy: 0.7711\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5581 - accuracy: 0.8057 - val_loss: 0.5833 - val_accuracy: 0.7622\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[109  34   5]\n",
            " [ 16 106  21]\n",
            " [  5  26 128]]\n",
            "\n",
            "P-Score: 0.769, R-Score: 0.761, F-Score: 0.763\n",
            "[0.7622222222222222, 0.7693948621659464, 0.7609255580953693, 0.7627160593557475, 0.8334750313227134, 0.7729095009225303, 0.8578421837515399, 0.8214089053322612]\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_48 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_50 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 13ms/step - loss: 1.1226 - accuracy: 0.2476 - val_loss: 1.1141 - val_accuracy: 0.3200\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.1071 - accuracy: 0.3410 - val_loss: 1.0986 - val_accuracy: 0.3200\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0910 - accuracy: 0.2514 - val_loss: 1.0840 - val_accuracy: 0.3111\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0775 - accuracy: 0.4305 - val_loss: 1.0708 - val_accuracy: 0.5044\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0621 - accuracy: 0.5333 - val_loss: 1.0558 - val_accuracy: 0.5489\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0493 - accuracy: 0.5457 - val_loss: 1.0429 - val_accuracy: 0.5711\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0361 - accuracy: 0.5876 - val_loss: 1.0277 - val_accuracy: 0.5467\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0220 - accuracy: 0.6000 - val_loss: 1.0120 - val_accuracy: 0.5444\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0056 - accuracy: 0.5771 - val_loss: 0.9964 - val_accuracy: 0.5844\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9861 - accuracy: 0.5781 - val_loss: 0.9770 - val_accuracy: 0.5933\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9668 - accuracy: 0.5714 - val_loss: 0.9567 - val_accuracy: 0.5822\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9458 - accuracy: 0.5895 - val_loss: 0.9369 - val_accuracy: 0.5756\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9239 - accuracy: 0.5952 - val_loss: 0.9216 - val_accuracy: 0.6156\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9036 - accuracy: 0.6362 - val_loss: 0.8975 - val_accuracy: 0.5933\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8869 - accuracy: 0.6210 - val_loss: 0.8787 - val_accuracy: 0.6489\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8630 - accuracy: 0.6448 - val_loss: 0.8626 - val_accuracy: 0.6444\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8443 - accuracy: 0.6390 - val_loss: 0.8518 - val_accuracy: 0.6289\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8313 - accuracy: 0.6581 - val_loss: 0.8310 - val_accuracy: 0.6489\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8104 - accuracy: 0.6476 - val_loss: 0.8192 - val_accuracy: 0.6511\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7994 - accuracy: 0.6495 - val_loss: 0.8103 - val_accuracy: 0.6622\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7930 - accuracy: 0.6695 - val_loss: 0.8027 - val_accuracy: 0.6533\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7798 - accuracy: 0.6448 - val_loss: 0.7912 - val_accuracy: 0.6778\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7709 - accuracy: 0.6695 - val_loss: 0.7906 - val_accuracy: 0.6489\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7617 - accuracy: 0.6876 - val_loss: 0.7753 - val_accuracy: 0.6689\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7542 - accuracy: 0.6686 - val_loss: 0.7706 - val_accuracy: 0.6467\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7524 - accuracy: 0.6743 - val_loss: 0.7647 - val_accuracy: 0.6778\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7436 - accuracy: 0.6695 - val_loss: 0.7597 - val_accuracy: 0.6733\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.6886 - val_loss: 0.7717 - val_accuracy: 0.6578\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.6762 - val_loss: 0.7587 - val_accuracy: 0.6644\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7301 - accuracy: 0.6800 - val_loss: 0.7532 - val_accuracy: 0.6822\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7239 - accuracy: 0.6867 - val_loss: 0.7469 - val_accuracy: 0.6889\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7233 - accuracy: 0.6857 - val_loss: 0.7428 - val_accuracy: 0.6911\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7162 - accuracy: 0.6971 - val_loss: 0.7439 - val_accuracy: 0.6800\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7137 - accuracy: 0.6943 - val_loss: 0.7359 - val_accuracy: 0.6822\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.7048 - val_loss: 0.7359 - val_accuracy: 0.6911\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.7086 - val_loss: 0.7402 - val_accuracy: 0.6800\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7045 - accuracy: 0.7105 - val_loss: 0.7288 - val_accuracy: 0.6956\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.6914 - val_loss: 0.7419 - val_accuracy: 0.6756\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7012 - accuracy: 0.7105 - val_loss: 0.7367 - val_accuracy: 0.6778\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7051 - accuracy: 0.6981 - val_loss: 0.7230 - val_accuracy: 0.6978\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6961 - accuracy: 0.7057 - val_loss: 0.7247 - val_accuracy: 0.6889\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.7124 - val_loss: 0.7128 - val_accuracy: 0.7111\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7200 - val_loss: 0.7105 - val_accuracy: 0.7133\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6818 - accuracy: 0.7267 - val_loss: 0.7154 - val_accuracy: 0.7022\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.7381 - val_loss: 0.7025 - val_accuracy: 0.7133\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6752 - accuracy: 0.7410 - val_loss: 0.7006 - val_accuracy: 0.7200\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.7438 - val_loss: 0.6974 - val_accuracy: 0.7222\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6657 - accuracy: 0.7429 - val_loss: 0.6939 - val_accuracy: 0.7267\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6642 - accuracy: 0.7505 - val_loss: 0.6861 - val_accuracy: 0.7378\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.7610 - val_loss: 0.6872 - val_accuracy: 0.7222\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.7486 - val_loss: 0.6788 - val_accuracy: 0.7400\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6464 - accuracy: 0.7505 - val_loss: 0.6933 - val_accuracy: 0.7156\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6472 - accuracy: 0.7514 - val_loss: 0.6812 - val_accuracy: 0.7267\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.7714 - val_loss: 0.6639 - val_accuracy: 0.7511\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.7800 - val_loss: 0.6570 - val_accuracy: 0.7600\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7810 - val_loss: 0.6558 - val_accuracy: 0.7556\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.7848 - val_loss: 0.6493 - val_accuracy: 0.7622\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7800 - val_loss: 0.6419 - val_accuracy: 0.7689\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.7886 - val_loss: 0.6359 - val_accuracy: 0.7800\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6060 - accuracy: 0.7943 - val_loss: 0.6308 - val_accuracy: 0.7778\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5967 - accuracy: 0.7981 - val_loss: 0.6214 - val_accuracy: 0.7800\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.8038 - val_loss: 0.6271 - val_accuracy: 0.7600\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.8124 - val_loss: 0.6162 - val_accuracy: 0.7800\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5760 - accuracy: 0.8095 - val_loss: 0.6084 - val_accuracy: 0.7978\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.8133 - val_loss: 0.6016 - val_accuracy: 0.7889\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5735 - accuracy: 0.7990 - val_loss: 0.5855 - val_accuracy: 0.8022\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5568 - accuracy: 0.8229 - val_loss: 0.6109 - val_accuracy: 0.7644\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5555 - accuracy: 0.8143 - val_loss: 0.5768 - val_accuracy: 0.8000\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5418 - accuracy: 0.8219 - val_loss: 0.5642 - val_accuracy: 0.8067\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.8381 - val_loss: 0.5614 - val_accuracy: 0.8067\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.8448 - val_loss: 0.5585 - val_accuracy: 0.8089\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5150 - accuracy: 0.8467 - val_loss: 0.5608 - val_accuracy: 0.7889\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5105 - accuracy: 0.8505 - val_loss: 0.5364 - val_accuracy: 0.8156\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.8429 - val_loss: 0.5281 - val_accuracy: 0.8156\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.8476 - val_loss: 0.5237 - val_accuracy: 0.8200\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.8581 - val_loss: 0.5140 - val_accuracy: 0.8244\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8514 - val_loss: 0.5150 - val_accuracy: 0.8267\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8543 - val_loss: 0.5083 - val_accuracy: 0.8267\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4687 - accuracy: 0.8543 - val_loss: 0.5076 - val_accuracy: 0.8267\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4643 - accuracy: 0.8590 - val_loss: 0.4865 - val_accuracy: 0.8289\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[115  16  17]\n",
            " [ 18 113  12]\n",
            " [ 14   0 145]]\n",
            "\n",
            "P-Score: 0.831, R-Score: 0.826, F-Score: 0.827\n",
            "[0.8288888888888889, 0.8305384169171545, 0.8263955009238028, 0.8271380802537333, 0.8355333810631824, 0.869046263183071, 0.9061466640731376, 0.8702421027731303]\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_51 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_52 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_53 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.0942 - accuracy: 0.3562 - val_loss: 1.0743 - val_accuracy: 0.4422\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0570 - accuracy: 0.5876 - val_loss: 1.0487 - val_accuracy: 0.5222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0351 - accuracy: 0.5752 - val_loss: 1.0302 - val_accuracy: 0.5267\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0157 - accuracy: 0.5895 - val_loss: 1.0117 - val_accuracy: 0.5356\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9984 - accuracy: 0.4971 - val_loss: 0.9933 - val_accuracy: 0.3844\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9787 - accuracy: 0.4571 - val_loss: 0.9789 - val_accuracy: 0.5333\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9621 - accuracy: 0.5152 - val_loss: 0.9613 - val_accuracy: 0.5622\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9418 - accuracy: 0.4990 - val_loss: 0.9415 - val_accuracy: 0.4844\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9247 - accuracy: 0.5800 - val_loss: 0.9254 - val_accuracy: 0.5489\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9067 - accuracy: 0.5524 - val_loss: 0.9115 - val_accuracy: 0.5156\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8906 - accuracy: 0.5571 - val_loss: 0.8942 - val_accuracy: 0.5467\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8745 - accuracy: 0.5838 - val_loss: 0.8786 - val_accuracy: 0.5444\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8589 - accuracy: 0.5886 - val_loss: 0.8652 - val_accuracy: 0.5511\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8429 - accuracy: 0.5886 - val_loss: 0.8482 - val_accuracy: 0.5733\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8232 - accuracy: 0.5848 - val_loss: 0.8338 - val_accuracy: 0.5822\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8100 - accuracy: 0.5800 - val_loss: 0.8226 - val_accuracy: 0.5867\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7980 - accuracy: 0.6124 - val_loss: 0.8205 - val_accuracy: 0.5844\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7909 - accuracy: 0.6257 - val_loss: 0.8051 - val_accuracy: 0.5956\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7817 - accuracy: 0.6171 - val_loss: 0.7995 - val_accuracy: 0.5956\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.6286 - val_loss: 0.7950 - val_accuracy: 0.6133\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7688 - accuracy: 0.6095 - val_loss: 0.7872 - val_accuracy: 0.6089\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7634 - accuracy: 0.6314 - val_loss: 0.7838 - val_accuracy: 0.6133\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7600 - accuracy: 0.6314 - val_loss: 0.7801 - val_accuracy: 0.6022\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7544 - accuracy: 0.6238 - val_loss: 0.7759 - val_accuracy: 0.6133\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7495 - accuracy: 0.6533 - val_loss: 0.7770 - val_accuracy: 0.6267\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7474 - accuracy: 0.6219 - val_loss: 0.7685 - val_accuracy: 0.6111\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7446 - accuracy: 0.6495 - val_loss: 0.7667 - val_accuracy: 0.6156\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7406 - accuracy: 0.6476 - val_loss: 0.7652 - val_accuracy: 0.6222\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7383 - accuracy: 0.6505 - val_loss: 0.7623 - val_accuracy: 0.6289\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7395 - accuracy: 0.6476 - val_loss: 0.7602 - val_accuracy: 0.6356\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7340 - accuracy: 0.6514 - val_loss: 0.7628 - val_accuracy: 0.6289\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7344 - accuracy: 0.6362 - val_loss: 0.7582 - val_accuracy: 0.6289\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7338 - accuracy: 0.6571 - val_loss: 0.7561 - val_accuracy: 0.6378\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7312 - accuracy: 0.6543 - val_loss: 0.7539 - val_accuracy: 0.6333\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7295 - accuracy: 0.6590 - val_loss: 0.7560 - val_accuracy: 0.6400\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7279 - accuracy: 0.6638 - val_loss: 0.7882 - val_accuracy: 0.6356\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.6514 - val_loss: 0.7521 - val_accuracy: 0.6489\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7247 - accuracy: 0.6371 - val_loss: 0.7517 - val_accuracy: 0.6333\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7202 - accuracy: 0.6495 - val_loss: 0.7490 - val_accuracy: 0.6511\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7271 - accuracy: 0.6581 - val_loss: 0.7489 - val_accuracy: 0.6378\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7206 - accuracy: 0.6781 - val_loss: 0.7483 - val_accuracy: 0.6578\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7197 - accuracy: 0.6648 - val_loss: 0.7458 - val_accuracy: 0.6467\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7190 - accuracy: 0.6790 - val_loss: 0.7493 - val_accuracy: 0.6489\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7162 - accuracy: 0.6781 - val_loss: 0.7471 - val_accuracy: 0.6622\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7191 - accuracy: 0.6790 - val_loss: 0.7563 - val_accuracy: 0.6778\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7175 - accuracy: 0.6838 - val_loss: 0.7427 - val_accuracy: 0.6600\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7163 - accuracy: 0.6790 - val_loss: 0.7441 - val_accuracy: 0.6533\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7131 - accuracy: 0.6800 - val_loss: 0.7451 - val_accuracy: 0.6733\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7109 - accuracy: 0.6933 - val_loss: 0.7407 - val_accuracy: 0.6800\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7090 - accuracy: 0.6971 - val_loss: 0.7445 - val_accuracy: 0.6867\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7098 - accuracy: 0.7010 - val_loss: 0.7394 - val_accuracy: 0.6711\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7080 - accuracy: 0.6981 - val_loss: 0.7379 - val_accuracy: 0.6733\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.7029 - val_loss: 0.7335 - val_accuracy: 0.6778\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7031 - accuracy: 0.6952 - val_loss: 0.7318 - val_accuracy: 0.6822\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7051 - accuracy: 0.7019 - val_loss: 0.7300 - val_accuracy: 0.6978\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6983 - accuracy: 0.7210 - val_loss: 0.7274 - val_accuracy: 0.6933\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6971 - accuracy: 0.7238 - val_loss: 0.7252 - val_accuracy: 0.7000\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6941 - accuracy: 0.7295 - val_loss: 0.7209 - val_accuracy: 0.7133\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6913 - accuracy: 0.7343 - val_loss: 0.7218 - val_accuracy: 0.7022\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6884 - accuracy: 0.7295 - val_loss: 0.7168 - val_accuracy: 0.7022\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7352 - val_loss: 0.7134 - val_accuracy: 0.7111\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6814 - accuracy: 0.7410 - val_loss: 0.7167 - val_accuracy: 0.7133\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6825 - accuracy: 0.7276 - val_loss: 0.7094 - val_accuracy: 0.7356\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.7400 - val_loss: 0.7006 - val_accuracy: 0.7267\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.7476 - val_loss: 0.6989 - val_accuracy: 0.7333\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6659 - accuracy: 0.7543 - val_loss: 0.6895 - val_accuracy: 0.7289\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6618 - accuracy: 0.7590 - val_loss: 0.6868 - val_accuracy: 0.7489\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.7733 - val_loss: 0.6923 - val_accuracy: 0.7689\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.7610 - val_loss: 0.7072 - val_accuracy: 0.7556\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6531 - accuracy: 0.7752 - val_loss: 0.6734 - val_accuracy: 0.7556\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7800 - val_loss: 0.6669 - val_accuracy: 0.7667\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6352 - accuracy: 0.7829 - val_loss: 0.6542 - val_accuracy: 0.7733\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6253 - accuracy: 0.8095 - val_loss: 0.6492 - val_accuracy: 0.7867\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6179 - accuracy: 0.8114 - val_loss: 0.6389 - val_accuracy: 0.7933\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6077 - accuracy: 0.8190 - val_loss: 0.6293 - val_accuracy: 0.7933\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6045 - accuracy: 0.8305 - val_loss: 0.6296 - val_accuracy: 0.7867\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.8276 - val_loss: 0.6128 - val_accuracy: 0.8133\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5866 - accuracy: 0.8181 - val_loss: 0.6158 - val_accuracy: 0.7822\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5797 - accuracy: 0.8333 - val_loss: 0.6105 - val_accuracy: 0.8000\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5742 - accuracy: 0.8486 - val_loss: 0.5891 - val_accuracy: 0.8111\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[121  18   9]\n",
            " [ 11 123   9]\n",
            " [ 17  21 121]]\n",
            "\n",
            "P-Score: 0.814, R-Score: 0.813, F-Score: 0.811\n",
            "[0.8111111111111111, 0.813947797764771, 0.8129045723385345, 0.8111509095922488, 0.862426167889744, 0.8665520147604837, 0.8495753096025417, 0.8595178307509231]\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_54 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_55 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_56 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0866 - accuracy: 0.4210 - val_loss: 1.0771 - val_accuracy: 0.4489\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0723 - accuracy: 0.5381 - val_loss: 1.0663 - val_accuracy: 0.4511\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0613 - accuracy: 0.5905 - val_loss: 1.0554 - val_accuracy: 0.5756\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0492 - accuracy: 0.7295 - val_loss: 1.0428 - val_accuracy: 0.6733\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0350 - accuracy: 0.6038 - val_loss: 1.0311 - val_accuracy: 0.6378\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0256 - accuracy: 0.6657 - val_loss: 1.0151 - val_accuracy: 0.7733\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0061 - accuracy: 0.8162 - val_loss: 0.9976 - val_accuracy: 0.8467\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9889 - accuracy: 0.8495 - val_loss: 0.9805 - val_accuracy: 0.8622\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9677 - accuracy: 0.8848 - val_loss: 0.9580 - val_accuracy: 0.8422\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9448 - accuracy: 0.7800 - val_loss: 0.9367 - val_accuracy: 0.8644\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9192 - accuracy: 0.8600 - val_loss: 0.9105 - val_accuracy: 0.8511\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8900 - accuracy: 0.8219 - val_loss: 0.8794 - val_accuracy: 0.8356\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8562 - accuracy: 0.8752 - val_loss: 0.8521 - val_accuracy: 0.8289\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8266 - accuracy: 0.8705 - val_loss: 0.8194 - val_accuracy: 0.8422\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7960 - accuracy: 0.8819 - val_loss: 0.7930 - val_accuracy: 0.8578\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7685 - accuracy: 0.8724 - val_loss: 0.7770 - val_accuracy: 0.8111\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7408 - accuracy: 0.8867 - val_loss: 0.7546 - val_accuracy: 0.8067\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7213 - accuracy: 0.8724 - val_loss: 0.7256 - val_accuracy: 0.8356\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6989 - accuracy: 0.8733 - val_loss: 0.7069 - val_accuracy: 0.8578\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6783 - accuracy: 0.8848 - val_loss: 0.6881 - val_accuracy: 0.8444\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.8790 - val_loss: 0.6680 - val_accuracy: 0.8533\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6405 - accuracy: 0.8724 - val_loss: 0.6496 - val_accuracy: 0.8511\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6232 - accuracy: 0.8762 - val_loss: 0.6328 - val_accuracy: 0.8600\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.8790 - val_loss: 0.6172 - val_accuracy: 0.8511\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5918 - accuracy: 0.8838 - val_loss: 0.6238 - val_accuracy: 0.8400\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5740 - accuracy: 0.8829 - val_loss: 0.5945 - val_accuracy: 0.8600\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5585 - accuracy: 0.8848 - val_loss: 0.5805 - val_accuracy: 0.8711\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5457 - accuracy: 0.8876 - val_loss: 0.5648 - val_accuracy: 0.8711\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5272 - accuracy: 0.8924 - val_loss: 0.5498 - val_accuracy: 0.8622\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.8905 - val_loss: 0.5299 - val_accuracy: 0.8578\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8943 - val_loss: 0.5244 - val_accuracy: 0.8667\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.8981 - val_loss: 0.5106 - val_accuracy: 0.8622\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.8933 - val_loss: 0.4956 - val_accuracy: 0.8778\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4616 - accuracy: 0.8933 - val_loss: 0.4794 - val_accuracy: 0.8689\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4465 - accuracy: 0.8971 - val_loss: 0.4758 - val_accuracy: 0.8689\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.9000 - val_loss: 0.4613 - val_accuracy: 0.8667\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.9048 - val_loss: 0.4454 - val_accuracy: 0.8689\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.4140 - accuracy: 0.8924 - val_loss: 0.4366 - val_accuracy: 0.8867\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4038 - accuracy: 0.9038 - val_loss: 0.4237 - val_accuracy: 0.8778\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3957 - accuracy: 0.8981 - val_loss: 0.4196 - val_accuracy: 0.8889\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3860 - accuracy: 0.9000 - val_loss: 0.4118 - val_accuracy: 0.8822\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3775 - accuracy: 0.9019 - val_loss: 0.3985 - val_accuracy: 0.8822\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3682 - accuracy: 0.9029 - val_loss: 0.3900 - val_accuracy: 0.8867\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.9010 - val_loss: 0.3859 - val_accuracy: 0.8778\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3590 - accuracy: 0.9019 - val_loss: 0.3827 - val_accuracy: 0.8822\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3429 - accuracy: 0.9133 - val_loss: 0.3724 - val_accuracy: 0.8889\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3395 - accuracy: 0.9095 - val_loss: 0.3727 - val_accuracy: 0.8844\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3309 - accuracy: 0.9095 - val_loss: 0.3583 - val_accuracy: 0.8844\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3248 - accuracy: 0.9143 - val_loss: 0.3684 - val_accuracy: 0.8911\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3213 - accuracy: 0.9162 - val_loss: 0.3575 - val_accuracy: 0.8867\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3167 - accuracy: 0.9076 - val_loss: 0.3553 - val_accuracy: 0.8911\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.9105 - val_loss: 0.3376 - val_accuracy: 0.8867\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.9029 - val_loss: 0.3358 - val_accuracy: 0.8844\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.9124 - val_loss: 0.3406 - val_accuracy: 0.8822\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.9133 - val_loss: 0.3243 - val_accuracy: 0.8911\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2954 - accuracy: 0.9143 - val_loss: 0.3238 - val_accuracy: 0.8822\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2968 - accuracy: 0.9076 - val_loss: 0.3163 - val_accuracy: 0.8911\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.9086 - val_loss: 0.3201 - val_accuracy: 0.8844\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2841 - accuracy: 0.9133 - val_loss: 0.3110 - val_accuracy: 0.8889\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2813 - accuracy: 0.9143 - val_loss: 0.3096 - val_accuracy: 0.8933\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.9086 - val_loss: 0.3116 - val_accuracy: 0.8889\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.9124 - val_loss: 0.3054 - val_accuracy: 0.8933\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.9143 - val_loss: 0.3035 - val_accuracy: 0.8956\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.9114 - val_loss: 0.3001 - val_accuracy: 0.8933\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2667 - accuracy: 0.9095 - val_loss: 0.2933 - val_accuracy: 0.8933\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.9152 - val_loss: 0.2979 - val_accuracy: 0.8822\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.9143 - val_loss: 0.2947 - val_accuracy: 0.8933\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2603 - accuracy: 0.9171 - val_loss: 0.2869 - val_accuracy: 0.8978\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9171 - val_loss: 0.2864 - val_accuracy: 0.8956\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2514 - accuracy: 0.9162 - val_loss: 0.2859 - val_accuracy: 0.8956\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2515 - accuracy: 0.9190 - val_loss: 0.2852 - val_accuracy: 0.9000\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9124 - val_loss: 0.2896 - val_accuracy: 0.8956\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2493 - accuracy: 0.9200 - val_loss: 0.2737 - val_accuracy: 0.9000\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2452 - accuracy: 0.9162 - val_loss: 0.2800 - val_accuracy: 0.9000\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.9162 - val_loss: 0.2736 - val_accuracy: 0.9044\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2459 - accuracy: 0.9181 - val_loss: 0.2972 - val_accuracy: 0.8889\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2412 - accuracy: 0.9181 - val_loss: 0.2797 - val_accuracy: 0.8978\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2418 - accuracy: 0.9190 - val_loss: 0.2720 - val_accuracy: 0.9000\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2366 - accuracy: 0.9257 - val_loss: 0.2664 - val_accuracy: 0.9067\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2383 - accuracy: 0.9171 - val_loss: 0.2652 - val_accuracy: 0.9022\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[129   6  13]\n",
            " [  6 135   2]\n",
            " [ 16   1 142]]\n",
            "\n",
            "P-Score: 0.903, R-Score: 0.903, F-Score: 0.903\n",
            "[0.9022222222222223, 0.9031558199466057, 0.9029197755612849, 0.9029929508161412, 0.8993869697512081, 0.960627320562174, 0.920767684626856, 0.9269273249800793]\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_57 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_58 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_59 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 27ms/step - loss: 1.1018 - accuracy: 0.3705 - val_loss: 1.0853 - val_accuracy: 0.3356\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0813 - accuracy: 0.5048 - val_loss: 1.0772 - val_accuracy: 0.5400\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0727 - accuracy: 0.4771 - val_loss: 1.0664 - val_accuracy: 0.6333\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0636 - accuracy: 0.6267 - val_loss: 1.0569 - val_accuracy: 0.6333\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0545 - accuracy: 0.5371 - val_loss: 1.0497 - val_accuracy: 0.5889\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0439 - accuracy: 0.5057 - val_loss: 1.0354 - val_accuracy: 0.4822\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0167 - accuracy: 0.5048 - val_loss: 1.0010 - val_accuracy: 0.7378\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9867 - accuracy: 0.8219 - val_loss: 0.9798 - val_accuracy: 0.7956\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9621 - accuracy: 0.8333 - val_loss: 0.9606 - val_accuracy: 0.7822\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9411 - accuracy: 0.8410 - val_loss: 0.9267 - val_accuracy: 0.8489\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9195 - accuracy: 0.8086 - val_loss: 0.9077 - val_accuracy: 0.8689\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8932 - accuracy: 0.8752 - val_loss: 0.8805 - val_accuracy: 0.8333\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8691 - accuracy: 0.8619 - val_loss: 0.8561 - val_accuracy: 0.8556\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8445 - accuracy: 0.8838 - val_loss: 0.8360 - val_accuracy: 0.8622\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8215 - accuracy: 0.8305 - val_loss: 0.8224 - val_accuracy: 0.8667\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7984 - accuracy: 0.8838 - val_loss: 0.7866 - val_accuracy: 0.8600\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7720 - accuracy: 0.8752 - val_loss: 0.7647 - val_accuracy: 0.8644\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7492 - accuracy: 0.8810 - val_loss: 0.7407 - val_accuracy: 0.8578\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7244 - accuracy: 0.8790 - val_loss: 0.7197 - val_accuracy: 0.8644\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7024 - accuracy: 0.8800 - val_loss: 0.6961 - val_accuracy: 0.8556\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6809 - accuracy: 0.8800 - val_loss: 0.6789 - val_accuracy: 0.8667\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.8743 - val_loss: 0.6561 - val_accuracy: 0.8600\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6388 - accuracy: 0.8800 - val_loss: 0.6351 - val_accuracy: 0.8644\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6174 - accuracy: 0.8790 - val_loss: 0.6158 - val_accuracy: 0.8556\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5956 - accuracy: 0.8857 - val_loss: 0.5983 - val_accuracy: 0.8556\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.8819 - val_loss: 0.5831 - val_accuracy: 0.8644\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5602 - accuracy: 0.8829 - val_loss: 0.5695 - val_accuracy: 0.8689\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5358 - accuracy: 0.8810 - val_loss: 0.5411 - val_accuracy: 0.8533\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5205 - accuracy: 0.8810 - val_loss: 0.5309 - val_accuracy: 0.8733\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.5029 - accuracy: 0.8886 - val_loss: 0.5162 - val_accuracy: 0.8667\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4888 - accuracy: 0.8876 - val_loss: 0.5001 - val_accuracy: 0.8644\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4748 - accuracy: 0.8810 - val_loss: 0.4957 - val_accuracy: 0.8800\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4640 - accuracy: 0.8924 - val_loss: 0.4849 - val_accuracy: 0.8689\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4550 - accuracy: 0.8924 - val_loss: 0.4698 - val_accuracy: 0.8733\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8943 - val_loss: 0.4553 - val_accuracy: 0.8689\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4311 - accuracy: 0.8914 - val_loss: 0.4474 - val_accuracy: 0.8778\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4253 - accuracy: 0.8914 - val_loss: 0.4492 - val_accuracy: 0.8778\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8914 - val_loss: 0.4365 - val_accuracy: 0.8844\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8952 - val_loss: 0.4252 - val_accuracy: 0.8778\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3995 - accuracy: 0.8952 - val_loss: 0.4128 - val_accuracy: 0.8778\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3857 - accuracy: 0.8933 - val_loss: 0.4089 - val_accuracy: 0.8711\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3811 - accuracy: 0.8933 - val_loss: 0.3992 - val_accuracy: 0.8778\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.3747 - accuracy: 0.8952 - val_loss: 0.4013 - val_accuracy: 0.8822\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3660 - accuracy: 0.8981 - val_loss: 0.3902 - val_accuracy: 0.8800\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.8924 - val_loss: 0.3838 - val_accuracy: 0.8622\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3549 - accuracy: 0.9000 - val_loss: 0.3837 - val_accuracy: 0.8800\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.9057 - val_loss: 0.3737 - val_accuracy: 0.8822\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3406 - accuracy: 0.9010 - val_loss: 0.3641 - val_accuracy: 0.8711\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8952 - val_loss: 0.3596 - val_accuracy: 0.8800\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.9000 - val_loss: 0.3563 - val_accuracy: 0.8844\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3265 - accuracy: 0.9029 - val_loss: 0.3536 - val_accuracy: 0.8800\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3216 - accuracy: 0.9038 - val_loss: 0.3552 - val_accuracy: 0.8844\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3185 - accuracy: 0.9010 - val_loss: 0.3527 - val_accuracy: 0.8756\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.9010 - val_loss: 0.3431 - val_accuracy: 0.8844\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3110 - accuracy: 0.9048 - val_loss: 0.3345 - val_accuracy: 0.8844\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3109 - accuracy: 0.9000 - val_loss: 0.3472 - val_accuracy: 0.8844\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3047 - accuracy: 0.9086 - val_loss: 0.3369 - val_accuracy: 0.8911\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3013 - accuracy: 0.9067 - val_loss: 0.3259 - val_accuracy: 0.8867\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3044 - accuracy: 0.9057 - val_loss: 0.3267 - val_accuracy: 0.8844\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.9095 - val_loss: 0.3243 - val_accuracy: 0.8911\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2895 - accuracy: 0.9057 - val_loss: 0.3139 - val_accuracy: 0.8933\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.9076 - val_loss: 0.3115 - val_accuracy: 0.8933\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.9105 - val_loss: 0.3251 - val_accuracy: 0.8800\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2818 - accuracy: 0.9105 - val_loss: 0.3074 - val_accuracy: 0.8889\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2800 - accuracy: 0.9124 - val_loss: 0.3030 - val_accuracy: 0.8911\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2760 - accuracy: 0.9114 - val_loss: 0.3076 - val_accuracy: 0.8933\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.9105 - val_loss: 0.2980 - val_accuracy: 0.8933\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.9114 - val_loss: 0.3142 - val_accuracy: 0.8867\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.9086 - val_loss: 0.2950 - val_accuracy: 0.8889\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.9133 - val_loss: 0.2961 - val_accuracy: 0.8911\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2622 - accuracy: 0.9143 - val_loss: 0.3023 - val_accuracy: 0.8867\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2619 - accuracy: 0.9162 - val_loss: 0.2888 - val_accuracy: 0.8911\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.9190 - val_loss: 0.2848 - val_accuracy: 0.8933\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2589 - accuracy: 0.9124 - val_loss: 0.3102 - val_accuracy: 0.8822\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.9181 - val_loss: 0.2809 - val_accuracy: 0.8956\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2528 - accuracy: 0.9152 - val_loss: 0.2793 - val_accuracy: 0.8978\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2507 - accuracy: 0.9190 - val_loss: 0.2941 - val_accuracy: 0.8889\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.9248 - val_loss: 0.2767 - val_accuracy: 0.8956\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2532 - accuracy: 0.9143 - val_loss: 0.2739 - val_accuracy: 0.8978\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.9133 - val_loss: 0.2800 - val_accuracy: 0.8978\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[123  11  14]\n",
            " [  5 137   1]\n",
            " [ 13   2 144]]\n",
            "\n",
            "P-Score: 0.897, R-Score: 0.898, F-Score: 0.897\n",
            "[0.8977777777777778, 0.8971113787412462, 0.8982611388271765, 0.8973416778801994, 0.8857392160372293, 0.9578483405844969, 0.9270569928029566, 0.9235481831415608]\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.871111   0.874461  0.870524  0.871929  0.869183  0.929159  0.910167   \n",
            "1  0.837778   0.837070  0.835406  0.835569  0.845534  0.869525  0.916164   \n",
            "2  0.817778   0.820666  0.818803  0.817811  0.854081  0.866313  0.872171   \n",
            "3  0.786667   0.789179  0.783596  0.784001  0.835064  0.792214  0.888413   \n",
            "4  0.882222   0.882953  0.882021  0.882401  0.877595  0.933134  0.923912   \n",
            "5  0.762222   0.769395  0.760926  0.762716  0.833475  0.772910  0.857842   \n",
            "6  0.828889   0.830538  0.826396  0.827138  0.835533  0.869046  0.906147   \n",
            "7  0.811111   0.813948  0.812905  0.811151  0.862426  0.866552  0.849575   \n",
            "8  0.902222   0.903156  0.902920  0.902993  0.899387  0.960627  0.920768   \n",
            "9  0.897778   0.897111  0.898261  0.897342  0.885739  0.957848  0.927057   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.902836  \n",
            "1       0.877074  \n",
            "2       0.864188  \n",
            "3       0.838564  \n",
            "4       0.911547  \n",
            "5       0.821409  \n",
            "6       0.870242  \n",
            "7       0.859518  \n",
            "8       0.926927  \n",
            "9       0.923548  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3zU9f3A8dc7e++wEiDIJkDYS1QUcVVxIu6trauOtmqrVWpt669b66jYOnALVou7KiAukKEoUzYJAbL3zn1+f3zuwmVfQo6Mez8fjzy4u++4z13C9/39vD9LjDEopZTyXX6dXQCllFKdSwOBUkr5OA0ESinl4zQQKKWUj9NAoJRSPk4DgVJK+TgNBKoREXlfRK7s6H07k4jsEZGTvXBeIyJDnI//KSK/9mTfdrzPpSLyv/aWU6mWiI4j6BlEpMTtaRhQCdQ6n//YGPPS0S9V1yEie4DrjDEfd/B5DTDUGLOjo/YVkRRgNxBojKnpiHIq1ZKAzi6A6hjGmAjX45YueiISoBcX1VXo32PXoKmhHk5EZolIhojcLSIHgWdFJFZE3hGRbBHJdz5OdjtmhYhc53x8lYh8LiJ/du67W0ROb+e+g0RkpYgUi8jHIvK4iLzYTLk9KeNvReQL5/n+JyIJbtsvF5G9IpIrIve28P1MFZGDIuLv9tq5IvKd8/EUEflKRApE5ICIPCYiQc2c6zkRecjt+S+cx2SKyDUN9v2RiHwjIkUiki4iC9w2r3T+WyAiJSIy3fXduh0/Q0TWiEih898Znn43bfye40TkWednyBeRt9y2nS0i3zo/w04ROc35er00nIgscP2eRSTFmSK7VkT2Acucry92/h4KnX8jqW7Hh4rIX5y/z0Ln31ioiLwrIrc2+Dzfici5TX1W1TwNBL6hDxAHDARuwP7en3U+HwCUA4+1cPxUYBuQAPwR+LeISDv2fRn4GogHFgCXt/CenpTxEuBqoBcQBPwcQERGAU86z9/P+X7JNMEYsxooBU5qcN6XnY9rgTucn2c6MBu4qYVy4yzDac7yzAGGAg3bJ0qBK4AY4EfAjSJyjnPb8c5/Y4wxEcaYrxqcOw54F3jU+dn+CrwrIvENPkOj76YJrX3PL2BTjanOc/3NWYYpwCLgF87PcDywp7nvowknACOBU53P38d+T72A9YB7KvPPwERgBvbv+C7AATwPXObaSUTSgCTsd6PawhijPz3sB/sf8mTn41lAFRDSwv7jgHy35yuwqSWAq4AdbtvCAAP0acu+2ItMDRDmtv1F4EUPP1NTZbzP7flNwAfOx/cDr7ptC3d+Byc3c+6HgGecjyOxF+mBzex7O/Cm23MDDHE+fg54yPn4GeBht/2Gue/bxHn/DvzN+TjFuW+A2/argM+djy8Hvm5w/FfAVa19N235noG+2AtubBP7PeUqb0t/f87nC1y/Z7fPdkwLZYhx7hONDVTlQFoT+4UA+dh2F7AB44mj/f+tJ/xojcA3ZBtjKlxPRCRMRJ5yVrWLsKmIGPf0SAMHXQ+MMWXOhxFt3LcfkOf2GkB6cwX2sIwH3R6XuZWpn/u5jTGlQG5z74W9+z9PRIKB84D1xpi9znIMc6ZLDjrL8Xts7aA19coA7G3w+aaKyHJnSqYQ+ImH53Wde2+D1/Zi74Zdmvtu6mnle+6P/Z3lN3Fof2Cnh+VtSt13IyL+IvKwM71UxOGaRYLzJ6Sp93L+Tb8GXCYifsDF2BqMaiMNBL6hYdewnwHDganGmCgOpyKaS/d0hANAnIiEub3Wv4X9j6SMB9zP7XzP+OZ2NsZsxl5IT6d+Wghsimkr9q4zCvhVe8qArRG5exlYCvQ3xkQD/3Q7b2td+TKxqRx3A4D9HpSroZa+53Ts7yymiePSgcHNnLMUWxt06dPEPu6f8RLgbGz6LBpba3CVIQeoaOG9ngcuxabsykyDNJryjAYC3xSJrW4XOPPND3j7DZ132GuBBSISJCLTgbO8VMYlwJkiMtPZsPsgrf+tvwzchr0QLm5QjiKgRERGADd6WIbXgatEZJQzEDUsfyT2brvCmW+/xG1bNjYlc0wz534PGCYil4hIgIjMB0YB73hYtoblaPJ7NsYcwObun3A2KgeKiCtQ/Bu4WkRmi4ifiCQ5vx+Ab4GLnPtPAi7woAyV2FpbGLbW5SqDA5tm+6uI9HPWHqY7a284L/wO4C9obaDdNBD4pr8Dodi7rVXAB0fpfS/FNrjmYvPyr2EvAE1pdxmNMZuAm7EX9wPYPHJGK4e9gm3AXGaMyXF7/efYi3Qx8LSzzJ6U4X3nZ1gG7HD+6+4m4EERKca2abzudmwZ8DvgC7G9laY1OHcucCb2bj4X23h6ZoNye6q17/lyoBpbK8rCtpFgjPka2xj9N6AQ+JTDtZRfY+/g84HfUL+G1ZRF2BrZfmCzsxzufg58D6wB8oD/o/61axEwBtvmpNpBB5SpTiMirwFbjTFer5GonktErgBuMMbM7OyydFdaI1BHjYhMFpHBzlTCadi88FutHadUc5xpt5uAhZ1dlu5MA4E6mvpguzaWYPvA32iM+aZTS6S6LRE5FduecojW00+qBZoaUkopH6c1AqWU8nHdbtK5hIQEk5KS0tnFUEqpbmXdunU5xpjEprZ1u0CQkpLC2rVrO7sYSinVrYhIw9HodTQ1pJRSPk4DgVJK+TgNBEop5eM0ECillI/TQKCUUj5OA4FSSvk4DQRKKeXjNBAopVQXU+swLF6bztaDRUfl/brdgDKllOrJdmWX8PPFG1i/r4CwIH8ev2QCJ47o5dX31BqBUkq1056cUoorqjvkXA6H4dkvdnPGo5+xI6uEh84ZzTGJ4Vz7/BpeXNXsoOAOoTUCpZTPcDgM6fll1DoOz7oc6O9HYmQwIYH+dft8v7+QZVuzWLk9m34xoTxw5ih6RYXUHVNd6+D/3t/Kvz7fTWigP2eM6cv8yf2ZnBKLSP0lrSuqa/nhUDGbMotIzyurt62sqpas4gqyiyvZn19OZmEFJw5P5OHzx9I7KoRzxydxy8vrue+tjWTkl3PXqcPx8+v4pcW73TTUkyZNMjrXkFJNyyqqYGNmIRv3F7Eps5CkmDDuPn04wQH+Hfo+xhiMod0XJYfDeHys6xrV8ALblFqH4ZMth6iuNSRGBtMrMpiwYH++3p3H8q3ZfPpDFjklVU0eGxkcQGJUMEXl1eSUVCECY5Nj2HqgiJBAfx48O5W5af3ILq7k5pfXs2ZPPpdMHYAx8PaGTEoqa+gfF0pCRHDdOcsqa9mZXUKNM/D4+wnuHzskwJ/EKFvOxMgQZg1L5LwJSfU+a02tgweWbuKl1fv45ekj+PEJgz363hoSkXXGmElNbtNAoFTXVF5Vy5//t42hvSI4M60fEcFNV+CNMXz6QzaPLdvB2r35AIjAgLgw9uaWMSUljoVXTCQmLMjj93Y4DF/tyiU9r4zs4kqyiivJKq6w/xZVkl1SSWxYIA+dM4Y5o3q3eK5d2SU89+UedmaXkFVkz1VSWcPZaf24+/QR9Ha70wYoLKvmsx3ZdcFsU2YRVTUOZg5J4KQRvZg1PLHe3bnL17vz+M3bm9iU2XQDa3RoICcMS2T64HjCgg4HxsoaB9nFlXU/QQF+nDAskeOHJRIXHsROZ87+m30FnDyyF9+mF1JaWcPD54/h7HFJAJRV1fDudwf4cNMhKmtq684dHODHsN6RjE6KZnS/aPrHhXoU0BoyxvD62nTOGNOXyJDANh8PGgiU6nYcDsPNL6/n/Y0HAQgL8udHY/py3oRkEiIOX9B3ZJXwxIqdfL+/kH7RIVwxI4WJA2MZ2TeKiOAAlm7I5OevbyA5LpTnrprCgPgwHA7DpswiVu/OZdox8YxOiq733rUOw91vfMeSdRl1r8WEBZIYEUyvqGB6RYbQKzKYldtz2HKgiPMnJHP/WaOIDq1/gdpyoIjHl+/g3e8PEBzgR2q/6Lpz2F4xGQT6CzefNIRrjh3E+n35vL4mnfc3HqSyxkGgvzC8TySpfaPx84MV27I5UFgBwJBeEYzuF0Vqv2iG9o5gyboM3vnuAP2iQ7j79BEM7xNpA1ZxJQXl1aQlRzOufwwB/u1rFq2pdbDws138/aPtJMeG8s/LJzKsd2S7ztVZNBAo1c384b0tPLVyF/f9aCTjB8Ty+pp03v4uk7Kq2kb7psSHcdOsIZwzPomggMYXuq9353H9orUE+gsnDOvFyu3ZZBdXAhDoL9x/ViqXTR2AiFBd6+DO1zfw9oZMbj1pCPMn9ycxMrjJ1FJVjYN/LNvOEyt20isymIsmDyC/rMrmuwvK+Ta9gPAgf66YkcK1MwfVS5mAbWj93Xtb+GjzIYID/KiscRAZEsA545I4d0ISo/tF1/s8xhi2Hixm+bYs1u/NZ+P+Ig4W2cAQHODHj08YzI0nDCY0qGPTYO4OFVUQHRpY157QnXRaIHAuUP4I4A/8yxjzcIPtA4FngEQgD7jMGJPR6ERuNBAob9ubW0pQgB99o0M75f1fWr2Xe9/cyOXTBvLg2al1qYTSyhq+3JlbL/UQGRLIsYPjW73T3ZldwvXPryWnpJIThvfixOGJpPWP4bfvbGbFtmzOG5/EA3NTuWvJBj7cdIi7TxvBjbM8y0VvSC/g54s3sD2rxObZI4NJjAxmxuAErpwxsNWU1Gfbs/nvt5nMHJLAaaP7tOkim1NSydYDxQzuFd5pv69mORxQlgMR7ej6ufm/8MEvISweZtwKqeeCf/tSQi6dEghExB/4AZgDZABrgIuNMZvd9lkMvGOMeV5ETgKuNsZc3tJ5NRAob9mUWcjjy3fw/saDJEYE886tMxvlovcXlHP982uZODCWO+cMIza85YtcUUU1u7JLySpy5teLK/EXYVS/KEYnRdEnKgQRwRhDUUUNX+7I4ZZXvuH4oQk8fcWkdqcymmKMwWFsg6WLw2H4x7Id/P2THwgN9Kesqpb7zxzFNTMHtencDoehssbh1bvxbqO6HDa8Cl89Dnk74ap3YeAMz44ty4P374LvF0OfMVBTBTnbICoJpt0IE66AkOjWz9OEzgoE04EFxphTnc9/CWCM+YPbPpuA04wx6WJvewqNMVEtnVcDgepIFdW1fLUzlxdX7eWTrVlEBgdw/sRkXluTTmq/KF6+flpdeqKoopp5T37FvrwyKmtqiQwJ5M45w7h06gAC/P3IKalkU2YRG/cXsjmziI2ZhezNrd9d0NVO6PpvFx8eRFiwP1lFlVTWOAAY1TeK138yvdnGYW/49IdsfvP2Jq6beQyXTB1w1N63S3M4YNdy8POHQScc/uW5VJbAlqVQXnD4tdIsWP+CrQn0HQdluRAYCj/5HALqp8bqGAMFe2H3Z7DsIXvs8XfBcXeC+MOOj+DLf8Cez+CUh2wNoR06KxBcgL3IX+d8fjkw1Rhzi9s+LwOrjTGPiMh5wBtAgjEmt8G5bgBuABgwYMDEvXu9O7hCdR8Oh+HzHTm8v/Ego5OiuGBicqtdJbOLK/lg4wGWb8vmy505VFQ7iAkL5NpjB3HFjBSiQwNZuiGTn77yDVdMH8iDZ4+mutbBNc+t4auduTx/zRTiI4J48O3NfLkzlwFxYVTVOOry1WB77KT2i2J0UjTDekfS29nIGh8RRFWNg60Hi+p6xVTVOOgVFeLsQhjMrOG9GjW8qg6yb7W9sCaOgP5TITq58QW+ugK+ew2+egxyfrCv9RoF02+BMRdAeT6sfgrW/hsqChu/x7DT7MV64LGw8xN48XyY9UuYdU/9/XYug7XPQPrXUHLI+T6pcO6T0Det8Xkzv4G4Y7pdjcCTQNAPeAwYBKwEzgdGG2MKmjgloDUCZWXkl7F4bQZL1mWwv6C8rrGxT1QINxx/DBdPGVAvTVFT6+DTH7J5bU06y7ZmUeMwDIgLq+uOOO2Y+Ea56d+9u5mnP9vNny4Yy/p9+bzydTp/PH8sF07uD9hUy4ebDvH8l3voHRXM6KRoUvtFM6pflF7Ij5QxUJgB6ashYw1UFEHSBHvx7jUK/NtQW3LUwtZ37V11xtf1t0X2g96p4Oc6n4H966A0G/qMtRd0R609NmsThCfaGoCphRFn2uCQOPzw+fwDISi8/nu8cZ3N+f/k88P7rnse3rkdIvrAoOOg/5TDn83PO+m1LpsaarB/BLDVGJPc0nk1EPiGb9ML2HawiOF9ohjRJ5KQQH8qa2r536ZDvL42nc935AAwc0gC8yf3Z86o3qzZnc8/lm1n9e48YsIC6R15OL+fW1pJTkkVCRFBnDchmQsmJjO0V0SLfbprah1c8czXrNqVi8PAzScO5henjvD6Z+/Rqsthwyuw6U0YOBMmXwfh8Ye3F2XC6n/Cd4uhONO+FhhmL66l2fZ5UARE969/Jz/+cph+U+P3y90JL18IuTsgZiBMvxnGzof8PfZOPONre9fvfh2M7g9TfwyDjq+fy9u5DNY9C5F9bb4+7hjPPnNJNjw2yV7kr3oXPvsLLH8IBs+GCxdBcITHX9+R6KxAEIBtLJ4N7Mc2Fl9ijNnktk8CkGeMcYjI74BaY8z9LZ1XA0HPZYxh9e48Hlu2o+5CD7Zxc0hiBFnFFeSXVZMUE8oFE5OZNymZ5NiwRuf5encer369r15Xy9Agf05N7cPskb0IbEMDbF5pFRf880smDIjlj+ePbXo0bG31EffoaJbr/2drg5DKC+B/90LGWhh3KUy88nAKoboCvn8dvn7aXlCn3QQjfuT5nacx9o54/fNw7lOQ3OBaUlUKb/4YSnPgrEfq3yG7lGTDmn/Bmqdt3jw2xV6MA0Jg3CX27vr7xfbHOGDY6XDMLHun3Hu0LWvBPnvxTl8NJQcPn7so097Fz30MJlxe/z3/Pcemb878K4yc67W77VZ98yL892ZInmKDz9j5cPbj3vu7aUJndh89A/g7tvvoM8aY34nIg8BaY8xSZ/roD4DBpoZuNsZUtnRODQRtU1RRTZC/X5fu95xVVMGKbdksXpfOmj35JEQEc8Pxg5g9sjfbnXO0bNxfSGRIIBdMTObYIQn1er54m6MkB7+QyKYb+zYvhTeutRezUx6C4FYGGVUUQk1l610KHbU2R738D9B7lE1RjDir6ZTIjk9g6a1QfND2NDnwLQRFHg4GXy+0d9O9x0BlkW2YjB1k745Tz6t/R96oHA4bYFY9AQGhNiBduAiGzrHbS3PtHXfmevvZqytg9q9tsPHzh5zt9nN8+wrUVtoL/IxbbS+anB/stg2v2W2B4bZXzLSf2EDhqZoqW4bdK+GS12HoyTY4PXcmZG2BK9+G/pM9P583GAPPn2UbfGfcCic/CH5Hd85PHVDWyXZll5BbWsXklLij+r6FZdWc/shK4iOCeePGGU0ONnJXXlXL2xsymTOqd6vdIj1RXlWLCPWCkDGGQ0WVbNxfyLfpBSzfllU3JUBybCg3HH8MF07q33UCV1merdZH9IHL3oCovoe37VsFi86G8F5QmA4x/eHsJ2zOt6H8vbDqSVi/yF4gL3q56f3ApjPeutHe+Q4+yd455+2yqY0p19vUhMuez2Ddc5AwDM79JyRNtI2KXz5m0y+mFobMgRm32J4vxgFb3rZ3+Pud/4/ih9j8tCtPnTDcXqRqqmw5Ni6BqTfCzNvhpXmQtdnefaccCy+cZz/7+f+G5Mk2773tPRgwHUJj7WP/YBh3MUy7GRKHNf68JVmw9wtbAwiNbd/vqaIInjsDcnfBlUvh0z/aRuH5L8GIM9p3zo5WmmuD9JDZnfL2Ggg62eX/Xs2u7FK+uOekDj93YXk1e3JKSesf02jb7a9+w9INmTgM3HrSEH52ShNVdqdah+Gml9bx4aZDRIfW7xbZVpkF5Tz16U5eXZNOZY2DqBA7yCg2LIjdOaXkltpJv/z9hIkDYpk1IpETh/diRJ/Ids3D4lUf3mv7gweF24vUZf+xF7PsH+CZUyA0Dq79CHK324tm3i6br45z64d/4DvbzVD8YPQF9kKdvxvO/xeMOvvwflVlthfJsocgIAjO+DOMmWcv3tvesxfv9NUNCij2zv6k+2w3RXdFmVBT0XQu2xh7F7975eF0S5mzs15wtE3/VJXY109eAMfebmsDFUXw2mWw+1MIiQEMXPwaDJx++LwbXoX377YBb8r1MPl6iEg8st+DJ4oO2FRQUaYNgD/6i22DUIAGgk5VVlXDuN98hMGw7bend+gUsqWVNVz41FdsyiziN3NTuXJGSt22d787wM0vr+f2k4eSnlfOm99ksOTGGUwY0PQdl6uHzI2zBvNdRgFf7MhlWO8IHjgrlWOHJHhUnh1Zxfzrs928sT4DY+Dc8UkMjA+rm7Qsr7SKAXFhzt41UYzsG0X4Uewr32Z5u+GxyZA2317MXrrApmzOfgw+uMc2fF770eGLflUpfLzA5sKN4/B5gqNh0lUw5ccQnWRrGS/Pt71hfvRnm7v++ml7XHkeDDkZ5v4Dovo1LlP+XptacgmJgsg+R/5ZjbFBzBUU0r+2vXZO+wOMv7T+vjWV8N9bIH2VDQK9RzU+n6uMzfWd95bsbfDCuTYYn/jLo/veXZwGgk60fGsWVz+3BoBvfj2nQ1IuYO/gb1i0luXbshg/IJZ1e/O594yRXH/8MWQVVXDK31cyMC6MJTfOoLy6ltP//hlBAX6899PjGo3+fGHVXn791kaunD6QBXNTAfjf5kM89O5m0vPKmT+pP/edObLRrIeVNbWs2pXH8q1ZrNiWxZ7cMoIC/Lhocn9uOP6YJhtyj4qyPPjo1zDpGpsqaa/FV8MPH8Ct6+xFOW+Xvcjk77H57KvesV0aG6qtrh8I/AIaN1JWlcES5/n9AsFRA8Od+fMB01tvHD4ajGm5HK1t7yxdtVydrKVA0IVvx3qGT3/IrnucVVzZ5kBQVFHNgv9u4oThifxoTN+6VM1v39nMJ1uz+O05o7locn9uf/VbfvfeFiqqa1m/L5/yqlr+cuE4Av39CPT340/zxnLJ06v5w/tbePDs0XXnX74tiwf+u5HZI3px/1mH57U5NbUPJwxL5JFPtvPUpzv5fEcOf7pgLDOGJLA5s4jX16bz5jf7KSyvJjjAj2OHJHDtzEGcOroPvSIbTxF8VH30a9tLY+N/4MIXbONhW6WvgU3/sSM8XXfmccfYGsCHv7I9c5oKAuBZT5CgMJu//mSBDQrTboSEoW0vpze1djHtqhfbrlquLkxrBF520l9WkFNcSVFFDS9eO5WZQz1Ls7i89/0BbnppPWBnmbxx1mCKK2p46N0tXDdzEPedaavlNbUO7lryHf/5Zj8AD5w1iquPrT9fzINvb+aZL3ZzwrBE8suqnHPDVzCybxSv/3h6s2madXvz+fniDezOKWVwYjg7s0sJ8vfjlNTenDchiRmDE9rXuFuaA9VuUzCERLd71GSd3Stt74yJV9suhVmbbTe9tIs8P4cx8Mxptgbw0/Wt9wRSqhvQGkEnSc8rY1d2KZdNG8CLq/aRXVLR+kENbM4swt9PeOSicTz16S7ufuN7AE5N7c2vzhhZt1+Avx9/npdGXHgQ+WXVXDk9pdG57jptOOn5ZWTkl9MrMphhvSPpFx3C5dNTWszVTxwYy3s/PY6//G8bGzIKuGzaQM4Zl3Rkaa7VT9kGRdxuRPyD4byFkHpO+85ZXQFv3267Rp72B5uiee1S28c9f+/hBk2wqZ3eqRDYoPbicNg+9+mr4My/axBQPkEDgRet3G7TQudPSLaBoLjFIRJN2nKgiMGJ4Zw5th8/GtOXT3/IZvXuPH560tBGDc9+flJXQ2hKSKA/T1/R5A1Bq0KD/Fs8d5ts/q8NAkPn1O81s34RLL4KSv9ke5u0JH2N7cnj3lD52Z/tbI+Xv2V70ASGwqVLbCBY8fvG5/APshOD9Z8CwVG28Tbja9vXP3GkbXBUygdoIPCiT7dlkxQTyrj+MQQH+B0OBPtW2TyyBw2ZWw4UMXmQHX8gIswa3otZw9sxv3lXsfcreON62+f8wkX1uzymnmcbUN/7uZ2E68R7m873rvk3vPszwNh+9jNutf38P/8bpF0Mg088vG9AMJz/DEy/FWrKD79elue88K+xPXZqq+xEZKPOsYFh+Bltm89GqW5M/9K94dAman/4iC93juCsNLsQdWJksA0EVaW266CjBn68EuKbX/yjoKyKzEKbw+8RsrfBKxfZgVeXvNa437urAfWd22Dln2zvnJPuOzzK1BhY8TB8+rCd4TF5sh01+8K5Nq0UHAWn/K7x+/r5QXITQXfUXPtvTaX9Cekh37NSbaSBoKNVV8DrV+Cfu4NJ1b/ghGF2OtnEyGCySyrh25ehosBOpLX4KrjuYx7+aDdTB8Vx4oj6d/qbD9gRt10yEBgDK/9sP8vJC1rvKVNRCC9eYNMxl70BYc2MsvYPsKNWo5JtqmfjG7af/fSb4duX7CjacZfZOW38A2xt4PvFdg74Gbe0PF1CcwKCj35/d6W6kKM72YUv+OwvkLuDcv8obgt4kxmD7YWpV2QwOUXldpqBpIl2SP7B76j98D4WrtzJvz/f3ehUWw4UA3ahkmZ986Id5t+e3l/l+XY+lh8+bNtxtdV2FO3yh+xcMa9eYms6LVm9EAr3wUUvtT6PjIgdDHTbd/ZCv3O5HTG67jmYeacd0OVK2wQEw/jL4NoPYeRZbfscSilAA0HHytpq89Rj5/PvkCsY77eDqMzPAVsjGFH8lW3MnH6znf9k6o34r1nIybKGNXvy6q1FC7Z9ICHCLlbSpIJ98N5ddvGL/D1tL+/aZ+1cNf+53vaqacgY28XTPchUltj0zoZX4MT7bM+aHR/D83PtXCpNqSy2AWPY6Tb/7qnoJJjzINy5CU7/o5358uQHtJ+4Uh1MA0FHcTjg7dsgOILcmQ/waO5kioN7w4r/A2NIjAhhfs3bmKgkGOnsKTPnN5TEjeaPgQuJr8nim3311+PZcqCIkX2b6b5oDLz7czuXDNg+821RU2Xz633H2XO9ca2906/bXmlf+9Ng+/PyRba2s2iunZf9rEfhhF/ApKvtoK2D38Mzp9rg1NDXT9sU0gm/aFsZXYIj7fzwbRkLoJTymAaCjrL+Odv3/NTf89l+qCKQook329f2fMZQs5sZ/pspTrumXlrjs9A+duYAACAASURBVHF/xB8Hfwx8ii/d5uCvrnWw/VBJ82mhTW/C9g/tHXJAKOxf37bybn4Lig/Yxtiz/m57zyx7yG6rKLKzTG58w86PM+x0u7DHJw/CoU0w/0U7xbHLyDPhirfseq3Pz7XzwLtUltjawJA5Rzbdg1LKa7SxuCMUH4KPFtgVjdIuZvlr3xIfHkTfWTfAd0/Ap39knImn1ASzL2Ueo90O3VaVyBc1F/FQ4LN8s+k1OMWuy7Mzu4SqWgej+jURCMrzbT/8fuPtUnlb32tbjcAYe3FOGGZXSfLzg12fwhd/h14j7WybhzbBOf+00we7lOXZY5tqkB04Ay59w47qfflCOw9PULidTbMsF064y/PyKaWOKq0RdITtH0JlIZz6B2ochhXbspk1vBd+QaF2Dvc9n9F331Jer53Foar6I1n355fzcdgZZESM4dKCpygrsItYb2mpx9BHD9iL61mP2MnMkibCgQ31Uzst2ful3X/ajYcXxzjtYTuI6s0f27v/S16rHwTA9vRpqVdO/8lwwTN2zvXFV9u2gS8fhWNObFvbgFLqqNJA0BHydtsZJhNH8E16AYXl1Zzk6go64Uq7cIkxPFt7WqPRxRn55fSLDefg8f9HJOUU/fduwPYYCgrw45iEBgth715plwycfjP0tV1TSZpgB0tlbfGsvKuesHPrj3XLuQeFwYXP2xTOlW8fXoGqrUacAWf8yQbHhSfalbFOuLt951JKHRUaCDpC/h674LV/AJ9sySLATzhumHNyuaAwOOsRak9+kH2md6NAsL+gnOTYMEaNm8rTjrPos/tN2LmcLQeKGNY7ov7CMKU58J8b7IpSs+45/Lor9+5Jeih3J2x9FyZda8vmLnE4XLak8Zq0bTX5OtvNM3c7pBxXf44fpVSXo4GgI+TvrlucZPnWLKYMiiPKfe7+EWcQMPOnRIcG2kFlTrUOQ2ZBOUmxoYQFBfBFv2vY79cP884d7NyfXb+h2Bjbd78sDy541ubfXWJT7EpZngSC1U/Z2ktrc/kcqdn3266lc//h3fdRSh0xDQQdIX8PxKaQkV/GtkPFh9NCDdRNM+GUVVxBjcOQHGunWpg0pC+/qLgayd/N4zUPMC3KrV/+V4/D9v/Bqb+DvmPrn1jE1gpa6zlUVWZH544+v2NWtWqJiO1aGjeo9X2VUp1KA8GRKi+wvXhiU1i+NQug+UAQUT8QZOTbSdCSYmwgmDE4ni8dqbwy8EFS5CDnrL7IBoCMtXYJxBFnNr8Ga9JEyN5iu2s2Z/uHdh3acZe0/XMqpXosDQRHyjWiN3YQn2zNIiU+jGMSI5rctW6+Iaf9zkDgWtJx/IBYQgL9+M2uYZxS+UdqU2bZ1bCeOdXewZ/9WPOjapMm2uURD2xovqwb/2MbrlNmtvVTKqV6MA0ER8oZCMoj+/PlzlxOGtG72V0bpoYy8u3qXK4aQVCAH5NT4qiodhAU05fAy16Dc5600yNf8Kzt6dMc17KJmc2khyqLbWop9ZzG6+cqpXyaBoIj5QwEq/KiqKpxMHtk82sFJEYGU1ZVS2llDWB7DCVEBNVbTH7GYNvbaGTfKHv3P+4SuPEL20e/JeEJEDOw+QbjbR/Y6ShSz/P8symlfIIGgiOVvxvC4vnfzjIiggOYnNLM9MrYNgKgrlaQkV9eVxtwcc1WOqq5OYZakjSx+UCw6T8Q2Q/6T237eZVSPZoGgiOVvwfjbCg+bmgCQQHNf6WuWURd7QT788vr2gdcxiRFc/vJQ5k3qX/by5I00U765j7XD9gG7e0fQeq5h0cSK6WUk14VjlTebopCkjhYVNFoYZmG6gJBcSUOhyHDOYbAnZ+fcPvJw+gfF9bUKVrmGljWsJ1g67vgqIbRmhZSSjWmgeBI1FZDYQaZfrZPfktpIbCL04ANBDmllVTVOOrGEHSIvmNB/Bunhzb9B2IG6OyfSqkmaSA4EoUZYGrJDugHQGxYy8s1xoYF4e8nZBdXNhpD0CGCwqHXKNs7qMSOaaAsD3atsI3EuqCLUqoJOg31kci3y0se8rc1gsiQlgOBn5+QEBFEdnFlozEEHWb8pfDBL+FvqTB2PoQngqNG00JKqWZ5tUYgIqeJyDYR2SEi9zSxfYCILBeRb0TkOxE5w5vl6XDOrqPp9CYyOAB/v9bvuF2DyupqBB2ZGgI7tfQta2H85XZR98//CnGDoc/Y1o9VSvkkr9UIRMQfeByYA2QAa0RkqTFms9tu9wGvG2OeFJFRwHtAirfK1OHy94B/EPtrookKLfToENc0E/sLyogJCyQi2Au/goQhcOZf4cR74ZsX7HTVmhZSSjXDm6mhKcAOY8wuABF5FTgbcA8EBnBNsRkNZHqxPB0vbzfEDKSw0kF0aMtpIZfEyGC2HChmfxNjCDpceLxdGEcppVrgzdRQEpDu9jzD+Zq7BcBlIpKBrQ3c2tSJROQGEVkrImuzs7Ob2qVzOGcdLSyvJirUs5iaGBlMTkkl6fnlHdtjSCml2qmzew1dDDxnjEkGzgBeEJFGZTLGLDTGTDLGTEpMTDzqhWySMfUCgcc1gohgahyGXdklJMV0cEOxUkq1gzcDwX7AfXhssvM1d9cCrwMYY74CQoAEL5ap45TnQ2URxA1qWyCItGsWOwxaI1BKdQneDARrgKEiMkhEgoCLgKUN9tkHzAYQkZHYQNCFcj8tcHYdJTaFovKaNrURuHR4jyGllGoHrwUCY0wNcAvwIbAF2ztok4g8KCJznbv9DLheRDYArwBXGWOMt8rUofJsIKiOGkB5dW39pSlbUC8QeLuxWCmlPODVAWXGmPewjcDur93v9ngzcKw3y+A1zjEEBSFJwD6iWxlV7OIeCPp39GAypZRqBx1Z3F75eyC8F0W1QQAep4bCg/wJDfTH30887mmklFLepFei9nLrMQQQ5WEgEBESI4MJC/JHdJCXUqoL0EDQXvl7YOCMw4HAwzYCgHH9Y4gM0a9eKdU16NWoPWoq7cyjsSkUOQOBp6khgEcvHu+tkimlVJt19oCy7qkgHTDtDgRKKdWVaCBoj5JD9t/Ivm5tBFq5Ukp1TxoI2qM8z/4bGktheTUhgX4EB/h3bpmUUqqdNBC0R3m+/Tcsrk3TSyilVFekgaA9yg7XCNoyvYRSSnVFGgjaozwf/AIhKEJrBEqpbk8DQXuU50FoLIjYtQjaMIZAKaW6Gg0E7VGeD2FxABRVaI1AKdW9aSBoj7J8CLWBwK5OpoFAKdV9aSBoD2dqqNZhKK7QxmKlVPemgaA9yvMhLJbiirZNOKeUUl2RBoK2MsZ2H3V2HQWdXkIp1b1pIGir6nKorYTQuLrpJTQQKKW6Mw0EbeWaXiIszm0Kap1nSCnVfWkgaCvX9BLOeYYAj5epVEqprkgDQVvVTS8RR1GFpoaUUt2fBoK2ajDzKGggUEp1bxoImvHCqr2s2ZPXeEODmUcD/ITQQJ2CWinVfWkgaMafPtjKy6v3Nd5Qb+ZRO72ELkKvlOrONBA0odZhKKqoIb+sqvHG8nwICIXAUJ15VCnVI3gUCETkPyLyIxHxicDhWoc4v7SZQBCm8wwppXoOTy/sTwCXANtF5GERGe7FMnW6AmcgyGuuRhAaC9iAoYFAKdXdeRQIjDEfG2MuBSYAe4CPReRLEblaRHrcldCVEsovrW680Tm9BECRTjinlOoBPE71iEg8cBVwHfAN8Ag2MHzklZJ1osIyGwBKKmuorKmtv7H8cCCwbQQ6qlgp1b15dBUTkTeB4cALwFnGmAPOTa+JyFpvFa6zFJQfTgkVlFXTO8qte6izjcAYo43FSqkewdPb2UeNMcub2mCMmdSB5ekSCsoOp4TySqvoHRVinxjjbCOIo7SqllqH0WUqlVLdnqepoVEiEuN6IiKxInJTaweJyGkisk1EdojIPU1s/5uIfOv8+UFECtpQdq9pGAjqVBaDo6ZuDAHoqGKlVPfnaSC43hhTd5E2xuQD17d0gIj4A48DpwOjgItFZJT7PsaYO4wx44wx44B/AP9pS+G9xTV1BDQIBE3MPKqBQCnV3XkaCPzFbfis8yIf1MoxU4Adxphdxpgq4FXg7Bb2vxh4xcPyeFVBWRXhQbZdoN6gsqZmHtVAoJTq5jwNBB9gG4Zni8hs7AX7g1aOSQLS3Z5nOF9rREQGAoOAZR6Wx6sKyqsZGB8ONKgRuM88Wq7LVCqlegZPG4vvBn4M3Oh8/hHwrw4sx0XAEmNMbVMbReQG4AaAAQMGdODbNq2grJr4iCCiQwPrjy52rxFka41AKdUzeBQIjDEO4Ennj6f2A/3dnic7X2vKRcDNLbz/QmAhwKRJk0wbytAuBWVV9I8LIy48iDy3huP6M4+WAFojUEp1f57ONTRURJaIyGYR2eX6aeWwNcBQERkkIkHYi/3SJs49AogFvmpr4b2loLyamNBAYsMa1AgazDwqApHBOqBMKdW9edpG8Cy2NlADnAgsAl5s6QBjTA1wC/AhsAV43RizSUQeFJG5brteBLxqjPH6nb4nHA47UCwmLNDWCBqmhoIiwT+QoooaIoMD8PPTKaiVUt2bp7ezocaYT0REjDF7gQUisg64v6WDjDHvAe81eO3+Bs8XtKG8XldcUYMxNvcfGxbEpsyiwxvL8yDMbXoJXatYKdUDeBoIKp1TUG8XkVuwuf4I7xWr87iml4gJC6qrERhj7OIzbjOP6vQSSqmewtPU0G1AGPBTYCJwGXCltwrVmVyjimNCA4kND6KyxkF5tbMzU1kehNq1CIrKq3V6CaVUj9BqIHAOHptvjCkxxmQYY642xpxvjFl1FMp31LnWIogNDyQuzI6Zq2snKM+rtyiN1giUUj1Bq4HA2bd/5lEoS5dQ4BxJHB0aRGy4DQR16xJoakgp1QN52kbwjYgsBRYDpa4XjTFdYm6gjuSaOqLPtkXUBqUAzpXKHLVQXlCXGtJAoJTqKTwNBCFALnCS22uGLjJJXEdytRGEf/Z7BiSOBm61YwkqCgEDobFUVNdSWePQwWRKqR7B05HFV3u7IF1FflkVvYKrkapiQg6sJYwK20ZQXmF3CIujqELnGVJK9RyerlD2LLYGUI8x5poOL1EnKyyr5pjgYqgCcVQzw38L+WWjobzY7qBrESilehhPU0PvuD0OAc4FMju+OJ2voLyalOAicHYUmhO0ke9Kz64382hmga0d9IoM7qRSKqVUx/E0NfSG+3MReQX43Csl6mQFZVVMCHSOJo5N4djCDXxaVlVvUZode+2Ec0N69cgxdUopH+PpgLKGhgK9OrIgXUVBeTX9/Artk3GXkuzIxL9wX70pqHdmlxATFkh8eGtr8yilVNfn6eyjxSJS5PoB3sauUdDjFJZV00vyIDAMRp0DwNCir52pIYGQaHZklTA4MQK3RduUUqrb8jQ1FOntgnQFxhgKyquJd+RBZB9IGEp+YG/GVK6D8rEQEg1+/uzMLmH2iN6dXVyllOoQntYIzhWRaLfnMSJyjveK1TlKKmuodRhianMhsi+IsC92GpMc32FKsyAsjoKyKnJKqrR9QCnVY3jaRvCAMabQ9cQYUwA84J0idR7XYLKI6lyIsHf82b1nEinlsHMFhMaxM9s2FA/uFd5ZxVRKqQ7laSBoar8etzSXnV7CEFqRbWsEQHnyTGqMH1JZCKGx7Mhy9hhK9IlsmVLKB3gaCNaKyF9FZLDz56/AOm8WrDPkl1URQTkBtWW2jQCIiEngWzPE7hAWx46sEoID/EiKDe3EkiqlVMfxNBDcih1i9RrwKlBBC4vNd1cFZdX0Fmc3UWeNIC4siM9qx9jXQmPZmV3KoIRw/HWJSqVUD+Fpr6FS4B4vl6XTFZRX00sK7JNI20YQFx7ESsdY7uANCLU1grHJ0S2cRSmluhdPew19JCIxbs9jReRD7xWrcxSWVdGL+jWC2PAgNpjBbEqaR+XgU0jPL9MeQ0qpHsXT1FCCs6cQAMaYfHrgyOKCsmr6Bzg7RznbCMKD/AnwD+Dt5J+z038wxsDgRA0ESqmew9NA4BCRAa4nIpJCE7ORdncF5dUkBxZCUAQE215BIkJseCD5pVV1XUe1RqCU6kk87QJ6L/C5iHwKCHAccIPXStVJCsqq6etXWDeGwCU2LIi8sip2ZJUgAoMSdAyBUqrn8LSx+AMRmYS9+H8DvAWUe7NgnaGwvIpekl/XPuASFx5EfmkVO7JL6B8bRkigfyeVUCmlOp6nC9NcB9wGJAPfAtOAr6i/dGW3V1BWTbzJg8gR9V6PDQ9iy4EiSiprNC2klOpxPG0juA2YDOw1xpwIjAcKWj6k+8kvrSKmJreuodglLiyInOJKduWUaiBQSvU4nrYRVBhjKkQEEQk2xmwVkeFeLdlRZozBUVFAUGBlo0AQGx5EUUUNAIMTtX1AKdWzeBoIMpzjCN4CPhKRfGCv94p19JVV1RLrqD+GwCUu7PDaxFojUEr1NJ42Fp/rfLhARJYD0cAHXitVJygod59eonGNwEXHECilepo2zyBqjPnUGwXpbAVlVfSmmRqBMxAkRAQRE6bLUyqlepb2rlnc4xS6TzjXxDgC0NqAUqpn8mogEJHTRGSbiOwQkSYnrRORC0Vks4hsEpGXvVmelrgmnKsNjIDg+hd8V41A2weUUj2R1xaXERF/4HFgDpABrBGRpcaYzW77DAV+CRxrjMkXkU6bv6igrJpeko+J6NNoW0JEMEkxoUwfHN8JJVNKKe/y5ipjU4AdxphdACLyKnA2sNltn+uBx52T2GGMyfJieVpUUF7FUMlHovo22hYU4McX9/SosXNKKVXHm6mhJCDd7XmG8zV3w4BhIvKFiKwSkdOaOpGI3CAia0VkbXZ2tlcKW1hWTR8pwD+qcY1AKaV6ss5uLA4AhgKzgIuBp93XPXAxxiw0xkwyxkxKTEz0SkHySytJlIJGXUeVUqqn82Yg2A/0d3ue7HzNXQaw1BhTbYzZDfyADQxHXVVJPiFUNeo6qpRSPZ03A8EaYKiIDBKRIOAiYGmDfd7C1gYQkQRsqmiXF8vULFN8wD7QGoFSysd4LRAYY2qAW4APgS3A68aYTSLyoIjMde72IZArIpuB5cAvjDG53ipTcxwOQ1mus7LSRK8hpZTqybzZawhjzHvAew1eu9/tsQHudP50mvT8MqKqcyAIrREopXxOZzcWdwmbM4voJc5ZtTUQKKV8jAYCYPOBIvr45WOCIyFIp5lWSvkWDQTYGsExwcWI9hhSSvkgDQTYGkFyYFGjyeaUUsoX+HwgyCut4kBhBbFSDOEJnV0cpZQ66nw+EGw5UARAeE0hhOmkckop3+PzgWBzZhH+1BJQpYFAKeWbNBAcKGJYVA2CgTBNDSmlfI/PB4JNmYVMTHDYJ2FxnVsYpZTqBD4dCCqqa9mZXcro2Gr7gqaGlFI+yKcDwQ+Hiql1GIZFVtkXNBAopXyQTweCzZm2x9DA0Ar7gnYfVUr5IN8OBAeKiAgOIBYbEAjVNgKllO/x7UCQWcTIvpH4ledBUAQEhnR2kZRS6qjz2UDgcBi2HChiVN8oKMvVHkNKKZ/ls4FgX14ZpVW1pPaLdgYCbShWSvkmnw0Em51TS4zqFwWlOTqYTCnls3w3EGQWEeAnDOkVAWV5WiNQSvksnw0E+/LK6BcTSkigv6aGlFI+zWcDQV5pFfERQVBdDtWl2lislPJZPhsIckoqiQ8PtrUB0MFkSimf5bOBIK+0ioSIoMOBQFNDSikf5ZOBwBhDXmkVceEaCJRSyicDQVF5DTUOQ3xEsO0xBBoIlFI+yycDQU5pJQDx9WoE2kaglPJNPhkI8krttNPxEUF2MBkCoTGdWyillOokPhkIcktsjaCujSA0Fvz8O7lUSinVOXwzEDhrBAkRwTqYTCnl83wzEJTYQBAb5qwR6BgCpZQP88lAkFdaRVRIAEEBflojUEr5PK8GAhE5TUS2icgOEbmnie1XiUi2iHzr/LnOm+VxySmptF1HQdciUEr5vABvnVhE/IHHgTlABrBGRJYaYzY32PU1Y8wt3ipHU/JKq2zXUWO0RqCU8nnerBFMAXYYY3YZY6qAV4Gzvfh+HsstcY4qriwCR40GAqWUT/NmIEgC0t2eZzhfa+h8EflORJaISP+mTiQiN4jIWhFZm52dfcQFyy2tsqmh0hz7gg4mU0r5MK+lhjz0NvCKMaZSRH4MPA+c1HAnY8xCYCHApEmTzJG8ocNhyC9zpoZ0egmlWlRdXU1GRgYVFRWdXRTloZCQEJKTkwkMDPT4GG8Ggv2A+x1+svO1OsaYXLen/wL+6MXyAFBYXk2tw9hRxTrhnFItysjIIDIykpSUFESks4ujWmGMITc3l4yMDAYNGuTxcd5MDa0BhorIIBEJAi4ClrrvICJ93Z7OBbZ4sTwA5JY2GFUM2mtIqWZUVFQQHx+vQaCbEBHi4+PbXIPzWo3AGFMjIrcAHwL+wDPGmE0i8iCw1hizFPipiMwFaoA84CpvlcfFNZgsISIYDumiNEq1RoNA99Ke35dX2wiMMe8B7zV47X63x78EfunNMjTkml7C1ghywD8IgiKOZhGUUqpL8bmRxbnuM4+6xhDoHY9Syof5XiBwzjxq5xnK04Zipbq4goICnnjiiTYfd8YZZ1BQUOCFEvU8nd199KjLK60iJiyQQH+dZ0iptvjN25vYnFnUoecc1S+KB85KbXEfVyC46aab6r1eU1NDQEDzl7D33nuv2W1dQWvlP5p8sEbgHFUMdkCZBgKlurR77rmHnTt3Mm7cOCZPnsxxxx3H3LlzGTVqFADnnHMOEydOJDU1lYULF9Ydl5KSQk5ODnv27GHkyJFcf/31pKamcsopp1BeXt7s+z399NNMnjyZtLQ0zj//fMrKygA4dOgQ5557LmlpaaSlpfHll18CsGjRIsaOHUtaWhqXX345AFdddRVLliypO2dEhG2HXLFihcfl/+CDD5gwYQJpaWnMnj0bh8PB0KFDcQ2qdTgcDBkyhI4YZIsxplv9TJw40RyJ+U99aeY9+aV98ocBxrzzsyM6n1I92ebNmzu7CGb37t0mNTXVGGPM8uXLTVhYmNm1a1fd9tzcXGOMMWVlZSY1NdXk5OQYY4wZOHCgyc7ONrt37zb+/v7mm2++McYYM2/ePPPCCy80+36u440x5t577zWPPvqoMcaYCy+80Pztb38zxhhTU1NjCgoKzMaNG83QoUNNdnZ2vbJceeWVZvHixXXnCQ8Pb1P5s7KyTHJyct1+rn0WLFhQV4YPP/zQnHfeeU1+hqZ+b9jemk1eV323RlBbAxUFWiNQqpuZMmVKvcFSjz76KGlpaUybNo309HS2b9/e6JhBgwYxbtw4ACZOnMiePXuaPf/GjRs57rjjGDNmDC+99BKbNm0CYNmyZdx4440A+Pv7Ex0dzbJly5g3bx4JCbYLelxc62OSPCn/qlWrOP744+v2c533mmuuYdGiRQA888wzXH311a2+nye6RoLqKMorrWLKoCAoz7cv6BgCpbqV8PDwuscrVqzg448/5quvviIsLIxZs2Y1OZgqODi47rG/v3+LqaGrrrqKt956i7S0NJ577jlWrFjR5jIGBATgcDgAm8Kpqqo6ovK79O/fn969e7Ns2TK+/vprXnrppTaXrSk+VSOodRjy6uYZck04p6OKlerKIiMjKS4ubnJbYWEhsbGxhIWFsXXrVlatWnXE71dcXEzfvn2prq6ud6GdPXs2Tz75JAC1tbUUFhZy0kknsXjxYnJz7eDUvDw7f1lKSgrr1q0DYOnSpVRXV7ep/NOmTWPlypXs3r273nkBrrvuOi677DLmzZuHv3/HrLXuU4GgoKwKY7Azj+o8Q0p1C/Hx8Rx77LGMHj2aX/ziF/W2nXbaadTU1DBy5Ejuuecepk2bdsTv99vf/papU6dy7LHHMmLEiLrXH3nkEZYvX86YMWOYOHEimzdvJjU1lXvvvZcTTjiBtLQ07rzzTgCuv/56Pv30U9LS0vjqq6/q1QI8KX9iYiILFy7kvPPOIy0tjfnz59cdM3fuXEpKSjosLQQgtg2h+5g0aZJZu3Ztu4794VAxp/xtJf+4eDxnBa6B16+An3wOfcZ0cCmV6hm2bNnCyJEjO7sYys3atWu54447+Oyzz5rdp6nfm4isM8ZMamp/n2ojcM0zFB8RBPlaI1BKdS8PP/wwTz75ZIe1Dbj4VGrINfNofLimhpTydTfffDPjxo2r9/Pss892drFadM8997B3715mzpzZoef1qRpBXmkVMRTT59CnsHMFBEVCQHCrxymlep7HH3+8s4vQZfhOINjwKmeu/D1XhOyFNwG/ABgzr7NLpZRSnc53AkFgGIcCk3mxYiY/vfJS6DcegsI6u1RKKdXpfCcQjJrLo+uT2E4JP005trNLo5RSXYaPNRY7B5MppZSq41uBoKTSdh1VSvVYrpk+led8JzWE7TUUH669hJRql/fvgYPfd+w5+4yB0x/u2HN2EV1pvYHW+EyNoKbWQX5Z9eG1CJRS3cI999xTr6vnggULeOihh5g9ezYTJkxgzJgx/Pe///XoXCUlJc0e19S6Ak2tQbBnzx5Gjx5dd9yf//xnFixYAMCsWbO4/fbbmTRpEo888ghvv/02U6dOZfz48Zx88skcOnSorhxXX301Y8aMYezYsbzxxhs888wz3H777XXnffrpp7njjjva/b21SXPzU3fVn/auR5BVVGEG3v2OWfTl7nYdr5Qv6grrEaxfv94cf/zxdc9Hjhxp9u3bZwoLC40xxmRnZ5vBgwcbh8NhjDk8939TqqurmzyuuXUFmlqDwH19BGOM+dOf/mQeeOABY4wxJ5xwgrnxxhvrtuXl5dWV6+mnnzZ33nmnMcaYu+66y9x222319isuLjbHHHOMqaqqMsYYM336dPPdd9+19esyxrR9PYLuUW/pAK5RxXGaGlKqWxk/fjxZWVlkZmaSnZ1NbGws8WLK4wAAChxJREFUffr04Y477mDlypX4+fmxf/9+Dh06RJ8+fVo8lzGGX/3qV42Oa25dgWXLltXN/+9agyA/P7/F93CfIC4jI4P58+dz4MABqqqq6tYX+Pjjj3n11Vfr9ouNjQXgpJNO4p133mHkyJFUV1czZszRmQfNZwJBnvs8Q0qpbmXevHksWbKEgwcPMn/+fF566SWys7NZt24dgYGBpKSktDiPv0t7j3PnvtYA0Oh495lGb731Vu68807mzp3LihUr6lJIzbnuuuv4/e9/z4gRIzp0dtHW+EwbQU6pMxBoG4FS3c78+fN59dVXWbJkCfPmzaOwsJBevXoRGBjI8uXL2bt3r0fnae645tYVaGoNgt69e5OVlUVubi6VlZW88847Lb5fUlISAM8//3zd63PmzKnX7uGqZUydOpX09HRefvllLr74Yk+/niPmM4Egr8Q54VyEpoaU6m5SU1MpLi4mKSmJvn37cumll7J27VrGjBnDokWL6q0b0JLmjmtuXYGm1iAIDAzk/vvvZ8qUKcyZM6fF916wYAHz5s1j4sSJdWkngPvuu4/8/HxGjx5NWloay5cvr9t24YUXcuyxx9ali44Gn1mP4H+bDrJkXQb/vGwifn7ihZIp1fPoegRH35lnnskdd9zB7Nmz232Otq5H4DM1glNS+7DwikkaBJRSXVJBQQHDhg0jNDT0iIJAe/hMY7FSynd8//33dWMBXIKDg1m9enUnlah1MTEx/PDDD53y3hoIlFItMsYg0r1q0mPGjOHbb7/t7GJ0ivak+30mNaSUaruQkBByc3PbdXFRR58xhtzcXEJCQtp0nFdrBCJyGvAI4A/8yxjT5KQiInI+sASYbIxp38r0SqkOl5ycTEZGBtnZ2Z1dFOWhkJAQkpOT23SM1wKBiPgDjwNzgAxgjYgsNcZsbrBfJHAb0HWTd0r5qMDAwLrRsKrn8mZqaAqwwxizyxhTBbwKnN3Efr8F/g9o2/A+pZRSHcKbgSAJSHd7nuF8rY6ITAD6G2PebelEInKDiKwVkbVaRVVKqY7VaY3FIuIH/BX4WWv7GmMWGmMmGWMmJSYmer9wSinlQ7zZWLwf6O/2PNn5mkskMBpY4eya1gdYKiJzW2owXrduXY6IeDaxCCQAOW0q9dHTVcvWVcsFWrb26Krlgq5btq5aLjiysg1sboPXppgQkQDgB2A2NgCsAS4xxmxqZv8VwM87steQiKxtbkh1Z+uqZeuq5QItW3t01XLB/7d3tyFyVXccx78/40NjhMRoCdFYVjEY0laTKBpbERuLRi3piwoafCElUCo+ltKaIAiWvipF27RSsE+Kldj6ECtBYuIaRNrSaDRJN65BrcEHEjeKUaISYvrri3PWvY67TSy5e05m/h8Y9s6ZMPvbOXdy5p4793/qzVZrLmgvW2tTQ7Y/Bq4DHgcGgb/Y3iLpJ5IWtfV7QwghfD6tXkdg+zHgsY62W8f4txe0mSWEEMLouv3K4rtKB/gfas1Way6IbP+PWnNBvdlqzQUtZTvkylCHEEI4uLr9iCCEEMJ+xEAQQgg9rmsHAkkLJW2V9LKkpYWz/EHSkKSBRttUSWslvZR/jt+6dCMZTpK0TtILkrZIurGibF+QtF7Sppztttx+sqR/5n79s6Qii1BLmiDpeUmrKsu1TdK/JG2U9Gxuq6E/p0h6UNKLkgYlnVtJrtPyazV8e1/STZVk+0He9wckrcjviVb2s64cCBoF7y4BZgOLJc0uGOluYGFH21Kg3/ZMoD/fH28fAz+0PRuYD1ybX6casu0BFtg+A5gDLJQ0n1SX6g7bpwLvAksKZINUKHGwcb+WXADfsD2n8X3zGvrzl8Bq27OAM0ivXfFctrfm12oOcCbwIbCydDZJJwI3AGfZ/gqpgvOVtLWf2e66G3Au8Hjj/jJgWeFMfcBA4/5WYHreng5sreB1+yupWmxV2YCjgeeAc0hXVR4+Wj+PY54ZpP8cFgCrANWQK//ubcDxHW1F+xOYDLxK/nJKLblGyXkR8LcasjFSq20q6Wv+q4CL29rPuvKIgAMoeFeBaba35+0dwLSSYST1AXNJ5cCryJanXzYCQ8Ba4BVgl9PFilCuX38B/Bj4T75/XCW5AAyskbRB0vdyW+n+PBnYCfwxT6f9TtKkCnJ1uhJYkbeLZrP9JvBz4DVgO/AesIGW9rNuHQgOKU7De7Hv8Uo6BngIuMn2+83HSmazvc/pkH0Gqaz5rBI5miR9CxiyvaF0ljGcZ3seaVr0WknnNx8s1J+HA/OA39ieC3xAx1RLBe+BI4FFwAOdj5XIls9JfJs0iJ4ATOKz08sHTbcOBPsreFeDtyRNB8g/h0qEkHQEaRC4z/bDNWUbZnsXsI50KDwl17GCMv36dWCRpG2kNTYWkOa/S+cCPvkkie0h0lz32ZTvzzeAN2wPLz71IGlgKJ2r6RLgOdtv5fuls30TeNX2Ttt7gYdJ+14r+1m3DgTPADPzGfYjSYd8jxbO1OlR4Oq8fTVpfn5cSRLwe2DQ9u2VZfuipCl5eyLp3MUgaUC4vFQ228tsz7DdR9qvnrR9VelcAJImKa34R556uQgYoHB/2t4BvC7ptNx0IfBC6VwdFjMyLQTls70GzJd0dH6fDr9m7exnJU/OtHyy5VJS9dNXgFsKZ1lBmufbS/p0tIQ0r9wPvAQ8AUwtkOs80iHvZmBjvl1aSbbTgedztgHg1tx+CrAeeJl0GH9UwX69AFhVS66cYVO+bRne7yvpzznAs7k/HwGOrSFXzjYJeAeY3Ggrng24DXgx7//3Ake1tZ9FiYkQQuhx3To1FEII4QDFQBBCCD0uBoIQQuhxMRCEEEKPi4EghBB6XAwEIWSS9nVUojxohcYk9alRfTaEmrS6ZnEIh5iPnEpahNBT4ogghP3INf5/luv8r5d0am7vk/SkpM2S+iV9KbdPk7Qyr6WwSdLX8lNNkPTbXGN+Tb5iGkk3KK0JsVnS/YX+zNDDYiAIYcTEjqmhKxqPvWf7q8CvSdVHAX4F3GP7dOA+YHluXw485bSWwjzSVb4AM4E7bX8Z2AV8J7cvBebm5/l+W39cCGOJK4tDyCTttn3MKO3bSIvk/DsX6dth+zhJb5Nq1u/N7dttHy9pJzDD9p7Gc/QBa50WOkHSzcARtn8qaTWwm1R64RHbu1v+U0P4lDgiCOHAeIztz2NPY3sfI+foLiOtqDcPeKZRXTKEcREDQQgH5orGz3/k7b+TKpACXAU8nbf7gWvgk8V1Jo/1pJIOA06yvQ64mbSa12eOSkJoU3zyCGHExLwi2rDVtoe/QnqspM2kT/WLc9v1pFW3fkRageu7uf1G4C5JS0if/K8hVZ8dzQTgT3mwELDcaf2FEMZNnCMIYT/yOYKzbL9dOksIbYipoRBC6HFxRBBCCD0ujghCCKHHxUAQQgg9LgaCEELocTEQhBBCj4uBIIQQetx/AZ8zzghkl88oAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2.17246544e-02 7.77595192e-02 5.15827909e-04]\n",
            " [1.63315111e-04 9.97924060e-02 4.42814053e-05]\n",
            " [9.01643783e-02 4.06660698e-03 5.76901250e-03]\n",
            " ...\n",
            " [9.91544779e-03 5.60324313e-03 8.44813138e-02]\n",
            " [1.18321215e-04 1.14623189e-03 9.87354442e-02]\n",
            " [3.47294398e-02 3.18925572e-03 6.20813146e-02]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAFCCAYAAAC3ugnQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3gUVdvA4d9JQif0Ir1JJwUIhCpVOiIfAtKkCkiVFymCIiAiinTQFwugKKgg7UVUVBAQMBAggvQWSkIvoaee74/ZxE1I2ZTN7CbPfV17ZXfqs5PdfeaUOaO01gghhBDpzcXsAIQQQmROkoCEEEKYQhKQEEIIU0gCEkIIYQpJQEIIIUwhCUgIIYQpJAFlQkqpo0qppmbHYTal1H+VUm+n8z5XKKVmpOc+7UUp1UsptTWF62bYz6BSSiulnjU7Dmeg5DogcymlAoGiQCTwAPgZGKG1fmBmXBmNUqofMEhr3cjkOFYAl7XWb5kcx1TgWa1173TY1woc4D2nF6WUBipqrc+YHYujkxKQY+iotc4NeAM1gTdNjifZlFJumXHfZpJjLpye1loeJj6AQKCl1esPgR+tXtcD9gB3gb+BplbzCgDLgWDgDrDBal4HIMCy3h7AM+4+geLAY6CA1byawE0gi+X1AOC4Zfu/AGWsltXAcOA0cD6B9/cCcNQSxx9A1ThxvAkcs2x/OZA9Ge9hAnAYCAXcgInAWeC+ZZudLctWBZ7wbynzrmX6CmCG5XlT4DIwFrgOXAH6W+2vIPA/4B6wH5gB/JnI/7WR1f/tEtDPap9LgB8tcfoBFazWW2BZ/h5wAGhsNW8qsBb42jJ/EFAX2GvZzxVgMZDVap3qwK/AbeAaMAloA4QB4Zbj8bdl2bzAF5btBFneo6tlXj9gNzAPuGWZ1y/6GADKMu+6JbYjQA1gsGU/YZZ9/S/u5x5wtcQV/b87AJRK4LjG+30AGmB8bktZXnthfKaqWF7H+9mI573dBc5ZttfP8r+4DvS1Wn4F8F/Lcb0P7ODp78WzlufZgI+Ai5bj/18gh9m/O47yMD2AzP6I80UsafniLrC8LmH5srfDKK0+b3ld2DL/R+A7ID+QBWhimV7T8qXxtXy5+1r2ky2efW4DXrWKZzbwX8vzTsAZjB9wN+AtYI/VstryJSwQ35cKqAQ8tMSdBRhv2V5Wqzj+AUpZtrGbfxOCLe8hwLJuDsu0rhhJ1QXobtl3Mcu8fsRJGDydgCKA6ZZY2wGPgPyW+d9aHjmBahg/TPEmIKAMxg9TD8u2CgLeVvu8hZE43IBvgG+t1u1tWd4NIxlexZKUMRJQOPCi5T3mAGpj/Ci7AWUxThZetyzvjpFMxgLZLa99rbb1dZy41wNLgVxAEWAfMMTq+EUAIy37ykHsBNQaI3Hkw0hGVa2OfcxxTuBzPw7jc1/Zsq4XUDCe45rU9+E9jM9zDsv2Rlitm9RnIwLoj/FZm4GRMJZgJJBWlv9nbqv3cx94zjJ/gfVngdgJaB6wCePz7Y5xEvO+2b87jvIwPYDM/rB8ER9YPtAa+B3IZ5k3AVgZZ/lfMH6MiwFRWH4g4yzzCfBunGkn+TdBWX/5BwHbLM8Vxg/rc5bXPwEDrbbhgvGjXMbyWgPNE3lvbwPfx1k/iH/PWgOBoVbz2wFnk/EeBiRxbAOATpbn/Ug6AT0G3KzmX8f4cXfF+OGvbDUvwRIQRqlufQLzVgCfx3nPJxJ5D3cAL8vzqcDOJN7z69H7xkiAhxJYbipWCQijHTIUqxMJy/rbrY7fxTjbiDmmQHPglOV4uSR0nON87qM/gyej/09JvLcEvw+W51kwkuARjLZUlYzPxmmreR4Yn+2iVtNuEfskwvqkITdG6Tq69KWBZzG+Tw+JXcKtTwK1BZnxIW1AjuFFrbU7xo9gFaCQZXoZoKtS6m70A6NqpxjGmf9trfWdeLZXBhgbZ71SGGeAcf0A1FdKFcM4o4sCdlltZ4HVNm5jfKlKWK1/KZH3VRy4EP1Cax1lWT6h9S9YxWjLe4i1b6XUK0qpAKvla/DvsbTFLa11hNXrRxg/LoUxzvqt95fY+y6FUd2TkKvx7AMApdQbSqnjSqkQy3vIS+z3EPc9V1JKbVZKXVVK3QNmWi2fVBzWymD8gF+xOn5LMUpC8e7bmtZ6G0b13xLgulLqU6VUHhv3bWuciX0f0FqHYySHGsAcbfnFB5s+G9esnj+2bC/utNxWr2OOhTY6DN3m6e9XYYwS8wGr/f5smS6QTggORWu9A+ML9JFl0iWMM758Vo9cWutZlnkFlFL54tnUJeC9OOvl1Fqvjmefd4CtGNUSPTHO7LTVdobE2U4OrfUe600k8paCMX40AFBKKYwfmyCrZUpZPS9tWcfW92D9A1MG+AwYgVF9kw+jek/ZEGdSbmBU0ZRMIO64LgEVkrsTpVRjjGrKbhgl23xACP++B3j6fXwCnMDodZUHoy0levlLQPkEdhd3O5cwSkCFrI53Hq119UTWib1BrRdqrWtjVFFWwqhaS3I9bD9eiX0fUEqVAN7BaEuco5TKZpme1GcjJWL+/0qp3BhVbMFxlrmJkbiqW8WbVxsdjgSSgBzRfOB5pZQXRmNzR6VUa6WUq1Iqu1KqqVKqpNb6CkYV2cdKqfxKqSxKqecs2/gMGKqU8lWGXEqp9kop9wT2uQp4BXjJ8jzaf4E3lVLVAZRSeZVSXZPxXr4H2iulWiilsmC0RYRiNCJHG66UKqmUKgBMxmjTSsl7yIXxQ3fDEmt/jLPcaNeAkkqprMmIHwCtdSSwDpiqlMqplKqCcbwS8g3QUinVTSnlppQqqJTytmFX7hiJ7gbgppSaAiRVinDHaPR/YInrNat5m4FiSqnXlVLZlFLuSilfy7xrQFmllIvlPV7BOBGZo5TKo5RyUUpVUEo1sSFulFJ1LP+rLBjVTk8wStPR+0ooEQJ8DryrlKpo+V97KqUKxrNcgt8Hy8nNCoxOFAMx2r7etayX1GcjJdoppRpZPk/vAn9prWOVEC0l/s+AeUqpIpZ9l1BKtU7lvjMMSUAORmt9A/gKmGL5QHfCOKu9gXEGOI5//299MNomTmC0V7xu2YY/8CpGlcgdjIb/fonsdhNQEbiqtf7bKpb1wAfAt5bqnX+Atsl4LycxGtUXYZwNdsToch5mtdgqjB++cxjVMDNS8h601seAORg9wq5h1OPvtlpkG0ZvvKtKqZu2vgcrIzCqw64CK4HVGMk0vlguYrTtjMWomgnAaFhPyi8YVTSnMKojn5B4VR/AGxgl1/sYP3bRCRyt9X2MhvqOlrhPA80ss9dY/t5SSh20PH8FyMq/vRLXYqneskEey/7vWGK/hdGhBYykUM1SDbUhnnXnYpysbMVIpl9gdCSIJYnvwyiM6sK3LSX4/kB/pVRjGz4bKbEKo7R1G6MjSELXU03A+Oz+ZfkO/YbR2UIgF6IKEynjItxBWuvfzI4luZRSHwDPaK37mh2LSF8qk11Ya09SAhLCBkqpKpaqIaWUqotRzbPe7LiEcGZyNbMQtnHHqHYrjlGNMwfYaGpEQjg5qYITQghhCqmCE0IIYQpJQEIIIUzhdAmoefPmGqNPvzziPK5du2Z6DI78kOMjx0aOj10eKeZ0CejWrVtmh+CwIiMjzQ7BocnxSZgcm8TJ8bEPp0tAQgghMgZJQEIIIUwhCUgIIYQpJAEJIYQwhSQgIYQQppAEJIQQwhSSgIQQQpjCbglIKbVMKXVdKfVPAvOVUmqhUuqMUuqwUqqWvWIRQgjheOxZAloBtElkfluMm6BVBAZj3FpYCCFEJmG32zForXcqpcomskgn4CvL3Qv/UkrlU0oVs9waWNjBmlNr2HJuS/JXvH8VHt5I+4DSWZSOwkVJrXN85NgkzhmOT1hkFOGRUUkvmMa+HxyQ4nXNvB9QCWLfbviyZdpTCUgpNRijlESxYsUIDg5OlwCdze3btxOdv+HEBs7eP0sF9wrJ2q7bg2u4hD8iKkvO1IRnOh2liXJJ/y+oM5BjkzhnOD7hEVFEaY2LUumyvygdhY5K1VBwznFDOq31p8CnAF5eXrp48eL23aH/cjiyNs03u4YHbFEP03y70ZI6SztPGFXJyvJbd5O34as34RkP6P9jKiM0V3BwMHb/7KTSKr+LbAwISvf9hoWFkTVr1nTfr7NwhuNz/Mo9qhXLw3dD6tt1P5cuXaJfv35s27aNjh07wrCUb8vMMmUQUMrqdUnLNPMdWQtXj6T5Zreoh5wkLM23a6vKZKWdzpX8FZ/xAI+X0j4g8ZSNAUEcu3LP7DCEE6pWLA+dvEvYdR+rVq3Cw8MDPz8/PvvsMzZuTN1Ngc0sAW0CRiilvgV8gRCHav+xxxn/z/2pDCxvszxtt2vhDGf49mBrqcE4i72QDhGl3LF0OouNK7N+dmwlx8fw+++/U61aNVauXEmFCsmryo+P3RKQUmo10BQopJS6DLwDZAHQWv8X2AK0A84Aj4D+9oolvSXU2H/y9kkqF6hsQkSOKa2qm/zOG21fvuUKpHpbZkuPs1ghkuPXX3+lSJEieHl5sXjxYrJkyYKbW9qkDnv2guuRxHwNDLfX/s205dyWeJNN5QKVaVe+nUlROZ7o6qZqxfKkaju+5QrQybsEPX1LJ7qcnMUKYbvHjx8zceJEFi5cSJcuXVi7di05cuRI0304RScEu4vb6eDqEaMKzgbxlXaik4+9qtpsZVaDtq3Mqm4SQiTuwIED9O7dmxMnTjB69Gjef/99u+xHEhD82+nAknTWPFOOLbmj4OekawX9r/kD4FPUJ2aao5R00qqEYS9S3SSE49mxYwctW7akaNGi/Prrr7Rs2dJu+8o8CSixrtXRycfS6WDLz/2NUgzPJLlZn6I+tCvfjq6VuqZltDazLuXEbWSXEoYQwlYRERG4ubnRoEEDJkyYwNixY8mfP79d95l5ElCcUk4sz3iwpkQltlhKPI5ShWYtoeq0xBrgpYQhhEiK1prPP/+cOXPmsGfPHgoUKMCMGTPSZd+ZIwH5L4cLf0KZRgl2rY4p9RSo7DBVaNYSqk6zboCXRnYhRHJcu3aNQYMGsXnzZlq0aEFoaGi67j/jJiDrKrcLfxp/k7iY0tFKPdFW+V3E7/xtfMsVkOo0IUSa2LBhA6+++ir3799n/vz5jBw5EheX9B2bwLFH10sN69EMyjSCDvPBJ/5OBWtOrYnpTOCIoqvepDpNCJEWtNYsXbqUUqVKcfDgQUaPHp3uyQcycgkIkhzNILoLdXTycbRqt+h2n2NX7uFbrkCS17kIIURidu/eTalSpShdujTffPMNuXPnNnWMu4ydgJIQfcGovXuypfR6HOsOBlL6EUKkVFhYGFOnTuWDDz6gd+/efPnllxQoYP7IIRkvAUW3/dh4MWl6tPuk9HocW6/wF0KIhBw9epTevXsTEBDAwIEDmTdvntkhxch4Ccg6+STQ6SC66i09x2aT63GEEOnt119/pWPHjuTJk4cNGzbQqVMns0OKJeMkoLgln0TafqyTj6O1+wghRGpprVFK4evrS9++fZk+fTpFixY1O6ynZIwE5L8cNr9uPC/TyKZ71zhql2shhEiNVatWsXTpUn755Rfy5MnD0qVLzQ4pQRmjG3b09T4d5hslnwS6W5sh+hoeIYSwp9u3b9OjRw969epFeHg4d+7cMTukJGWMBARGyceBEk80uYZHCGFvv/76K56enqxdu5YZM2awc+dOihUrZnZYScoYVXAOTq7hEULYS1RUFBMnTsTd3Z2NGzdSu3Zts0OymSQgIYRwQocOHaJs2bLkz5+f9evXU7hw4TS/YZy9ZZwqOBs5+rA7QgiRmIiICGbOnEndunWZMmUKAKVLl3a65AOZpARkfdfS9Bx2x3oQUSGESK2zZ8/yyiuvsGfPHrp168a0adPMDilVnL8EFH2rhUREX/cDxg3kptSfki43kJMOCEKItPLTTz/h5eXF0aNH+eabb/j2228dYjid1HD+ElB0F+x4rv2JO+JBelz3Yz3umwwiKoRIK56enrRu3Zr58+dTqlQps8NJE85fAoIEu2CbMeJB9LhvIHckFUKkzqZNm+jZsydRUVGUKFGCH374IcMkH8gIJaAkpOeIB3LjOCFEWrh//z7/+c9/+Pzzz/H29ubWrVsULlzY7LDSnHOXgGxo/0lP0uYjhEit3bt34+3tzRdffMHEiRPx8/PLkMkHnL0ElEj7T3qIe58fafMRQqRGeHg4ffr0QWvNzp07adSokdkh2ZVzJyAwZQie6MRjfcM4kDYfIUTKnDx5krJly5ItWzY2bdpE6dKlyZMnefcPc0bOn4ASEH3BqU9RnzTftvVtsuWGcUKIlIqKimLx4sVMmDCB8ePHM23aNGrUqGF2WOkmwyag6AtP07r3m3Q0EEKkhcuXL9O/f39+++03OnTowLBhw8wOKd1lyARkXfpJ6wtOpaOBECK1fvrpJ3r27ElYWBhLly7l1VdfRSlldljpLsMloDWn1jB973QgbUs/0e0+0tFACJFaJUuWxNvbm88++4xnn33W7HBM45zdsP2Xw/L2xu2344iuekvL4XZW+V1k0voj+J2/LR0NhBAp8vvvvzN+/HgAPDw82L59e6ZOPuCsCejIWiP5POMRbxfstK56i652m9nZg++G1JfSjxDCZo8fP2bMmDG0bNmSTZs2ERISYnZIDsN5q+Ce8TBuv51OpNpNCJFchw4donfv3hw7doyRI0cya9YscubMaXZYDsN5E5AQQjiwx48f06ZNG9zc3Pjll19o1aqV2SE5HElAibDueFCtWMa/KEwIkXqXL1+mePHi5MiRg7Vr11K9enWnv22CvThdG5DLk9t2Hf9tld9Fui/dS/ele6XjgRDCZlprvvjiC6pWrconn3wCQOPGjSX5JMLpSkAuT0IAZbfx36xLPDLSgRDCFtevX2fw4MFs3LiRZs2a0bFjR7NDcgpOl4AAu43/JqMcCCGSa+vWrfTp04eQkBDmzp3L6NGjcXFxusolUzhnArITGeVACJFcbm5ulChRgt9//z1TjeOWFiRNW1iXfqTKTQiRmL1797JgwQIAmjdvjr+/vySfFLBrCUgp1QZYALgCn2utZ8WZXxr4EshnWWai1npLSva15tSaWLfgTkzc+/gAMbdWkNKPECIh4eHhTJ8+nZkzZ1KuXDleffVVcubMKVVuKWS3o6aUcgWWAG2BakAPpVS1OIu9BXyvta4JvAx8nNL9WSefpMaAi+5oYM23XAFmdvaQ0o8QIl7Hjx+nfv36zJgxg759+3Lw4EG5qDSV7FkCqguc0VqfA1BKfQt0Ao5ZLaOB6Ats8gLBqdlh5QKVWd5mebzzrEs90b3cpKOBEMIW9+7do379+mTJkoV169bRuXNns0PKEOyZgEoAl6xeXwZ84ywzFdiqlBoJ5AJa2isY6+7Vcl2PEMIWd+7cIX/+/OTJk4fly5dTv359nnnmGbPDyjDM7gXXA1ihtZ6jlKoPrFRK1dBaR1kvpJQaDAwG8CiWndCwUG4Fxy4shYWFARAc/HQhasM/N/E7f5uaJXIzr2OZmOnxLevMbt++bXYIDk2OT8Lk2Dxt48aNTJo0idmzZ1OvXj18fX2JiorKcL8bqVW8ePEUr2vPBBQElLJ6XdIyzdpAoA2A1nqvUio7UAi4br2Q1vpT4FOA2mXy6GxZsz31prNmzQo8fTBW+V3kw21GQaxr3XKpOljOIKO/v9SS45MwOTaGO3fuMGLECFatWoWvry9NmjQhV65ccnzswJ5dN/YDFZVS5ZRSWTE6GWyKs8xFoAWAUqoqkB24kZZBWN9KQToYCCESs337djw9Pfnuu++YPn06f/75JxUrVjQ7rAzLbiUgrXWEUmoE8AtGF+tlWuujSqnpgL/WehMwFvhMKTUGo0NCP621TqsY5NoeIURyBAUFkStXLvbu3UudOnXMDifDs2sbkOWani1xpk2xen4MaJja/aw5tQb/a/74FPWJNV1GNhBCJCUgIICTJ0/SvXt3evXqRdeuXcmWLZvZYWUKGeLqqejbcMd3/Y+UfoQQ8YmMjOSDDz6gbt26TJ48mfDwcJRSknzSUYZIQJD2t+EWQmRc58+fp2nTpkycOJFOnTrh5+dHlixZzA4r0zG7G7YQQqSr69ev4+3tDcDKlSvp1asXSimTo8qcJAEJITKF0NBQsmXLRpEiRfjggw9o164dpUtL9byZnL4KLroDghBCJGTz5s2UL1+ePXv2ADB06FBJPg7AqRPQmlNrmL53OhC7A0L0bbXjDjgqhMhcHjx4wJAhQ+jYsSOFChUiT548Sa8k0o1TV8FF936bUn8KXSt1jRlwNPrWCtG31BZCZD5//fUXffr04ezZs4wfP57p06dLDzcH49QJCGL3fosecDQ68Uj3ayEyrz/++IPw8HD++OMPnnvuObPDEfFw+gQUl9xmQYjM68SJEwQHB9O8eXPGjRvHsGHDpNrNgTl1G5AQQgBorVm8eDE1a9Zk+PDhREVF4erqKsnHwWWIBCSdDoTIvIKDg2nTpg0jR46kWbNmbNu2TW6R7SScvgru+r1QJv1xBJBOB0JkNhcvXsTb25vQ0FA++eQThgwZIheVOhGnT0A3H4YCcrsFITKTqKgoXFxcKFWqFCNGjKB3795UqlTJ7LBEMmWIcqoMOCpE5rF9+3aqV6/OqVOnUEoxffp0ST5OKkMkICFExvfkyRPGjh1L8+bNiYyM5NGjR2aHJFJJEpAQwuEFBATg4+PD3LlzGTZsGIcOHYoZUFQ4L6dvAxJCZHzLly/n1q1bbNmyhbZt25odjkgjUgISQjik8+fPExAQAMD777/PkSNHJPlkMJKAhBAORWvN8uXL8fT0ZNCgQWityZkzJ4UKFTI7NJHGJAEJIRzGjRs36NKlCwMGDKBWrVr88MMPcl1PBmZzG5BSKqfWWrqdCCHs4tSpUzz33HPcuXOH2bNnM2bMGFxdXc0OS9hRkiUgpVQDpdQx4ITltZdS6mO7RyaEyFTKly9Px44d2b9/P2+88YYkn0zAliq4eUBr4BaA1vpvQMY2F0Kkmp+fH40aNeL69eu4ubnx2Wef4enpaXZYIp3Y1Aaktb4UZ1KkHWIRQmQS4eHhvPPOOzRs2JBLly4RHBxsdkjCBLa0AV1SSjUAtFIqCzAaOG7fsIQQGdXJkyfp3bs3/v7+9O3blwULFpA3b16zwxImsCUBDQUWACWAIGArMMyeQSXl2v0njFq6l8Cs93gUGgHSSUYIpzF16lTOnTvH2rVr6dKli9nhCBPZkoAqa617WU9QSjUEdtsnpKTdfBDKsfCtUOgUObNVolM1uQWDEI4sODiYsLAwypYty6JFiwgPD6dYsWJmhyVMZksb0CIbp6WrnAUOA/BGw5dlJGwhHNiaNWvw8PBg4MCBABQqVEiSjwASKQEppeoDDYDCSqn/WM3KAzhE/0ifoj50rdTV7DCEEPEICQlhxIgRfP3119SpU4dPPvnE7JCEg0msCi4rkNuyjLvV9HvAS/YMKjF3VBTTCj3giQoDqpsVhhAiEceOHaNt27YEBQXxzjvvMHnyZLJkyWJ2WMLBJJiAtNY7gB1KqRVa6wvpGFOiQogi0C2S7LoU7cq3MzscIUQ8ypQpg4eHB99//z2+vr5mhyMclC2dEB4ppWZjFDeyR0/UWje3W1SJ0BpKhbnQpeY8ulaSth8hHMXhw4eZNm0aK1euJFeuXGzevNnskISDs6UTwjcYw/CUA6YBgcB+O8aUqMcuGlcXJR0PhHAQkZGRzJ49mzp16rBnzx7OnDljdkjCSdiSgApqrb8AwrXWO7TWAwBTSj/RGj7KaubuhRAWgYGBNG/enPHjx9OhQweOHDkiQ+kIm9lSBRdu+XtFKdUeCAYK2C+kxOWIUrSUBCSEQxg6dCiHDh3iyy+/pE+fPnLrBJEstiSgGUqpvMBYjOt/8gCv2zUqIYTDunnzJkopChYsyCeffIJSirJly5odlnBCSVbBaa03a61DtNb/aK2baa1rA7fTITYhhIPZsmULNWrUYNgwYzSucuXKSfIRKZZgAlJKuSqleiil3lBK1bBM66CU2gMsTrcIhRCme/jwIa+99hrt27encOHCTJ482eyQRAaQWBXcF0ApYB+wUCkVDPgAE7XWG9IjOCGE+Y4ePUrnzp05c+YMb7zxBu+++y7Zs2dPekUhkpBYAvIBPLXWUUqp7MBVoILW+lb6hCaEcASFCxcmX758bNu2jaZNm5odjshAEmsDCtNaRwForZ8A5yT5CJE5nDp1iuHDhxMZGUmRIkXw8/OT5CPSXGIJqIpS6rDlccTq9RGl1GFbNq6UaqOUOqmUOqOUmpjAMt2UUseUUkeVUqtS8iaEEGlDa83HH3+Mt7c33377LSdPngSQ7tXCLhKrgquamg0rpVyBJcDzwGVgv1Jqk9b6mNUyFYE3gYZa6ztKqSKp2acQIuWuXLnCgAED+Pnnn2ndujXLli2jePHiZoclMrDEBiNN7QCkdYEzWutzAEqpb4FOwDGrZV4Flmit71j2eT2V+xRCpIDWmi5duvD333+zZMkSXnvtNSn1CLuz5ULUlCoBXLJ6fRmIOyxuJQCl1G6MewxN1Vr/bMeYhBBWQkJCyJIlC0opPv74Y3LmzEnlypXNDktkEvZMQLbuvyLQFCgJ7FRKeWit71ovpJQaDAwGyFc6BzpKExwcnN6xOrzbt+X64MTI8Ylt7969jB49mtatWzNmzBiKFi0KIN+teMhnJ2Gpqaa1KQEppXIApbXWJ5Ox7SCM64iilbRMs3YZ8NNahwPnlVKnMBJSrNG2tdafAp8CFCiTUysXJXXTCZDjkjg5PhAaGspbb73FnDlzqFChAq+++ioFChSQY5MEOT5pL8mheJRSHYEA4GfLa2+l1CYbtr0fqKiUKqeUygq8DMRdbwNG6QelVCGMKrlzNkcvhEiWY8eOUadOHT766COGDBlCQEAA9erVMzsskUnZUgKaitGh4A8ArXWAUqpcUitprSOUUiOAXzDad5ZprY8qpaYD/lrrTZZ5rZRSx4BIYJxcaySE/bi5ufHw4UM2b95M+/btzQ5HZHI23Y5Bax0Sp0eMtmXjWustwJY406ZYPUeXEtgAACAASURBVNfAfywPIYQdXLhwgZUrVzJ58mQqVarEyZMncXMzu/lXCNtuSHdUKdUTcFVKVVRKLQL22DkuIUQqaa356quv8PT05MMPP+T8+fMAknyEw7AlAY0EqgOhwCogBLkfkBAO7ebNm3Tt2pW+ffvi5eXF33//Tfny5c0OS4hYbDkVqqK1ngzI+OtCOAGtNS1atOD48eN88MEHjB07FldXV7PDEuIptiSgOUqpZ4C1wHda63/sHJMQIgUePXpEtmzZcHV1Zc6cORQuXBgvLy+zwxIiQbbcEbUZ0Ay4ASy1DEb6lt0jE0LYbN++fdSsWZOPPvoIgJYtW0ryEQ7PljYgtNZXtdYLgaEY1wRNSWIVIUQ6iIiIYNq0aTRo0IDHjx9Tt25ds0MSwmZJVsEppaoC3YEuwC3gO2CsneMSQiTh9OnT9O7dm3379tG7d28WLVpEvnz5zA5LCJvZ0ga0DCPptNZayyBRQjiI69evc+7cOb777ju6detmdjhCJFuSCUhrXT89AhFCJO3KlSts2bKFgQMH0rBhQwIDA8mVK5fZYQmRIgkmIKXU91rrbpa7oVqPfKAwBjHwtHt0QogYP/zwA0OGDOHx48e0a9eOYsWKSfIRTi2xEtBoy98O6RGIECJ+ISEhjBo1iq+++gofHx9WrlxJsWLFzA5LiFRLsBec1vqK5ekwrfUF6wcwLH3CEyJzi4iIoH79+nz99de8/fbb7NmzhypVqpgdlhBpwpZOCM8DE+JMaxvPNCFEGgkPD8fNzQ03NzfeeustypcvL7dNEBlOgiUgpdRrlvafykqpw1aP88Dh9AtRiMzlyJEj+Pj4sHr1agB69uwpyUdkSIldiLoK6IhxE7mOVo/aWuve6RCbEJlKVFQUc+bMwcfHh2vXrpE/f36zQxLCrhKrgtNa60Cl1PC4M5RSBbTWptwk3aYbEQnhZC5cuEC/fv34448/ePHFF/n0008pXLiw2WEJYVeJJaBVGD3gDmD87lvfkU4Dpo3tXih3NrN2LYRdHDx4EH9/f5YtW0a/fv2IcwNIITKkBBOQ1rqD5W+St99OTwoo6p7d7DCESLVbt26xZ88eOnbsSOfOnTl37pyUekSmkuRgpEqphkqpXJbnvZVSc5VSpe0fmhAZ188//4yHhwc9e/bkzp07AJJ8RKZjy2jYnwCPlFJeGIOQngVW2jUqITKoR48eMWLECNq2bUv+/PnZuXOndDYQmZYt1wFFaK21UqoTsFhr/YVSaqC9AxMio3ny5Ak+Pj4cP36cMWPGMHPmTLJnl+pkkXnZkoDuK6XeBPoAjZVSLkAW+4YlRMahtUYpRfbs2Rk4cCDe3t60aNHC7LCEMJ0tVXDdgVBggNb6KlASmG3XqITIIE6fPk3Dhg3Ztm0bAGPHjpXkI4SFLbfkvgp8A+RVSnUAnmitv7J7ZEI4Ma01S5cuxdvbmxMnTvDgwQOzQxLC4djSC64bsA/oCnQD/JRSL9k7MCGc1dWrV+nQoQNDhw6lYcOGHDlyhBdeeMHssIRwOLa0AU0G6mitrwMopQoDvwFr7RmYEM5q3bp1bNu2jYULFzJ8+HBcXGyp6RYi87ElAblEJx+LW9jWdiREpnHv3j3++ecfGjRowNChQ2nTpg3ly5s2WIgQTsGWBPSzUuoXYLXldXdgi/1CEsK57Nq1i1deeYX79+9z4cIFcuXKJclHCBvY0glhHLAU8LQ8PtVay72ARKYXGhrKxIkTadKkCa6urvzvf/+TW2QLkQwJloCUUhWBj4AKwBHgDa11UHoFJoQju3//Po0bN+bvv/9m8ODBzJkzh9y5c5sdlhBOJbES0DJgM9AFY0TsRekSkRBOwN3dnebNm7Np0yaWLl0qyUeIFEgsAblrrT/TWp/UWn8ElE2nmIRwSBcvXqRdu3b8888/AMydO5eOHTuaHJUQziuxTgjZlVI1+fc+QDmsX2utD9o7OCEcgdaab775huHDhxMVFcWZM2eoUaOG2WEJ4fQSS0BXgLlWr69avdZAc3sFJYSjuH37NkOHDmXNmjU0bNiQr776Snq4CZFGErshXbP0DEQIR7R48WI2bNjA+++/z7hx43B1dTU7JCEyDFuuAxIiU3n06BEXLlygatWqTJgwgc6dO+Ph4WF2WEJkODKigRBW/P39qVWrFm3btiU0NJRs2bJJ8hHCTiQBCQFERETw7rvvUr9+fR4+fMgXX3xBtmzZzA5LiAwtySo4pZQCegHltdbTlVKlgWe01vvsHp0Q6eD27du0b9+ev/76i549e7J48WK5TbYQ6cCWEtDHQH2gh+X1fWCJ3SISIp3ly5ePkiVLsnr1ar755htJPkKkE1sSkK/WejjwBEBrfQfIateohLCza9eu0bt3b4KCgnBxcWHNmjW8/PLLZoclRKZiSwIKV0q5Ylz7E30/oChbNq6UaqOUOqmUOqOUmpjIcl2UUlop5WNT1EKkwoYNG6hRowY//PAD/v7+ZocjRKZlSwJaCKwHiiil3gP+BGYmtZIlaS0B2gLVgB5KqWrxLOcOjAb8khG3EMl2//59Bg4cSOfOnSldujQHDhygU6dOZoclRKZly+0YvgHGA+9jjI7wotZ6jQ3brguc0Vqf01qHAd8C8X3b3wU+wFLFJ4S9zJkzhxUrVjB58mT27t1LtWpPnQ8JIdKRLb3gSgOPgP9ZT9NaX0xi1RLAJavXlwHfONuuBZTSWv+olBqXSAyDgcEA+UrnIDQslFvBwUmFnuncvn3b7BAcTlhYGLdu3aJYsWL069ePDh064OPjw82bN80OzaHIZydxcnwSVrx48RSva8tICD9itP8oIDtQDjgJVE/xXgGllAvG2HL9klpWa/0p8ClAgTI5dbas2VL1pjMyOS7/Onr0KL169cLFxYX9+/cD0KBBA5Ojclzy2UmcHJ+0Z0sVnIfW2tPytyJG1dpeG7YdBJSyel3SMi2aO1AD+EMpFQjUAzZJRwSRWlFRUcybN4/atWsTHBzM1KlTZQw3IRxQsseC01ofVEr5Jr0k+4GKSqlyGInnZaCn1XZCgELRr5VSf2DcdVW6JYkUu3HjBi+//DLbtm3jhRde4LPPPqNIkSJmhyWEiIctbUD/sXrpAtQCkmyA0VpHKKVGAL8ArsAyrfVRpdR0wF9rvSmFMQuRIHd3dx4/fsznn3/OgAEDMAbyEEI4IltKQO5WzyMw2oR+sGXjWustwJY406YksGxTW7YpRFy3b99m2rRpvPvuu+TJk4fdu3dL4hHCCSSagCzX8rhrrd9Ip3iESJZff/2V/v37c+3aNVq1akX79u0l+QjhJBLshKCUctNaRwIN0zEeIWzy+PFjRo8eTatWrciTJw9+fn60b9/e7LCEEMmQWAloH0Z7T4BSahOwBngYPVNrvc7OsQmRoFGjRvH5558zevRo3n//fXLkyGF2SEKIZLKlDSg7cAtozr/XA2lAEpBIVxERETx48IB8+fLx9ttv0717d1q2bGl2WEKIFEosARWx9ID7h38TTzRt16iEiOPs2bP06dOHPHny8NNPP1G6dGlKly5tdlhCiFRI7EJUVyC35eFu9Tz6IYTdaa357LPP8PLy4vjx4/Tt21c6GQiRQSRWArqitZ6ebpEIEcfNmzcZMGAA//vf/2jRogXLly+nVKlSSa8ohHAKiZWA5DRTmMrFxYVjx44xf/58tm7dKslHiAwmsRJQi3SLQgiL+/fvM3/+fCZMmECBAgU4duwYWbPKDXiFyIgSLAFprWX8cZGudu/ejZeXF1OnTmXHjh0AknyEyMBsuSOqEHYVFhbGpEmTeO655wDYsWMHzz//vMlRCSHsLdmjYQuR1vr378+qVasYOHAg8+bNw93dPemVhBBOTxKQMEVUVBRhYWFkz56dcePG0a1bNzp1iu+O7UKIjEqq4ES6u3TpEs8//zwjR44EwNvbW5KPEJmQJCCRrlatWoWHhwd+fn74+tpyX0MhREYlCUikizt37tCjRw969epFtWrVCAgIYNCgQWaHJYQwkSQgkS7u3bvHr7/+yowZM9i5cyfPPvus2SEJIUwmnRCE3Tx+/JivvvqKwYMHU6ZMGc6dO0eePHnMDksI4SCkBCTs4uDBg9SuXZuhQ4eye/duAEk+QohYJAGJNBUREcHMmTPx9fUlJCSEX375hUaNGpkdlhDCAUkVnEhTPXr0YO3atXTr1o1PPvmEAgUKmB2SEMJBSQISqaa1JioqCldXVwYPHkznzp3p0aOH3LdHCJEoSUAiVa5du8arr75KrVq1mDp1qozhJoSwmbQBiRTbtGkTHh4ebN26VarahBDJJglIJNv9+/cZNGgQnTp1okSJEhw4cIBRo0aZHZYQwslIAhLJdubMGb7++msmTpyIn58f1atXNzskIYQTkjYgYZOwsDC2bNnCiy++SM2aNTl37hzFixc3OywhhBOTEpBI0rFjx6hXrx6dO3cmICAAQJKPECLVJAGJBEVFRbFw4UJq167NpUuXWL9+Pd7e3maHJYTIIKQKTiSoa9eurFu3jvbt2/PFF19QtGhRs0MSQmQgkoDEU7TWKKXo3LkzrVu35tVXX5WLSoUQaU4SkIhx584dRowYQbNmzRg0aBC9e/c2OyQhRAYmbUACgN9//x1PT0++//577t69a3Y4QohMQBJQJvf48WPGjBlDy5YtyZ07N3v37uWNN94wOywhRCYgCSiT27t3LwsWLGDkyJEcOHAAHx8fs0MSQmQS0gaUCUVGRrJ3714aNWpE8+bNOXr0KFWrVjU7LCFEJiMloEzm3LlzPPfcczRt2pTTp08DSPIRQphCElAmobXmiy++wMvLi6NHj/Lll1/y7LPPmh2WECITkyq4TEBrTbdu3Vi7di3NmjVjxYoVlC5d2uywhBCZnCSgTEAphY+PDw0aNGD06NG4uEjBVwhhPrv+Eiml2iilTiqlziilJsYz/z9KqWNKqcNKqd+VUmXsGU9m8uDBA4YMGcKPP/4IwIQJExgzZowkHyGEw7BbCUgp5QosAZ4HLgP7lVKbtNbHrBY7BPhorR8ppV4DPgS62yumzGLv3r306dOHc+fOUb58edq3b29aLOHh4Vy+fJknT56YFkO0yMhIQkJCzA7DIcmxSZwcH8iePTslS5YkS5YsabZNe1bB1QXOaK3PASilvgU6ATEJSGu93Wr5vwAZ+yUVwsPDefvtt5k5cyalS5dmx44dNG7c2NSYLl++jLu7O2XLljV9PLmwsDCyZs1qagyOSo5N4jL78dFac+vWLS5fvky5cuXSbLv2rI8pAVyyen3ZMi0hA4Gf7BhPhvfLL78wY8YM+vbty99//2168gF48uQJBQsWND35CCFSTilFwYIF07wmwyE6ISilegM+QJME5g8GBgPkK52D0LBQbgUHp2OEjisqKoozZ85QqVIl6tevz4YNG6hTpw4PHjzgwYMHZodHZGQk4eHhZocBGLGEhYWZHYZDkmOTODk+hsjISILj/Pam5uaU9kxAQUApq9clLdNiUUq1BCYDTbTWofFtSGv9KfApQIEyOXW2rNnkjpxAUFAQAwYMYO/evZw4cYKCBQvi4eFhdlixhISEOEzVRWavRkmMHJvEyfExuLq6pulvrz2r4PYDFZVS5ZRSWYGXgU3WCyilagJLgRe01tftGEuG89133+Hh4cHu3bv56KOPJCEnwtXVFW9vb2rWrEnHjh1jjfZ99OhRmjdvTuXKlalYsSLvvvsuWuuY+T/99BM+Pj5Uq1aNmjVrMnbsWDPeQqIOHTrEwIEDzQ4jQaGhoXTv3p1nn30WX19fAgMD411uwYIF1KhRg+rVqzN//vxY8xYtWkSVKlWoXr0648ePB+DIkSP069cvwf326NEDT09P5s2bl6K4V6xYgYuLC4cPH46ZVqNGjQTjT8jNmzfJkiUL//3vf2NNL1u2LDdv3uTu3bt8/PHHKYoxIfPnz+fRo0cxr9u1a+eYo9xrre32ANoBp4CzwGTLtOkYCQfgN+AaEGB5bEpqm/lL59B6WTudWUVEROhevXppQPv6+upTp07FzAsKCjIxsvgdO3bM7BB0rly5tNZah4aG6ldeeUXPmDFDa631o0ePdPny5fUvv/yitdb64cOHuk2bNnrx4sVaa62PHDmiy5cvr48fP661No79xx9/nKaxhYeHp3obL730kg4ICEjVPkNDQ1MdR0KWLFmihwwZorXWevXq1bpbt25PLXPkyBFdvXp1/fDhQx0eHq5btGihT58+rbXWetu2bbpFixb6yZMnWmutr127FrNeixYt9IULF57a3pUrV3SFChWSFWfc47J8+XJdqlQp3a1bt5jjU716dX3+/Plkbffjjz/WjRo10s8991ys6WXKlNE3btzQ58+f19WrV0/WNqOionRkZGSC86O3ndYS+D6nOEfYtQ1Ia70F2BJn2hSr5y3tuf+MyNXVlbx58zJ9+nTefPNN3NwcohnPJtP+d5RjwffSdJvViufhnY7VbV6+fv36MWe0q1atomHDhrRq1QqAnDlzsnjxYpo2bcrw4cP58MMPmTx5MlWqVAGMY//aa689tc0HDx4wcuRI/P39UUrxzjvv0KVLF3Lnzh3TDrd27Vo2b97MihUr6NevH9mzZ+fQoUM0bNiQdevWERAQQL58+QCoWLEif/75Jy4uLgwdOpSLFy8Cxlltw4YNY+37/v37HD58GC8vLwD27dvH6NGjefLkCTly5GD58uVUrlyZFStWsG7dOh48eEBkZCRbtmxh5MiR/PPPP4SHhzN58mReeuklAgMD6dOnDw8fPgRg8eLFNGjQwObjG5+NGzcydepUAF566SVGjBgRc9fdaMePH8fX15ecOXMC0KRJE9atW8f48eP55JNPmDhxItmyZQOgSJEiMet17NiRb7/9NqZUFK1Vq1YEBQXh7e3NokWLcHd3Z+jQoTx69IgKFSqwbNky8ufPT9OmTfH29ubPP/+kR48eT5VwO3TowM6dOzl58uRT1durV69m5syZaK1p3749H3zwQbzvf/Xq1cyZM4eePXty+fJlSpYsGWv+xIkTOXv2LN7e3jz//PPMnj2b2bNn8/333xMaGkrnzp2ZNm0agYGBtG7dGl9fXw4cOMCWLVuYNWsW+/fv5/Hjx7z00ktMmzaNhQsXEhwcTLNmzShUqBDbt2+nbNmy+Pv7U6hQIebOncuyZcsAGDRoEK+//jqBgYG0bduWRo0asWfPHkqUKMHGjRvJkSOHrf/mFJGrEp3AkydPGDt2LAcOHACMH4W3337bqZKPI4iMjOT333/nhRdeAIzqt9q1a8dapkKFCjx48IB79+7xzz//PDU/Pu+++y558+blyJEjHD58mObNmye5zuXLl9mzZw9z586lU6dOrF+/HgA/Pz/KlClD0aJFGT16NGPGjGH//v388MMPDBo06Knt+Pv7U6NGjZjXVapUYdeuXRw6dIjp06czadKkmHkHDx5k7dq17Nixg/fee4/mzZuzb98+tm/fzptvvsnDhw8pUqQIv/76KwcPHuS7775j1KhR8cbfuHFjvL29n3r89ttvTy0bFBREqVJGc7Cbmxt58+bl1q1bsZapUaMGu3bt4tatWzx69IgtW7Zw6ZLRifbUqVPs2rULX19fmjRpwv79+2PW8/HxYdeuXU/tc9OmTVSoUIGAgAAaN27MK6+8wgcffMDhw4fx8PBg2rRpMcuGhYXh7+8fb/Wqi4sL48eP58MPP4w1PTg4mAkTJrBt2zYCAgLYv38/GzZseGr9S5cuceXKFerWrUu3bt347rvvnlpm1qxZMbHOnj2brVu3cvr0afbt20dAQAAHDhxg586dAJw+fZphw4Zx9OhRypQpw3vvvYe/vz+HDx9mx44dHD58mFGjRlG8eHG2b9/O9u3bY+3rwIEDLF++HD8/P/766y8+++wzDh06FLPt4cOHc/ToUfLly8cPP/zwVKxpTX7BHNyhQ4fo06cPR48epUiRItSuXdtpuzQnp6SSlh4/foy3tzdBQUFUrVqV559/Pk23/9tvv/Htt9/GvM6fP3+S63Tt2hVXV1cAunfvzvTp0+nfvz/ffvst3bt3j9nusWP/Xrd97949Hjx4QO7cuWOmXblyhcKFC8e8DgkJoW/fvpw+fRqlVKweiM8//zwFChQAYOvWrWzatImPPvoIMNppLl68SPHixRkxYgQBAQG4urpy6tSpeOOP70c/NapWrcqECRNo1aoVuXLlwtvbO+b4REREcPv2bf766y/2799Pt27dOHfuHEopihQp8lSvrLhCQkK4e/cuTZoYnWz79u1L165dY+ZHH++E9OzZkxkzZnD+/PmYafv376dp06Yxx75Xr17s3LmTF198Mda63333Hd26dQPg5ZdfZsCAAUm2I27dupWtW7dSs2ZNwChhnz59mtKlS1OmTBnq1asXs+z333/Pp59+SkREBFeuXOHYsWN4enomuO0///yTzp07kytXLgD+7//+j127dvHCCy9Qrlw5vL29Aahdu3ay27pSQhKQg4qMjGT27NlMmTKFQoUK8dNPP9GmTRuzw3JKOXLkICAggLt379KxY0eWLFnCqFGjqFatWsyZZbRz586RO3du8uTJQ/Xq1Tlw4EBM9VZyWZ8oxL1+IvoHAIxqwTNnznDjxg02bNjAW2+9BRhd7P/66y+yZ8+e6Huz3vbbb79Ns2bNWL9+PYGBgTRt2jTefWqt+eGHH6hcuTLwby+vqVOnUrRoUf7++2+ioqIS3Hfjxo25f//+U9M/+ugjWraMXbNeokQJLl26RMmSJYmIiCAkJISCBQs+te7AgQNjOlNMmjQppqqqZMmS/N///R9KKerWrYuLiws3b96kcOHCMVWNqWF9XOLj5ubG66+/nmAVW2JWr17N1atX+eabbwCj5HT69GkqVqyY4Dpaa958802GDBkSa3pgYGCsWM+fP89HH33E/v37yZ8/P/369UvVdTrRVZxgVDc/fvw4xduylVTBOajly5fz5ptv0qlTJ44cOSLJJw3kzJmThQsXMmfOHCIiIujVqxd//vlnTLXR48ePGTVqVEx7wrhx45g5c2ZMKSAqKuqpnkxglCyWLFkS8/rOnTsAFC1alOPHjxMVFRVTxRYfpRSdO3fmP//5D1WrVo35cW7VqhWLFi2KWS4gIOCpdatWrcqZM2diXoeEhFCihHG994oVKxLcZ+vWrVm0aFFMj7/obYeEhFCsWDFcXFxYuXIlkZGR8a6/a9cuAgICnnrETT4AL7zwAl9++SVgtIU1b9483lL89etGR9iLFy+ybt06evbsCcCLL74YU5V06tQpwsLCKFSoUMxr6yrI+OTNm5f8+fPHlNpWrlwZUxqy1SuvvMJvv/3GjRs3AKhbty47duzg5s2bREZGsnr16qe2eerUKR48eEBQUBCBgYEEBgby5ptvsnr16ljLubu7x0rmrVu3ZtmyZTHth0FBQTHHxtq9e/fIlSsXefPm5dq1a/z0008JbjNa48aN2bBhA48ePeLhw4esX7/e1AvWJQE5EK01QUHGpVJ9+/Zl48aNfP/99/GeLYqUqVmzJp6enqxevZocOXKwceNGZsyYQeXKlfHw8KBOnTqMGDECAE9PT+bPn0+PHj2oWrUqNWrU4Ny5c09t86233uLOnTvUqFEDLy+vmB/LWbNm0aFDBxo0aECxYsUSjat79+58/fXXsaqDFi5ciL+/P56enlSrVi3e5FelShVCQkJifmzGjx/Pm2++Sc2aNYmIiEhwf2+//Tbh4eF4enpSvXr1mE4Cw4YN48svv8TLy4sTJ04kWTqwxcCBA7l16xbPPvssc+fOZdasWYBRGmjXrl3Mcl26dKFatWoxpdToThkDBgzg3Llz1KhRg5dffpkvv/wyJoFt377dprEOv/zyS8aNG4enpycBAQFMmTIlyXWsZc2alVGjRsUkgmLFijFr1iyaNWuGl5cXtWvXplOnTrHWWb16NZ07d441rUuXLk8loIIFC9KwYUNq1KjBuHHjaNWqFT179qR+/fp4eHjw0ksvxZtMvLy8qFmzJlWqVKFnz56xOqgMHjyYNm3a0KxZs1jr1KpVi379+lG3bl18fX0ZNGhQTFWfGVT0GZCzKFAmp749tRn0/9HsUNLUjRs3GDx4MH5+fhw9etSmdoS4goODHe56oOPHjzvMHVcz6sWE8+bNw93dPd5OCrZyxmMTGhpKkyZN+PPPP+3eIccZj489JPB9TnGjtJSAHMDmzZupUaMGW7Zs4Y033iBv3rxmhyScyGuvvRar/j6zuHjxIrNmzZLeoE5M/nMmCgsLY+TIkXz66ad4enry22+/OdxQOsLxZc+enT59+pgdRrqrWLFioo35wvFJCchEWbJk4erVq4wfP559+/ZJ8hFCZCpSAkpn4eHhzJw5k1deeYVy5cqxbt26mOsdhBAiM5ESUDo6ceIE9evXZ+rUqaxduxZAko8QItOSBJQOoqKiWLx4MTVr1iQwMJC1a9cybtw4s8PKNGQ0bHOldjTsv//+O6ZLcseOHbl3zxhP0N6jYUd78cUXU3ytTHBwMC+99BIAf/zxBx06dACMa7Siu/v/97//5auvvkpVjE4rNSOZmvFwxtGw582bpwHdtm1bHRwcbLf9yGjY8ZPRsJPepyOPhu3j46P/+OMPrbXWX3zxhX7rrbdi1rPnaNhaa33nzh1dsmRJXblyZX327Fmb14vP9u3bdfv27bXWxkjbw4cPT1Z8jiCtR8OWEpAdhYSEAMaFeMuXL+fHH39M8oJEYV/169ePudg3odGwoy+UTM5o2P3798fDwwNPT8+YQRytx2xbu3ZtzNl6v379GDp0KL6+vowfP56yZcvGKpVVrFiRa9eucePGDbp06UKdOnWoU6cOu3fvfmrf8Y2GXb9+fWrWrEmDBg04efIkYJxxv/DCCzRv3pwWLVrw8OFDBgwYQN26dalZsyabNhm36goMDKRx5z90KgAAFGFJREFU48bUqlWLWrVqsWfPnpQfbIuNGzfSt29fwBgN+/fff49VyoTYo2G7ubnFjIYNxogCzz33HGCMOmE9SGb0aNhxWY+GHT1qQ7169fD09KRz584xo1U0bdqU119/HR8fHxYsWPDUdtatW0fHjh3p1q1brP3E/R+ePXuWevXq4eHhwVtvvRXzvw8MDExypIapU6fGjMl35swZWrZsiZeXF7Vq1eLs2bOJH1wnJ50Q7ODu3buMHDmSgwcP4u/vj7u7e6JVBZnGTxPh6pG03eYzHtB2lk2LRo+GHV1dZcto2LZUuVmPhg3/DsWTmOjRsF1dXYmMjGT9+vX0798/1mjYPXv2ZMyYMTRq1IiLFy/SunVrjh8/Hms7CY2G7ebmxm+//cakSZNifrAPHjzI4cOHKVCgAJMmTaJ58+YsW7aMu3fvUqdOHdq2bRszGnb27Nk5ffo0PXr0wN/f/6n4kzMWXEKjYUcPpwPGaNiTJ0/m1q1b5MiRgy1btuDj4wNA9erV2bhxIy+++CJr1qyJGSUbjNGwZ82a9dTtGDZt2kSHDh1ihhjy9PRk0aJFNGnShClTpjBt2rSYar7o0bDjs3r1aqZMmUL+/Pnp0aNHrNHFrf+HHTp0YPTo0fTo0SPeESts1atXLyZOnEjnzp158uQJUVFRKd6WM5AElMa2b99O3759CQ4OZsqUKWTJksXskDI9GQ3b4KyjYS9btoxRo0bx7rvv8sILL8QakcCeo2Ffu3aN06dP06hRI8LDw8mSJQv//PNPTMK3/h/u3bs35nYMPXv25I033kj2Mbh//z5BQUExw/ckNghtRiEJKI2EhoYyadIk5s6dS6VKldi7dy916tQxOyzHYmNJJa3JaNhP71M70WjYVapUYevWrYBRHffjj/8Ow2XP0bC///577ty5Q7ly5QDjBGD16tW89957ia4nbCdtQGnExcWFXbt2MWzYMA4dOiTJxwHJaNj/cqbRsKOnR0VFMWPGDIYOHRqzjj1Hw169ejU///wzgYGBnDp1igMHDsTb3gRQr169mKrOhJZJiru7OyVLlowpSYWGhvLo0aMUbctZSAJKhcjISBYsWMDt27fJkiULO3bsYMmSJTG3FRaOR0bDNjjTaNirV6+mUqVKVKlSheLFi9O/f/+Ydew1GnZgYCAXLlyIdfO3cuXKkTdvXvz8/J5afv78+cydOxdPT0/OnDmT4vEcV65cycKFC/H09KRBgwZcvXo1RdtxGqnpQmfGw1G6YZ87d07/f3t3Hx1VfSZw/PvEFyIQiYXVI2vBbopKhJ7IazWCKfYAqx7YSqrlCIgQhSwGtFAV9cgSRIsIaLFYjECIa1sk0spqWLbbDUJahQCBAd9QC7LILiKCZwkEYvLsH/dOHJKZzOT1zsvzOWcOd2Z+985vnpnwm3vv7z7PjTfeqIAuWbLE6+6oqk3DDqctpxp7afHixVpQUNCibcRibKqqqnTw4MGtMpU9nHDxqays1NraWlV1ppqPGjWqzfvkhdaehm3ngJpIVSksLGT69OkkJSVRVFTEuHHjvO6WSWC5ubmsXbvW6260u2jKhr1jxw7uv/9+VJXU1FRWrlzpdZdigvefXBMl4e20xAULFjB79myGDh1KUVERPXv29LQ/xlg2bO8NGTKE3bt3e92NmBNzAxAAfbPb/SXPnDlDhw4duPvuu0lOTiYvL8/yuBljTAvE3CSEWpJgwD3hG7aSyspKcnNzGTlyJLW1tVx++eU88MADNvgYY0wLxdwA1J62bt1KRkYGy5cvZ+DAgSGnpBpjjGk6G4CCqK6uZs6cOWRmZnL27FlKS0t55plnLKuBMca0IhuAgqiqqqKoqIi77roLn88X0UVrxhhjmsYGIJeqUlRURFVVFSkpKezYsYPVq1c3+4IyEz2sHpC3YrUeUGDNntYW7nsXTKi6QZFk3I5aLbmIyIvbJT0uavLFU+F8/vnnOnz4cAV0+fLlrb799mIXogZn9YDCv6bVA2oYl8CaPYHxaelnFu5711T79+/Xa6+9tkV9ipRdiNrK1q5dy9SpUzl9+jTLli3j3nvv9bpLcWvBtgV8+NWHrbrNa75zDQ8Pejji9tdffz0+nw8IXQ8oKyuLadOmNakeUF5eHtu3b0dEmDNnDmPGjKFz586cPHkScHKgvfnmmxQWFjJx4kSSk5OpqKggMzOTdevWsWvXrrrUM7169aKsrIykpCSmTp3KwYMHASfdS2Zm5jmvHawe0IwZM+qSdK5atYqrr76awsJC1q1bx8mTJ6mpqaGkpIS8vDz27t1LdXU1jz32GNnZ2Rw4cIDx48dTWVkJwAsvvMANN9wQcXyDeeONN+pS/WRnZ9ddsBmYDy6wHhBQVw/ooYcealAPaMSIEcybNw/4th5Q/XIMgfWAli5dSkpKClOnTuXUqVOkpaWxcuVKLrnkErKyssjIyKCsrIyxY8eG3MPNycmhY8eOdZ/ZhAkTQm5v8ODBlJaWcuLECVasWNGgmmq4792MGTPo2rUrTzzxBBs3bmT+/Pls2rSJ/Px8OnfuzKxZs9ixYweTJk2qe69+NTU1PPLII2zatIkzZ84wbdo0pkyZ0tyPrs0l9CG4efPmcccdd5CWlkZFRQW5ublBkySa+OCvBzRq1CggsnpA9Z8PJrAekM/nY9iwYWHX8deSWbx4MaNHj65LVhpYD2jGjBk8+OCDlJeX8/rrr5OTk9NgO6HqAVVUVJCfn39O/ZqdO3dSXFzM22+/zfz58xk2bBjbtm2jtLSU2bNnU1lZWVcPaOfOnaxZs4bp06cH7f+QIUPIyMhocPMndg0Uqh5QoD59+rBlyxaOHTvGqVOnKCkpqav7468HBAStBxSsNMT69etJS0tj165dDBkyhAkTJrBgwQJ8Ph99+/Zl7ty5dW399YDCHV4N/Mwa294333zDtm3beO6558553C/c9+7pp59mzZo1lJaWMn36dFatWkVS0rn/Vd9zzz0sXbq0wcWvK1asoEuXLpSXl1NeXk5BQQH79+9v9H15KSH3gGpra0lKSiI7O5va2loeffRRm+HWDpqyp9KarB6Qw+oBNa0eUH3+zyzc9m6//XYA+vfvH/J8V2M6duxIQUEBQ4cOZcmSJaSlpZ3z/IkTJzhx4kTdXuH48ePZsGED4HyuPp+P4uLiuvf+8ccf15WUiDYJNQBVVVXx+OOPc+TIEV555RV69+7NnDlzvO6WaWNWD6jha6rVA6oTacbvSNt16NABcA7ZBstIHu57B84Ei65du4YdXOtTVZYuXcqIESOatJ5XEuYQnM/nY9CgQSxatIiUlJRGU9Wb+GT1gL5l9YCaf2lFS7cX7nv32WefsWjRIioqKtiwYUOD8g+pqamkpqZSVlYGwKuvvlr33IgRI3jxxRfr9nz37dtXdz4vGsX9AFRTU8PChQsZOHAgR48epaSkhGXLlkVFBl3T/qwekMPqATVeD6gtt9fY905VmTx5Ms8++yzdu3dnxYoV5OTkNNiDXrVqFdOmTSMjI+Oc6ds5OTmkp6fTr18/+vTpw5QpU6L6x7YEdj4WfKdnR/3qs8irBB45coT09HSysrJYvnw53bp1a8Peeevw4cN0797d626c44MPPqB3795edwP49jBTvFmyZAkpKSlBJylEKhZjc+bMGW666SbKysra/AdlLManLYT4e272zK243ANSVd566y1qa2u57LLLqKiooLi4OK4HH5O4cnNz6847JJJoqgdkmifuBqAvv/yS7OxsbrvttrqZST169LDp1SZuJXI9oMBJFib2xNVPh5KSEiZNmsTx48dZuHBhxNMrTduqf9GhMSb2tMXpmrjZA8rPz+fWW2/l0ksvpby8nFmzZlnNniiQnJzMsWPH2uTLa4xpH6rKsWPHGr0koDniZg8oKyuLmTNn8uSTT7Z6kEzzXXHFFRw6dIijR4963RVqamrsR0kIFpvGWXycH5P+a7NaS5vOghORkcDzwHnAy6r6y3rPdwCKgP7AMeBOVT3Q2Db9s+Cqq6uZP38+Z8+e5amnnmqbNxBjonEWXDSx+IRmsWmcxadR0TcLTkTOA34N/COQDowVkfR6zSYDx1X1+8ASYEEk2/7oo4/IzMxk7ty5HD582A7vGGNMDGrLc0CDgE9U9W+qehb4PTC6XpvRwGp3uRi4WSI4W33dddfx6aef8tprr1FYWGgnuI0xJga15QD098B/B9w/5D4WtI2qfgN8DTRMEhVAUYYOHcqePXvOSQBojDEmtsTEJAQRuQ+4z717ZuPBjXv9+a7MOboBX3rdiShm8QnNYtM4i09oe1W1WSVZ23IA+hz4bsD9K9zHgrU5JCLnA11wJiOcQ1VfAl4CEJHtqjqgTXoc4yw2jbP4hGaxaZzFJzQR2d7cddvyEFw50EtEviciFwI/A9bXa7MeuNtdzgb+S21GgTHGJIQ22wNS1W9E5H5gI8407JWq+p6I5APbVXU9sAJ4RUQ+Ab7CGaSMMcYkgDY9B6SqJUBJvceeCFiuApo6k+ClVuhavLLYNM7iE5rFpnEWn9CaHZuYK8dgjDEmPsRNLjhjjDGxJWoHIBEZKSIficgnIvJIkOc7iMga9/mtInJl+/fSGxHE5uci8r6I+ETkzyLS04t+eiVcfALajRERFZGEmd0USWxE5A73+/OeiPy2vfvopQj+tnqISKmIVLh/X7cE2068EZGVIvKFiOwN8byIyK/cuPlEpF9EG1bVqLvhTFr4FPgH4EJgN5Ber80/A79xl38GrPG631EUmx8BHd3l3ESJTaTxcdulAJuBd4EBXvc7WmID9AIqgEvc+5d63e8oi89LQK67nA4c8Lrf7RSboUA/nGt+gj1/C7ABJy/cD4GtkWw3WveA2iyNTxwIGxtVLVVVf93yd3GuwUoUkXx3AObh5B6sas/OeSyS2NwL/FpVjwOo6hft3EcvRRIfBS52l7sAh9uxf55R1c04M5VDGQ0UqeNdIFVELg+33WgdgNokjU+ciCQ2gSbj/DJJFGHj4x4e+K6qvtWeHYsCkXx3rgKuEpG/iMi7bkb7RBFJfP4FGCcih3Bm+Oa1T9eiXlP/XwJiJBWPaR4RGQcMAG7yui/RQkSSgMXARI+7Eq3OxzkMl4Wz57xZRPqq6glPexU9xgKFqrpIRK7HuY6xj6rWet2xWBSte0BNSeNDY2l84lAksUFEfgw8BoxS1TPt1LdoEC4+KUAfYJOIHMA5Xr0+QSYiRPLdOQSsV9VqVd0P7MMZkBJBJPGZDLwGoKrvAMk4eeISXUT/L9UXrQOQpfEJLWxsROQ6YDnO4JNIx/AhTHxU9WtV7aaqV6rqlTjnyEaparPzWcWQSP6u/oiz94OIdMM5JPe39uykhyKJz0HgZgAR6Y0zAHlf7td764EJ7my4HwJfq+r/hFspKg/BqaXxCSnC2CwEOgNr3XkZB1V1lGedbkcRxichRRibjcBwEXkfqAF+oaqJcGQh0vjMBApE5EGcCQkTE+GHr4j8DueHSTf3/Ncc4AIAVf0NzvmwW4BPgFPAPRFtNwFiZ4wxJgpF6yE4Y4wxcc4GIGOMMZ6wAcgYY4wnbAAyxhjjCRuAjDHGeMIGIBPzRKRGRHYF3K5spO3JVni9QhHZ777WTveK+KZu42URSXeXH6333F9b2kd3O/647BWRfxOR1DDtMxIlu7OJDjYN28Q8ETmpqp1bu20j2ygE3lTVYhEZDjyrqj9owfZa3Kdw2xWR1cA+VZ3fSPuJOJnB72/tvhgTjO0BmbgjIp3dOkg7RWSPiDTIhi0il4vI5oA9hCHu48NF5B133bUiEm5g2Ax831335+629orIA+5jnUTkLRHZ7T5+p/v4JhEZICK/BC5y+/Gq+9xJ99/fi8itAX0uFJFsETlPRBaKSLlbe2VKBGF5Bzc5pIgMct9jhYj8VUSudq/8zwfudPtyp9v3lSKyzW0bLKu4Mc3ndZ0Ju9mtpTecK/Z3ubc/4GT4uNh9rhvO1dn+vf2T7r8zgcfc5fNwcsR1wxlQOrmPPww8EeT1CoFsd/mnwFagP7AH6ISTheI94DpgDFAQsG4X999NuHWI/H0KaOPv40+A1e7yhTjZhi8C7gMedx/vAGwHvheknycD3t9aYKR7/2LgfHf5x8Dr7vJE4IWA9Z8CxrnLqTh54Tp5/XnbLX5uUZmKx5gmOq2qGf47InIB8JSIDAVqcX75Xwb8b8A65cBKt+0fVXWXiNyEU2TsL24Kowtx9hyCWSgij+PkAZuMkx/sD6pa6fZhHTAE+HdgkYgswDlst6UJ72sD8LyIdABGAptV9bR72O8HIpLttuuCkzB0f731LxKRXe77/wD4U0D71SLSCyedzAUhXn84MEpEZrn3k4Ee7raMaTEbgEw8ugv4O6C/qlaLk/U6ObCBqm52B6hbgUIRWQwcB/6kqmMjeI1fqGqx/46I3ByskaruE6f+0C3AkyLyZ1XNj+RNqGqViGwCRgB34hRIA6fqZJ6qbgyzidOqmiEiHXHym00DfoVTjK9UVX/iTtjYFGJ9Acao6keR9NeYprJzQCYedQG+cAefHwE96zcQkZ7AEVUtAF7GKTf8LpApIv5zOp1E5KoIX3ML8E8i0lFEOuEcPtsiIt2BU6r6rzhJYvsFWbfa3RMLZg1OYkf/3hQ4g0mufx0Rucp9zaDUqY47HZgp35Yu8afKnxjQ9P9wDkX6bQTyxN0dFCfLujGtxgYgE49eBQaIyB5gAvBhkDZZwG4RqcDZu3heVY/i/If8OxHx4Rx+uyaSF1TVnTjnhrbhnBN6WVUrgL7ANvdQ2BzgySCrvwT4/JMQ6vkPnIKC/6lOmWhwBsz3gZ0ishen9EajRzPcvvhwCqo9AzztvvfA9UqBdP8kBJw9pQvcvr3n3jem1dg0bGOMMZ6wPSBjjDGesAHIGGOMJ2wAMsYY4wkbgIwxxnjCBiBjjDGesAHIGGOMJ2wAMsYY4wkbgIwxxnji/wGHSKrauLfxmQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'MLP_SGD'\n",
        "NAME = 'Landsat9_DATA'\n",
        "optimiser_type = 'sgd'\n",
        "experimental_runs = 10\n",
        "\n",
        "best_model, best_history, avg_y_pred, df = MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "best_model.save('Best_model_{}_{}'.format(NAME, Model_name))\n",
        "plot_metric(best_history, \"loss\")\n",
        "print(\"\")\n",
        "plot_metric(best_history, \"accuracy\")\n",
        "# plot_AUC_ROC(best_model, test_x, test_y, 3, label_names)\n",
        "# print(\"\")\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "print(avg_y_pred)\n",
        "test_y_dummies = test_y.argmax(axis = 1)\n",
        "plot_avg_AUC_ROC(avg_y_pred, test_y_dummies, 3, label_names)\n",
        "print(\"\")\n",
        "avg_y_pred = avg_y_pred.argmax(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l04kcgnPQkQV",
        "outputId": "1f35820c-c4e0-4483-905d-8935c787c943"
      },
      "id": "l04kcgnPQkQV",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_60 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_61 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_62 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0990 - accuracy: 0.3276 - val_loss: 1.0926 - val_accuracy: 0.3378\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0941 - accuracy: 0.3467 - val_loss: 1.0891 - val_accuracy: 0.3333\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0887 - accuracy: 0.3800 - val_loss: 1.0845 - val_accuracy: 0.3689\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0816 - accuracy: 0.3819 - val_loss: 1.0718 - val_accuracy: 0.4044\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.4305 - val_loss: 1.0652 - val_accuracy: 0.4022\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0662 - accuracy: 0.4305 - val_loss: 1.0601 - val_accuracy: 0.4044\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0611 - accuracy: 0.4610 - val_loss: 1.0556 - val_accuracy: 0.4178\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0558 - accuracy: 0.4705 - val_loss: 1.0514 - val_accuracy: 0.4867\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.4771 - val_loss: 1.0475 - val_accuracy: 0.5133\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0465 - accuracy: 0.4581 - val_loss: 1.0428 - val_accuracy: 0.5089\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0414 - accuracy: 0.4648 - val_loss: 1.0371 - val_accuracy: 0.4911\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0348 - accuracy: 0.4295 - val_loss: 1.0409 - val_accuracy: 0.4467\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0300 - accuracy: 0.4571 - val_loss: 1.0258 - val_accuracy: 0.4511\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0259 - accuracy: 0.4495 - val_loss: 1.0221 - val_accuracy: 0.5022\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0212 - accuracy: 0.4714 - val_loss: 1.0157 - val_accuracy: 0.4800\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0141 - accuracy: 0.4790 - val_loss: 1.0088 - val_accuracy: 0.4111\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0099 - accuracy: 0.4543 - val_loss: 1.0040 - val_accuracy: 0.4933\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0025 - accuracy: 0.5171 - val_loss: 0.9982 - val_accuracy: 0.5222\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9967 - accuracy: 0.5381 - val_loss: 0.9926 - val_accuracy: 0.5622\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9898 - accuracy: 0.5257 - val_loss: 0.9858 - val_accuracy: 0.6156\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9818 - accuracy: 0.6076 - val_loss: 0.9736 - val_accuracy: 0.5867\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9653 - accuracy: 0.6133 - val_loss: 0.9579 - val_accuracy: 0.5978\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9551 - accuracy: 0.6390 - val_loss: 0.9485 - val_accuracy: 0.6267\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9475 - accuracy: 0.6486 - val_loss: 0.9500 - val_accuracy: 0.7178\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9395 - accuracy: 0.6819 - val_loss: 0.9390 - val_accuracy: 0.7111\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9330 - accuracy: 0.6848 - val_loss: 0.9266 - val_accuracy: 0.6933\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9243 - accuracy: 0.6943 - val_loss: 0.9189 - val_accuracy: 0.7000\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9161 - accuracy: 0.7114 - val_loss: 0.9104 - val_accuracy: 0.6844\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9076 - accuracy: 0.6819 - val_loss: 0.9118 - val_accuracy: 0.7244\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9013 - accuracy: 0.7010 - val_loss: 0.8939 - val_accuracy: 0.6844\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8906 - accuracy: 0.7048 - val_loss: 0.8852 - val_accuracy: 0.6822\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8849 - accuracy: 0.6971 - val_loss: 0.8785 - val_accuracy: 0.6911\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8765 - accuracy: 0.7038 - val_loss: 0.8704 - val_accuracy: 0.6933\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8669 - accuracy: 0.7162 - val_loss: 0.8642 - val_accuracy: 0.7222\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8582 - accuracy: 0.7086 - val_loss: 0.8541 - val_accuracy: 0.6800\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8508 - accuracy: 0.6914 - val_loss: 0.8475 - val_accuracy: 0.7111\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8419 - accuracy: 0.7048 - val_loss: 0.8429 - val_accuracy: 0.7244\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8336 - accuracy: 0.7029 - val_loss: 0.8330 - val_accuracy: 0.7200\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8241 - accuracy: 0.7029 - val_loss: 0.8236 - val_accuracy: 0.6889\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8198 - accuracy: 0.7171 - val_loss: 0.8164 - val_accuracy: 0.6844\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8122 - accuracy: 0.7105 - val_loss: 0.8141 - val_accuracy: 0.7267\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8051 - accuracy: 0.7095 - val_loss: 0.8140 - val_accuracy: 0.7244\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7978 - accuracy: 0.7343 - val_loss: 0.7978 - val_accuracy: 0.7133\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7927 - accuracy: 0.7238 - val_loss: 0.7905 - val_accuracy: 0.6822\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7857 - accuracy: 0.7229 - val_loss: 0.7857 - val_accuracy: 0.6822\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7800 - accuracy: 0.7124 - val_loss: 0.7822 - val_accuracy: 0.6822\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7741 - accuracy: 0.7238 - val_loss: 0.7746 - val_accuracy: 0.6778\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7655 - accuracy: 0.7181 - val_loss: 0.7792 - val_accuracy: 0.7267\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7612 - accuracy: 0.7314 - val_loss: 0.7621 - val_accuracy: 0.7089\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7579 - accuracy: 0.7238 - val_loss: 0.7687 - val_accuracy: 0.7111\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7525 - accuracy: 0.7133 - val_loss: 0.7651 - val_accuracy: 0.7133\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.7257 - val_loss: 0.7496 - val_accuracy: 0.7178\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7426 - accuracy: 0.7229 - val_loss: 0.7430 - val_accuracy: 0.6956\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7359 - accuracy: 0.7219 - val_loss: 0.7405 - val_accuracy: 0.7178\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7297 - accuracy: 0.7162 - val_loss: 0.7352 - val_accuracy: 0.7156\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7241 - accuracy: 0.7267 - val_loss: 0.7304 - val_accuracy: 0.7133\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7223 - accuracy: 0.7295 - val_loss: 0.7270 - val_accuracy: 0.6956\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7181 - accuracy: 0.7324 - val_loss: 0.7240 - val_accuracy: 0.7267\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.7333 - val_loss: 0.7209 - val_accuracy: 0.7333\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7091 - accuracy: 0.7295 - val_loss: 0.7188 - val_accuracy: 0.7222\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7064 - accuracy: 0.7352 - val_loss: 0.7145 - val_accuracy: 0.7178\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7027 - accuracy: 0.7295 - val_loss: 0.7128 - val_accuracy: 0.7400\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6949 - accuracy: 0.7314 - val_loss: 0.7210 - val_accuracy: 0.7156\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6991 - accuracy: 0.7400 - val_loss: 0.7162 - val_accuracy: 0.7244\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6930 - accuracy: 0.7352 - val_loss: 0.7093 - val_accuracy: 0.7356\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6905 - accuracy: 0.7362 - val_loss: 0.6983 - val_accuracy: 0.7222\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6846 - accuracy: 0.7419 - val_loss: 0.7180 - val_accuracy: 0.7178\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6845 - accuracy: 0.7238 - val_loss: 0.7353 - val_accuracy: 0.6911\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6827 - accuracy: 0.7438 - val_loss: 0.6975 - val_accuracy: 0.7378\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6796 - accuracy: 0.7400 - val_loss: 0.6897 - val_accuracy: 0.7511\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6751 - accuracy: 0.7362 - val_loss: 0.6892 - val_accuracy: 0.7533\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6697 - accuracy: 0.7514 - val_loss: 0.6820 - val_accuracy: 0.7400\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6674 - accuracy: 0.7467 - val_loss: 0.6821 - val_accuracy: 0.7244\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6681 - accuracy: 0.7457 - val_loss: 0.6804 - val_accuracy: 0.7578\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6651 - accuracy: 0.7352 - val_loss: 0.6774 - val_accuracy: 0.7533\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.7505 - val_loss: 0.6754 - val_accuracy: 0.7578\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.7514 - val_loss: 0.6782 - val_accuracy: 0.7489\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.7610 - val_loss: 0.6906 - val_accuracy: 0.7200\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7667 - val_loss: 0.6678 - val_accuracy: 0.7578\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.7638 - val_loss: 0.6579 - val_accuracy: 0.7622\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[118  25   5]\n",
            " [ 21 106  16]\n",
            " [ 10  30 119]]\n",
            "\n",
            "P-Score: 0.767, R-Score: 0.762, F-Score: 0.763\n",
            "[0.7622222222222222, 0.7667771339641781, 0.7623279038373378, 0.7626559459130015, 0.8473241453373904, 0.7810528233981003, 0.8381313622511833, 0.8221694436622248]\n",
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_63 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_64 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_65 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1057 - accuracy: 0.3610 - val_loss: 1.0965 - val_accuracy: 0.3956\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0975 - accuracy: 0.4057 - val_loss: 1.0926 - val_accuracy: 0.4200\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0926 - accuracy: 0.4238 - val_loss: 1.0898 - val_accuracy: 0.5378\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0882 - accuracy: 0.4810 - val_loss: 1.0854 - val_accuracy: 0.5533\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0832 - accuracy: 0.4924 - val_loss: 1.0814 - val_accuracy: 0.5644\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0786 - accuracy: 0.5505 - val_loss: 1.0760 - val_accuracy: 0.5400\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0736 - accuracy: 0.5057 - val_loss: 1.0720 - val_accuracy: 0.6422\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0690 - accuracy: 0.5819 - val_loss: 1.0663 - val_accuracy: 0.5933\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0630 - accuracy: 0.5781 - val_loss: 1.0600 - val_accuracy: 0.5711\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0567 - accuracy: 0.6152 - val_loss: 1.0540 - val_accuracy: 0.5622\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0513 - accuracy: 0.5895 - val_loss: 1.0486 - val_accuracy: 0.5822\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0452 - accuracy: 0.6190 - val_loss: 1.0430 - val_accuracy: 0.6356\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0385 - accuracy: 0.6457 - val_loss: 1.0366 - val_accuracy: 0.6311\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0317 - accuracy: 0.6410 - val_loss: 1.0300 - val_accuracy: 0.6511\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.6257 - val_loss: 1.0234 - val_accuracy: 0.6444\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0169 - accuracy: 0.6276 - val_loss: 1.0163 - val_accuracy: 0.6444\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0093 - accuracy: 0.6324 - val_loss: 1.0089 - val_accuracy: 0.6444\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0009 - accuracy: 0.6276 - val_loss: 1.0002 - val_accuracy: 0.6267\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9930 - accuracy: 0.6295 - val_loss: 0.9941 - val_accuracy: 0.6356\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9846 - accuracy: 0.6305 - val_loss: 0.9836 - val_accuracy: 0.6444\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9752 - accuracy: 0.6162 - val_loss: 0.9786 - val_accuracy: 0.6244\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9672 - accuracy: 0.6381 - val_loss: 0.9660 - val_accuracy: 0.6289\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9572 - accuracy: 0.6286 - val_loss: 0.9570 - val_accuracy: 0.6444\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9480 - accuracy: 0.6305 - val_loss: 0.9479 - val_accuracy: 0.6444\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9380 - accuracy: 0.6171 - val_loss: 0.9383 - val_accuracy: 0.6378\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9279 - accuracy: 0.6171 - val_loss: 0.9299 - val_accuracy: 0.6467\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9195 - accuracy: 0.6276 - val_loss: 0.9225 - val_accuracy: 0.6356\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9092 - accuracy: 0.6257 - val_loss: 0.9108 - val_accuracy: 0.6244\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8986 - accuracy: 0.6314 - val_loss: 0.9024 - val_accuracy: 0.6067\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8910 - accuracy: 0.6381 - val_loss: 0.8932 - val_accuracy: 0.6022\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8830 - accuracy: 0.6248 - val_loss: 0.8851 - val_accuracy: 0.6422\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8720 - accuracy: 0.6352 - val_loss: 0.8767 - val_accuracy: 0.6111\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8652 - accuracy: 0.6181 - val_loss: 0.8717 - val_accuracy: 0.6356\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8564 - accuracy: 0.6190 - val_loss: 0.8607 - val_accuracy: 0.6400\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8475 - accuracy: 0.6286 - val_loss: 0.8556 - val_accuracy: 0.6400\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8410 - accuracy: 0.6286 - val_loss: 0.8465 - val_accuracy: 0.6378\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8328 - accuracy: 0.6267 - val_loss: 0.8400 - val_accuracy: 0.6378\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8269 - accuracy: 0.6267 - val_loss: 0.8343 - val_accuracy: 0.6422\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8207 - accuracy: 0.6238 - val_loss: 0.8300 - val_accuracy: 0.6467\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8144 - accuracy: 0.6305 - val_loss: 0.8262 - val_accuracy: 0.6400\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8085 - accuracy: 0.6286 - val_loss: 0.8173 - val_accuracy: 0.6422\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8030 - accuracy: 0.6352 - val_loss: 0.8153 - val_accuracy: 0.6511\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7986 - accuracy: 0.6286 - val_loss: 0.8087 - val_accuracy: 0.6444\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7933 - accuracy: 0.6352 - val_loss: 0.8048 - val_accuracy: 0.6333\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7888 - accuracy: 0.6457 - val_loss: 0.7998 - val_accuracy: 0.6400\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7842 - accuracy: 0.6352 - val_loss: 0.7959 - val_accuracy: 0.6400\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7807 - accuracy: 0.6410 - val_loss: 0.7951 - val_accuracy: 0.6222\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7774 - accuracy: 0.6410 - val_loss: 0.7889 - val_accuracy: 0.6422\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7732 - accuracy: 0.6352 - val_loss: 0.7869 - val_accuracy: 0.6511\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7697 - accuracy: 0.6324 - val_loss: 0.7828 - val_accuracy: 0.6378\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7658 - accuracy: 0.6314 - val_loss: 0.7806 - val_accuracy: 0.6378\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7632 - accuracy: 0.6429 - val_loss: 0.7779 - val_accuracy: 0.6444\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7597 - accuracy: 0.6324 - val_loss: 0.7752 - val_accuracy: 0.6444\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7589 - accuracy: 0.6343 - val_loss: 0.7729 - val_accuracy: 0.6356\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7556 - accuracy: 0.6505 - val_loss: 0.7706 - val_accuracy: 0.6444\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7525 - accuracy: 0.6467 - val_loss: 0.7692 - val_accuracy: 0.6444\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7512 - accuracy: 0.6467 - val_loss: 0.7675 - val_accuracy: 0.6422\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7516 - accuracy: 0.6400 - val_loss: 0.7714 - val_accuracy: 0.6400\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7488 - accuracy: 0.6448 - val_loss: 0.7636 - val_accuracy: 0.6467\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7446 - accuracy: 0.6419 - val_loss: 0.7626 - val_accuracy: 0.6422\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7445 - accuracy: 0.6457 - val_loss: 0.7611 - val_accuracy: 0.6556\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7428 - accuracy: 0.6562 - val_loss: 0.7605 - val_accuracy: 0.6511\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7435 - accuracy: 0.6552 - val_loss: 0.7608 - val_accuracy: 0.6444\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7407 - accuracy: 0.6524 - val_loss: 0.7681 - val_accuracy: 0.6200\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.6552 - val_loss: 0.7575 - val_accuracy: 0.6533\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7378 - accuracy: 0.6533 - val_loss: 0.7569 - val_accuracy: 0.6444\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7349 - accuracy: 0.6543 - val_loss: 0.7620 - val_accuracy: 0.6333\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7357 - accuracy: 0.6590 - val_loss: 0.7530 - val_accuracy: 0.6533\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.6571 - val_loss: 0.7537 - val_accuracy: 0.6378\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7344 - accuracy: 0.6590 - val_loss: 0.7527 - val_accuracy: 0.6400\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7306 - accuracy: 0.6562 - val_loss: 0.7499 - val_accuracy: 0.6422\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7332 - accuracy: 0.6552 - val_loss: 0.7520 - val_accuracy: 0.6444\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.6581 - val_loss: 0.7633 - val_accuracy: 0.6511\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7301 - accuracy: 0.6657 - val_loss: 0.7473 - val_accuracy: 0.6533\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7280 - accuracy: 0.6581 - val_loss: 0.7482 - val_accuracy: 0.6422\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7283 - accuracy: 0.6629 - val_loss: 0.7487 - val_accuracy: 0.6444\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7250 - accuracy: 0.6648 - val_loss: 0.7477 - val_accuracy: 0.6422\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.6648 - val_loss: 0.7477 - val_accuracy: 0.6422\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7263 - accuracy: 0.6610 - val_loss: 0.7433 - val_accuracy: 0.6511\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7249 - accuracy: 0.6600 - val_loss: 0.7423 - val_accuracy: 0.6533\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[108  33   7]\n",
            " [ 17  85  41]\n",
            " [  8  50 101]]\n",
            "\n",
            "P-Score: 0.665, R-Score: 0.653, F-Score: 0.657\n",
            "[0.6533333333333333, 0.6652782683778798, 0.6531184833071625, 0.657050408025909, 0.8234741363880437, 0.6620236441083346, 0.735135836088958, 0.7402112055284454]\n",
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_66 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_67 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_68 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1697 - accuracy: 0.2400 - val_loss: 1.1108 - val_accuracy: 0.0978\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1128 - accuracy: 0.2457 - val_loss: 1.1040 - val_accuracy: 0.4044\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1066 - accuracy: 0.3838 - val_loss: 1.0997 - val_accuracy: 0.4089\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1025 - accuracy: 0.4343 - val_loss: 1.0962 - val_accuracy: 0.4378\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0986 - accuracy: 0.4610 - val_loss: 1.0927 - val_accuracy: 0.4622\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0948 - accuracy: 0.4781 - val_loss: 1.0897 - val_accuracy: 0.4911\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0910 - accuracy: 0.4962 - val_loss: 1.0860 - val_accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0875 - accuracy: 0.4771 - val_loss: 1.0838 - val_accuracy: 0.5578\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0833 - accuracy: 0.4848 - val_loss: 1.0791 - val_accuracy: 0.4089\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0809 - accuracy: 0.4838 - val_loss: 1.0769 - val_accuracy: 0.5689\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0777 - accuracy: 0.5200 - val_loss: 1.0743 - val_accuracy: 0.5644\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0745 - accuracy: 0.5419 - val_loss: 1.0711 - val_accuracy: 0.5689\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0711 - accuracy: 0.5429 - val_loss: 1.0685 - val_accuracy: 0.5600\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0678 - accuracy: 0.4962 - val_loss: 1.0651 - val_accuracy: 0.5733\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.5571 - val_loss: 1.0639 - val_accuracy: 0.4956\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0610 - accuracy: 0.5343 - val_loss: 1.0616 - val_accuracy: 0.4622\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0585 - accuracy: 0.5771 - val_loss: 1.0561 - val_accuracy: 0.6089\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0547 - accuracy: 0.6476 - val_loss: 1.0529 - val_accuracy: 0.6044\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0520 - accuracy: 0.5962 - val_loss: 1.0493 - val_accuracy: 0.6756\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0487 - accuracy: 0.6495 - val_loss: 1.0461 - val_accuracy: 0.7200\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0451 - accuracy: 0.6676 - val_loss: 1.0432 - val_accuracy: 0.7044\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0413 - accuracy: 0.7048 - val_loss: 1.0391 - val_accuracy: 0.7444\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0385 - accuracy: 0.7210 - val_loss: 1.0363 - val_accuracy: 0.7267\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0343 - accuracy: 0.7276 - val_loss: 1.0329 - val_accuracy: 0.7711\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0303 - accuracy: 0.7724 - val_loss: 1.0285 - val_accuracy: 0.7822\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0271 - accuracy: 0.7705 - val_loss: 1.0252 - val_accuracy: 0.7622\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0221 - accuracy: 0.7581 - val_loss: 1.0205 - val_accuracy: 0.7622\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0183 - accuracy: 0.7305 - val_loss: 1.0180 - val_accuracy: 0.7422\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0145 - accuracy: 0.7838 - val_loss: 1.0130 - val_accuracy: 0.7889\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0102 - accuracy: 0.8124 - val_loss: 1.0085 - val_accuracy: 0.7867\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0055 - accuracy: 0.8067 - val_loss: 1.0067 - val_accuracy: 0.6933\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.7886 - val_loss: 1.0029 - val_accuracy: 0.7222\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9965 - accuracy: 0.7657 - val_loss: 0.9975 - val_accuracy: 0.7156\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9905 - accuracy: 0.7324 - val_loss: 0.9895 - val_accuracy: 0.6644\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9869 - accuracy: 0.7505 - val_loss: 0.9862 - val_accuracy: 0.8067\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9812 - accuracy: 0.7686 - val_loss: 0.9825 - val_accuracy: 0.7178\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9757 - accuracy: 0.7695 - val_loss: 0.9758 - val_accuracy: 0.8044\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9701 - accuracy: 0.7990 - val_loss: 0.9689 - val_accuracy: 0.8000\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9645 - accuracy: 0.8067 - val_loss: 0.9637 - val_accuracy: 0.8089\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9589 - accuracy: 0.8067 - val_loss: 0.9570 - val_accuracy: 0.7911\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9525 - accuracy: 0.8067 - val_loss: 0.9518 - val_accuracy: 0.8200\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9454 - accuracy: 0.8162 - val_loss: 0.9452 - val_accuracy: 0.8222\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9383 - accuracy: 0.7781 - val_loss: 0.9407 - val_accuracy: 0.8022\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9317 - accuracy: 0.8133 - val_loss: 0.9314 - val_accuracy: 0.8089\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9245 - accuracy: 0.8019 - val_loss: 0.9237 - val_accuracy: 0.6756\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9174 - accuracy: 0.7848 - val_loss: 0.9162 - val_accuracy: 0.8022\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9083 - accuracy: 0.7933 - val_loss: 0.9073 - val_accuracy: 0.7489\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8999 - accuracy: 0.7467 - val_loss: 0.9067 - val_accuracy: 0.7289\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8919 - accuracy: 0.7790 - val_loss: 0.8932 - val_accuracy: 0.8000\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8840 - accuracy: 0.7952 - val_loss: 0.8859 - val_accuracy: 0.8067\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8764 - accuracy: 0.8019 - val_loss: 0.8797 - val_accuracy: 0.7867\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8686 - accuracy: 0.8133 - val_loss: 0.8706 - val_accuracy: 0.8000\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8604 - accuracy: 0.7800 - val_loss: 0.8649 - val_accuracy: 0.7844\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8532 - accuracy: 0.8086 - val_loss: 0.8575 - val_accuracy: 0.7822\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8456 - accuracy: 0.7962 - val_loss: 0.8488 - val_accuracy: 0.7867\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8378 - accuracy: 0.7971 - val_loss: 0.8424 - val_accuracy: 0.7911\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8307 - accuracy: 0.7962 - val_loss: 0.8349 - val_accuracy: 0.7800\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8224 - accuracy: 0.7981 - val_loss: 0.8281 - val_accuracy: 0.7956\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8148 - accuracy: 0.8038 - val_loss: 0.8222 - val_accuracy: 0.7733\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8083 - accuracy: 0.7924 - val_loss: 0.8130 - val_accuracy: 0.7733\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7994 - accuracy: 0.7876 - val_loss: 0.8063 - val_accuracy: 0.7356\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.7790 - val_loss: 0.7997 - val_accuracy: 0.7378\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7870 - accuracy: 0.7886 - val_loss: 0.7942 - val_accuracy: 0.7933\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7796 - accuracy: 0.8000 - val_loss: 0.7899 - val_accuracy: 0.7756\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.7933 - val_loss: 0.7822 - val_accuracy: 0.7844\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7668 - accuracy: 0.7924 - val_loss: 0.7753 - val_accuracy: 0.7778\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.7771 - val_loss: 0.7776 - val_accuracy: 0.7467\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7546 - accuracy: 0.8029 - val_loss: 0.7663 - val_accuracy: 0.7800\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7481 - accuracy: 0.7952 - val_loss: 0.7592 - val_accuracy: 0.7644\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7443 - accuracy: 0.7781 - val_loss: 0.7546 - val_accuracy: 0.7911\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7394 - accuracy: 0.8000 - val_loss: 0.7524 - val_accuracy: 0.7778\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7345 - accuracy: 0.7971 - val_loss: 0.7460 - val_accuracy: 0.7867\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7296 - accuracy: 0.7876 - val_loss: 0.7406 - val_accuracy: 0.7756\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7235 - accuracy: 0.7924 - val_loss: 0.7412 - val_accuracy: 0.7844\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7193 - accuracy: 0.8038 - val_loss: 0.7319 - val_accuracy: 0.7800\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7132 - accuracy: 0.8124 - val_loss: 0.7322 - val_accuracy: 0.7400\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.8095 - val_loss: 0.7230 - val_accuracy: 0.7867\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7025 - accuracy: 0.8067 - val_loss: 0.7192 - val_accuracy: 0.7844\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6955 - accuracy: 0.7905 - val_loss: 0.7124 - val_accuracy: 0.7756\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6900 - accuracy: 0.7933 - val_loss: 0.7131 - val_accuracy: 0.7800\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[124  19   5]\n",
            " [ 21 118   4]\n",
            " [ 20  30 109]]\n",
            "\n",
            "P-Score: 0.794, R-Score: 0.783, F-Score: 0.780\n",
            "[0.78, 0.7939435971405929, 0.7828490847358772, 0.7802087336865186, 0.851038124216932, 0.8327828523268263, 0.8273033780717111, 0.8370414515384897]\n",
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_69 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1352 - accuracy: 0.3171 - val_loss: 1.1024 - val_accuracy: 0.3267\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0990 - accuracy: 0.3057 - val_loss: 1.0951 - val_accuracy: 0.2822\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0917 - accuracy: 0.3276 - val_loss: 1.0880 - val_accuracy: 0.3733\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0844 - accuracy: 0.3771 - val_loss: 1.0856 - val_accuracy: 0.3489\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0799 - accuracy: 0.3657 - val_loss: 1.0760 - val_accuracy: 0.4644\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0753 - accuracy: 0.3638 - val_loss: 1.0702 - val_accuracy: 0.4444\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0690 - accuracy: 0.4410 - val_loss: 1.0652 - val_accuracy: 0.4156\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.4371 - val_loss: 1.0612 - val_accuracy: 0.4778\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0578 - accuracy: 0.4676 - val_loss: 1.0547 - val_accuracy: 0.5000\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.4648 - val_loss: 1.0487 - val_accuracy: 0.5444\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0474 - accuracy: 0.4895 - val_loss: 1.0430 - val_accuracy: 0.5778\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0429 - accuracy: 0.5362 - val_loss: 1.0371 - val_accuracy: 0.5467\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0348 - accuracy: 0.5714 - val_loss: 1.0308 - val_accuracy: 0.5044\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0281 - accuracy: 0.5781 - val_loss: 1.0304 - val_accuracy: 0.5511\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0214 - accuracy: 0.5429 - val_loss: 1.0192 - val_accuracy: 0.6444\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0159 - accuracy: 0.6067 - val_loss: 1.0107 - val_accuracy: 0.6378\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.6324 - val_loss: 1.0057 - val_accuracy: 0.6422\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.6181 - val_loss: 0.9963 - val_accuracy: 0.6556\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.6410 - val_loss: 0.9895 - val_accuracy: 0.6844\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9876 - accuracy: 0.6610 - val_loss: 0.9811 - val_accuracy: 0.6667\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9792 - accuracy: 0.6648 - val_loss: 0.9727 - val_accuracy: 0.6222\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9713 - accuracy: 0.6486 - val_loss: 0.9670 - val_accuracy: 0.6867\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9616 - accuracy: 0.6657 - val_loss: 0.9562 - val_accuracy: 0.6111\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9528 - accuracy: 0.6743 - val_loss: 0.9474 - val_accuracy: 0.6356\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9447 - accuracy: 0.6581 - val_loss: 0.9461 - val_accuracy: 0.6800\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9370 - accuracy: 0.6676 - val_loss: 0.9320 - val_accuracy: 0.6844\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9240 - accuracy: 0.6876 - val_loss: 0.9213 - val_accuracy: 0.6244\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9172 - accuracy: 0.6771 - val_loss: 0.9136 - val_accuracy: 0.6089\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9076 - accuracy: 0.6562 - val_loss: 0.9092 - val_accuracy: 0.6867\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8988 - accuracy: 0.6724 - val_loss: 0.8962 - val_accuracy: 0.6844\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8888 - accuracy: 0.6638 - val_loss: 0.8873 - val_accuracy: 0.6756\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8797 - accuracy: 0.6771 - val_loss: 0.8775 - val_accuracy: 0.6644\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8718 - accuracy: 0.6714 - val_loss: 0.8757 - val_accuracy: 0.6822\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8640 - accuracy: 0.6819 - val_loss: 0.8605 - val_accuracy: 0.6200\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8519 - accuracy: 0.6552 - val_loss: 0.8588 - val_accuracy: 0.6956\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8461 - accuracy: 0.6838 - val_loss: 0.8449 - val_accuracy: 0.6244\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8392 - accuracy: 0.6629 - val_loss: 0.8395 - val_accuracy: 0.6867\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8311 - accuracy: 0.6857 - val_loss: 0.8303 - val_accuracy: 0.6711\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8228 - accuracy: 0.6686 - val_loss: 0.8337 - val_accuracy: 0.6844\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8168 - accuracy: 0.6714 - val_loss: 0.8186 - val_accuracy: 0.6867\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8100 - accuracy: 0.6943 - val_loss: 0.8113 - val_accuracy: 0.6733\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8024 - accuracy: 0.6867 - val_loss: 0.8160 - val_accuracy: 0.6800\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7982 - accuracy: 0.6924 - val_loss: 0.8014 - val_accuracy: 0.6956\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7917 - accuracy: 0.6943 - val_loss: 0.7940 - val_accuracy: 0.6844\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7812 - accuracy: 0.6876 - val_loss: 0.7952 - val_accuracy: 0.6933\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7800 - accuracy: 0.6933 - val_loss: 0.7841 - val_accuracy: 0.6778\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7753 - accuracy: 0.7019 - val_loss: 0.7799 - val_accuracy: 0.6889\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7713 - accuracy: 0.6819 - val_loss: 0.7792 - val_accuracy: 0.7089\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7669 - accuracy: 0.6924 - val_loss: 0.7693 - val_accuracy: 0.7000\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7590 - accuracy: 0.7095 - val_loss: 0.7656 - val_accuracy: 0.7156\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7503 - accuracy: 0.7114 - val_loss: 0.7587 - val_accuracy: 0.6911\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7477 - accuracy: 0.7105 - val_loss: 0.7541 - val_accuracy: 0.7044\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7438 - accuracy: 0.6952 - val_loss: 0.7517 - val_accuracy: 0.7133\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7427 - accuracy: 0.7095 - val_loss: 0.7483 - val_accuracy: 0.6600\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7342 - accuracy: 0.7219 - val_loss: 0.7429 - val_accuracy: 0.6844\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7329 - accuracy: 0.7171 - val_loss: 0.7398 - val_accuracy: 0.7156\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7245 - accuracy: 0.7171 - val_loss: 0.7392 - val_accuracy: 0.7111\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7200 - accuracy: 0.7267 - val_loss: 0.7366 - val_accuracy: 0.7111\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7212 - accuracy: 0.7029 - val_loss: 0.7283 - val_accuracy: 0.7133\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7153 - accuracy: 0.7238 - val_loss: 0.7268 - val_accuracy: 0.7156\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.7190 - val_loss: 0.7233 - val_accuracy: 0.7067\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.7133 - val_loss: 0.7197 - val_accuracy: 0.7111\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7082 - accuracy: 0.7238 - val_loss: 0.7360 - val_accuracy: 0.6889\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7046 - accuracy: 0.7181 - val_loss: 0.7221 - val_accuracy: 0.7178\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7006 - accuracy: 0.7295 - val_loss: 0.7151 - val_accuracy: 0.7089\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6982 - accuracy: 0.7371 - val_loss: 0.7111 - val_accuracy: 0.7200\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7001 - accuracy: 0.7286 - val_loss: 0.7245 - val_accuracy: 0.6889\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6964 - accuracy: 0.7333 - val_loss: 0.7133 - val_accuracy: 0.7178\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.7248 - val_loss: 0.7165 - val_accuracy: 0.7089\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6920 - accuracy: 0.7362 - val_loss: 0.7077 - val_accuracy: 0.7178\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6892 - accuracy: 0.7333 - val_loss: 0.7016 - val_accuracy: 0.7222\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.7505 - val_loss: 0.6979 - val_accuracy: 0.7311\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.7314 - val_loss: 0.7045 - val_accuracy: 0.7000\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.7457 - val_loss: 0.7193 - val_accuracy: 0.6800\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6778 - accuracy: 0.7267 - val_loss: 0.6947 - val_accuracy: 0.7289\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6776 - accuracy: 0.7324 - val_loss: 0.7186 - val_accuracy: 0.6844\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6702 - accuracy: 0.7495 - val_loss: 0.7308 - val_accuracy: 0.6733\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6732 - accuracy: 0.7419 - val_loss: 0.6930 - val_accuracy: 0.7244\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.7505 - val_loss: 0.6955 - val_accuracy: 0.7044\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.7438 - val_loss: 0.6782 - val_accuracy: 0.7356\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[110  30   8]\n",
            " [ 19  95  29]\n",
            " [  7  26 126]]\n",
            "\n",
            "P-Score: 0.737, R-Score: 0.733, F-Score: 0.735\n",
            "[0.7355555555555555, 0.7369895790762574, 0.7333439125891955, 0.7345050287924927, 0.8285752640057276, 0.7409626204414479, 0.8326525319328276, 0.8007301387933343]\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_72 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_74 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1615 - accuracy: 0.1229 - val_loss: 1.1324 - val_accuracy: 0.1667\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1328 - accuracy: 0.2152 - val_loss: 1.1211 - val_accuracy: 0.2889\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1215 - accuracy: 0.2924 - val_loss: 1.1151 - val_accuracy: 0.2756\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1152 - accuracy: 0.2514 - val_loss: 1.1104 - val_accuracy: 0.2533\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1100 - accuracy: 0.2038 - val_loss: 1.1054 - val_accuracy: 0.2333\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1053 - accuracy: 0.1971 - val_loss: 1.1015 - val_accuracy: 0.1978\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1009 - accuracy: 0.1905 - val_loss: 1.0975 - val_accuracy: 0.1844\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0965 - accuracy: 0.1638 - val_loss: 1.0931 - val_accuracy: 0.2778\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0925 - accuracy: 0.2276 - val_loss: 1.0890 - val_accuracy: 0.3378\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0877 - accuracy: 0.3619 - val_loss: 1.0829 - val_accuracy: 0.3933\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0803 - accuracy: 0.3829 - val_loss: 1.0758 - val_accuracy: 0.4644\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0751 - accuracy: 0.4429 - val_loss: 1.0704 - val_accuracy: 0.4111\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0704 - accuracy: 0.3905 - val_loss: 1.0676 - val_accuracy: 0.4933\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0668 - accuracy: 0.4429 - val_loss: 1.0632 - val_accuracy: 0.4711\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0626 - accuracy: 0.4467 - val_loss: 1.0588 - val_accuracy: 0.4467\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0585 - accuracy: 0.4448 - val_loss: 1.0545 - val_accuracy: 0.4444\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0538 - accuracy: 0.4162 - val_loss: 1.0519 - val_accuracy: 0.5111\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0501 - accuracy: 0.4743 - val_loss: 1.0460 - val_accuracy: 0.4622\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0458 - accuracy: 0.4562 - val_loss: 1.0411 - val_accuracy: 0.4444\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0410 - accuracy: 0.4429 - val_loss: 1.0371 - val_accuracy: 0.4822\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0361 - accuracy: 0.4752 - val_loss: 1.0309 - val_accuracy: 0.4244\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0317 - accuracy: 0.4267 - val_loss: 1.0267 - val_accuracy: 0.4711\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0261 - accuracy: 0.4676 - val_loss: 1.0211 - val_accuracy: 0.4778\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0208 - accuracy: 0.4781 - val_loss: 1.0184 - val_accuracy: 0.5778\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0149 - accuracy: 0.5533 - val_loss: 1.0097 - val_accuracy: 0.5489\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0095 - accuracy: 0.5933 - val_loss: 1.0044 - val_accuracy: 0.5778\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0033 - accuracy: 0.5867 - val_loss: 0.9998 - val_accuracy: 0.6511\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9967 - accuracy: 0.6333 - val_loss: 0.9910 - val_accuracy: 0.5756\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9903 - accuracy: 0.6400 - val_loss: 0.9846 - val_accuracy: 0.5489\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9843 - accuracy: 0.6248 - val_loss: 0.9778 - val_accuracy: 0.6133\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9767 - accuracy: 0.6610 - val_loss: 0.9709 - val_accuracy: 0.6156\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9692 - accuracy: 0.6600 - val_loss: 0.9666 - val_accuracy: 0.7111\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9618 - accuracy: 0.6914 - val_loss: 0.9563 - val_accuracy: 0.6444\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9544 - accuracy: 0.6695 - val_loss: 0.9496 - val_accuracy: 0.6844\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9478 - accuracy: 0.6867 - val_loss: 0.9413 - val_accuracy: 0.6778\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9395 - accuracy: 0.6629 - val_loss: 0.9356 - val_accuracy: 0.7044\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9311 - accuracy: 0.6876 - val_loss: 0.9261 - val_accuracy: 0.6778\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9227 - accuracy: 0.6867 - val_loss: 0.9182 - val_accuracy: 0.6800\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9141 - accuracy: 0.6990 - val_loss: 0.9089 - val_accuracy: 0.6800\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9061 - accuracy: 0.6829 - val_loss: 0.8997 - val_accuracy: 0.6600\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8960 - accuracy: 0.6810 - val_loss: 0.8958 - val_accuracy: 0.7111\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8876 - accuracy: 0.7000 - val_loss: 0.8835 - val_accuracy: 0.6867\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8791 - accuracy: 0.7076 - val_loss: 0.8739 - val_accuracy: 0.6444\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8694 - accuracy: 0.6981 - val_loss: 0.8634 - val_accuracy: 0.6844\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8559 - accuracy: 0.6800 - val_loss: 0.8501 - val_accuracy: 0.6978\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8423 - accuracy: 0.6924 - val_loss: 0.8356 - val_accuracy: 0.6756\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8301 - accuracy: 0.6838 - val_loss: 0.8344 - val_accuracy: 0.7067\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8206 - accuracy: 0.6857 - val_loss: 0.8221 - val_accuracy: 0.7089\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8082 - accuracy: 0.7057 - val_loss: 0.8079 - val_accuracy: 0.7178\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7975 - accuracy: 0.7152 - val_loss: 0.7981 - val_accuracy: 0.7022\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7879 - accuracy: 0.7076 - val_loss: 0.8013 - val_accuracy: 0.7044\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7814 - accuracy: 0.7286 - val_loss: 0.7842 - val_accuracy: 0.7156\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7759 - accuracy: 0.7114 - val_loss: 0.7851 - val_accuracy: 0.7133\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7693 - accuracy: 0.7133 - val_loss: 0.7859 - val_accuracy: 0.7067\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7618 - accuracy: 0.7181 - val_loss: 0.7683 - val_accuracy: 0.7156\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7558 - accuracy: 0.7200 - val_loss: 0.7625 - val_accuracy: 0.6978\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7501 - accuracy: 0.7219 - val_loss: 0.7613 - val_accuracy: 0.7178\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7442 - accuracy: 0.7190 - val_loss: 0.7580 - val_accuracy: 0.7156\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7409 - accuracy: 0.7181 - val_loss: 0.7457 - val_accuracy: 0.7178\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7362 - accuracy: 0.7343 - val_loss: 0.7415 - val_accuracy: 0.7178\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7303 - accuracy: 0.7343 - val_loss: 0.7447 - val_accuracy: 0.7156\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7252 - accuracy: 0.7390 - val_loss: 0.7355 - val_accuracy: 0.7267\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7206 - accuracy: 0.7410 - val_loss: 0.7418 - val_accuracy: 0.7133\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7173 - accuracy: 0.7248 - val_loss: 0.7268 - val_accuracy: 0.7200\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7133 - accuracy: 0.7314 - val_loss: 0.7276 - val_accuracy: 0.7111\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7092 - accuracy: 0.7276 - val_loss: 0.7208 - val_accuracy: 0.7333\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7035 - accuracy: 0.7324 - val_loss: 0.7176 - val_accuracy: 0.7289\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7076 - accuracy: 0.7238 - val_loss: 0.7142 - val_accuracy: 0.7267\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7003 - accuracy: 0.7229 - val_loss: 0.7119 - val_accuracy: 0.7244\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6953 - accuracy: 0.7476 - val_loss: 0.7131 - val_accuracy: 0.7244\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6939 - accuracy: 0.7371 - val_loss: 0.7126 - val_accuracy: 0.7244\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6890 - accuracy: 0.7457 - val_loss: 0.7165 - val_accuracy: 0.7156\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6884 - accuracy: 0.7467 - val_loss: 0.7032 - val_accuracy: 0.7178\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6873 - accuracy: 0.7362 - val_loss: 0.7260 - val_accuracy: 0.6867\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.7476 - val_loss: 0.7072 - val_accuracy: 0.6978\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6821 - accuracy: 0.7352 - val_loss: 0.6940 - val_accuracy: 0.7156\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6754 - accuracy: 0.7486 - val_loss: 0.6934 - val_accuracy: 0.7400\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.7448 - val_loss: 0.6886 - val_accuracy: 0.7178\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6728 - accuracy: 0.7400 - val_loss: 0.6930 - val_accuracy: 0.7289\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6705 - accuracy: 0.7457 - val_loss: 0.6836 - val_accuracy: 0.7333\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[109  32   7]\n",
            " [ 19  99  25]\n",
            " [  7  30 122]]\n",
            "\n",
            "P-Score: 0.738, R-Score: 0.732, F-Score: 0.734\n",
            "[0.7333333333333333, 0.7381740106377789, 0.7320299254261519, 0.7337288421100165, 0.8251968856273492, 0.7451766474567778, 0.8286649808727226, 0.7996795046522832]\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_75 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_77 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1102 - accuracy: 0.3352 - val_loss: 1.0979 - val_accuracy: 0.3289\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.3362 - val_loss: 1.0871 - val_accuracy: 0.3800\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0851 - accuracy: 0.4210 - val_loss: 1.0808 - val_accuracy: 0.5933\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0812 - accuracy: 0.5590 - val_loss: 1.0781 - val_accuracy: 0.5333\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0763 - accuracy: 0.5486 - val_loss: 1.0751 - val_accuracy: 0.5267\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0717 - accuracy: 0.5371 - val_loss: 1.0674 - val_accuracy: 0.5178\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0673 - accuracy: 0.5143 - val_loss: 1.0673 - val_accuracy: 0.5800\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0638 - accuracy: 0.5705 - val_loss: 1.0608 - val_accuracy: 0.5533\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0599 - accuracy: 0.5600 - val_loss: 1.0566 - val_accuracy: 0.5556\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0562 - accuracy: 0.5829 - val_loss: 1.0528 - val_accuracy: 0.5422\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0512 - accuracy: 0.5676 - val_loss: 1.0510 - val_accuracy: 0.6133\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0475 - accuracy: 0.5781 - val_loss: 1.0485 - val_accuracy: 0.6467\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0434 - accuracy: 0.6076 - val_loss: 1.0413 - val_accuracy: 0.6156\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0392 - accuracy: 0.6057 - val_loss: 1.0362 - val_accuracy: 0.5467\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0346 - accuracy: 0.6086 - val_loss: 1.0319 - val_accuracy: 0.5622\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0300 - accuracy: 0.6267 - val_loss: 1.0271 - val_accuracy: 0.5378\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0254 - accuracy: 0.6048 - val_loss: 1.0225 - val_accuracy: 0.6089\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0203 - accuracy: 0.6305 - val_loss: 1.0179 - val_accuracy: 0.6267\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0147 - accuracy: 0.6200 - val_loss: 1.0187 - val_accuracy: 0.6689\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0108 - accuracy: 0.6429 - val_loss: 1.0095 - val_accuracy: 0.6756\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0050 - accuracy: 0.6476 - val_loss: 1.0018 - val_accuracy: 0.6111\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9991 - accuracy: 0.6305 - val_loss: 0.9971 - val_accuracy: 0.6578\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9936 - accuracy: 0.6457 - val_loss: 0.9903 - val_accuracy: 0.5889\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9876 - accuracy: 0.6390 - val_loss: 0.9852 - val_accuracy: 0.6511\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9815 - accuracy: 0.6333 - val_loss: 0.9840 - val_accuracy: 0.6689\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9755 - accuracy: 0.6305 - val_loss: 0.9762 - val_accuracy: 0.6733\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9694 - accuracy: 0.6486 - val_loss: 0.9665 - val_accuracy: 0.6156\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9629 - accuracy: 0.6324 - val_loss: 0.9623 - val_accuracy: 0.6733\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9558 - accuracy: 0.6305 - val_loss: 0.9598 - val_accuracy: 0.6622\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9499 - accuracy: 0.6562 - val_loss: 0.9471 - val_accuracy: 0.6533\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9416 - accuracy: 0.6495 - val_loss: 0.9400 - val_accuracy: 0.6422\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9350 - accuracy: 0.6419 - val_loss: 0.9343 - val_accuracy: 0.6667\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9281 - accuracy: 0.6429 - val_loss: 0.9262 - val_accuracy: 0.6178\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9217 - accuracy: 0.6676 - val_loss: 0.9200 - val_accuracy: 0.6667\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9128 - accuracy: 0.6419 - val_loss: 0.9124 - val_accuracy: 0.6000\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9061 - accuracy: 0.6448 - val_loss: 0.9087 - val_accuracy: 0.6822\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8993 - accuracy: 0.6543 - val_loss: 0.8984 - val_accuracy: 0.6689\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8913 - accuracy: 0.6600 - val_loss: 0.8943 - val_accuracy: 0.6800\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8841 - accuracy: 0.6571 - val_loss: 0.8844 - val_accuracy: 0.6667\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8765 - accuracy: 0.6514 - val_loss: 0.8821 - val_accuracy: 0.6689\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8690 - accuracy: 0.6610 - val_loss: 0.8705 - val_accuracy: 0.6622\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8611 - accuracy: 0.6648 - val_loss: 0.8638 - val_accuracy: 0.6756\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8534 - accuracy: 0.6495 - val_loss: 0.8585 - val_accuracy: 0.6156\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8441 - accuracy: 0.6695 - val_loss: 0.8481 - val_accuracy: 0.6800\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8373 - accuracy: 0.6533 - val_loss: 0.8400 - val_accuracy: 0.6844\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8263 - accuracy: 0.6638 - val_loss: 0.8358 - val_accuracy: 0.6800\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8196 - accuracy: 0.6705 - val_loss: 0.8245 - val_accuracy: 0.6667\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8138 - accuracy: 0.6600 - val_loss: 0.8185 - val_accuracy: 0.6556\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8082 - accuracy: 0.6552 - val_loss: 0.8141 - val_accuracy: 0.6689\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8024 - accuracy: 0.6610 - val_loss: 0.8076 - val_accuracy: 0.6600\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7962 - accuracy: 0.6505 - val_loss: 0.8069 - val_accuracy: 0.6800\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7924 - accuracy: 0.6733 - val_loss: 0.8049 - val_accuracy: 0.6644\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7852 - accuracy: 0.6695 - val_loss: 0.7941 - val_accuracy: 0.6622\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7810 - accuracy: 0.6714 - val_loss: 0.7932 - val_accuracy: 0.6844\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7769 - accuracy: 0.6657 - val_loss: 0.7892 - val_accuracy: 0.6822\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7726 - accuracy: 0.6705 - val_loss: 0.7947 - val_accuracy: 0.6644\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7684 - accuracy: 0.6743 - val_loss: 0.7831 - val_accuracy: 0.6778\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7659 - accuracy: 0.6648 - val_loss: 0.7762 - val_accuracy: 0.6800\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7617 - accuracy: 0.6686 - val_loss: 0.7736 - val_accuracy: 0.6578\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7593 - accuracy: 0.6733 - val_loss: 0.7789 - val_accuracy: 0.6667\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7554 - accuracy: 0.6676 - val_loss: 0.7697 - val_accuracy: 0.6844\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7522 - accuracy: 0.6933 - val_loss: 0.7725 - val_accuracy: 0.6222\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7485 - accuracy: 0.6810 - val_loss: 0.7647 - val_accuracy: 0.6867\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7467 - accuracy: 0.6819 - val_loss: 0.7591 - val_accuracy: 0.6778\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7431 - accuracy: 0.6762 - val_loss: 0.7588 - val_accuracy: 0.6844\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.6857 - val_loss: 0.7548 - val_accuracy: 0.6756\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7402 - accuracy: 0.6829 - val_loss: 0.7521 - val_accuracy: 0.6800\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7364 - accuracy: 0.6781 - val_loss: 0.7502 - val_accuracy: 0.6778\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7318 - accuracy: 0.6829 - val_loss: 0.7486 - val_accuracy: 0.6911\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7317 - accuracy: 0.6790 - val_loss: 0.7477 - val_accuracy: 0.6889\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7287 - accuracy: 0.6829 - val_loss: 0.7444 - val_accuracy: 0.6867\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7243 - accuracy: 0.6867 - val_loss: 0.7650 - val_accuracy: 0.6667\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7197 - accuracy: 0.6962 - val_loss: 0.7365 - val_accuracy: 0.7000\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7179 - accuracy: 0.7000 - val_loss: 0.7331 - val_accuracy: 0.6933\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7196 - accuracy: 0.6943 - val_loss: 0.7330 - val_accuracy: 0.6733\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7135 - accuracy: 0.7057 - val_loss: 0.7290 - val_accuracy: 0.7000\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7148 - accuracy: 0.6990 - val_loss: 0.7282 - val_accuracy: 0.6889\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7114 - accuracy: 0.6971 - val_loss: 0.7270 - val_accuracy: 0.7022\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7096 - accuracy: 0.7048 - val_loss: 0.7297 - val_accuracy: 0.6956\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7099 - accuracy: 0.7038 - val_loss: 0.7320 - val_accuracy: 0.6644\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[ 99  39  10]\n",
            " [ 12  74  57]\n",
            " [  4  29 126]]\n",
            "\n",
            "P-Score: 0.678, R-Score: 0.660, F-Score: 0.663\n",
            "[0.6644444444444444, 0.6782820222378048, 0.6596180888633719, 0.6626863491832472, 0.8079693932342938, 0.6479920730735064, 0.7811061401802504, 0.7456892021626835]\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_78 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_80 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0878 - accuracy: 0.4419 - val_loss: 1.0760 - val_accuracy: 0.4867\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0755 - accuracy: 0.4867 - val_loss: 1.0706 - val_accuracy: 0.6111\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0695 - accuracy: 0.5086 - val_loss: 1.0668 - val_accuracy: 0.4689\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0647 - accuracy: 0.5238 - val_loss: 1.0622 - val_accuracy: 0.5400\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0595 - accuracy: 0.5648 - val_loss: 1.0587 - val_accuracy: 0.4644\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0550 - accuracy: 0.6000 - val_loss: 1.0556 - val_accuracy: 0.4311\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0510 - accuracy: 0.5676 - val_loss: 1.0506 - val_accuracy: 0.5000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0462 - accuracy: 0.5743 - val_loss: 1.0449 - val_accuracy: 0.6711\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0410 - accuracy: 0.6562 - val_loss: 1.0400 - val_accuracy: 0.7644\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0356 - accuracy: 0.6476 - val_loss: 1.0331 - val_accuracy: 0.7867\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0292 - accuracy: 0.7743 - val_loss: 1.0264 - val_accuracy: 0.8378\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0218 - accuracy: 0.7505 - val_loss: 1.0221 - val_accuracy: 0.6689\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.7629 - val_loss: 1.0147 - val_accuracy: 0.8444\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.8048 - val_loss: 1.0104 - val_accuracy: 0.6356\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0027 - accuracy: 0.7410 - val_loss: 1.0064 - val_accuracy: 0.5733\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9954 - accuracy: 0.7114 - val_loss: 0.9954 - val_accuracy: 0.7778\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9883 - accuracy: 0.7133 - val_loss: 0.9886 - val_accuracy: 0.7711\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9806 - accuracy: 0.7724 - val_loss: 0.9816 - val_accuracy: 0.8289\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9717 - accuracy: 0.7619 - val_loss: 0.9748 - val_accuracy: 0.6356\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9624 - accuracy: 0.7571 - val_loss: 0.9736 - val_accuracy: 0.5422\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9553 - accuracy: 0.7181 - val_loss: 0.9584 - val_accuracy: 0.7156\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9462 - accuracy: 0.7267 - val_loss: 0.9496 - val_accuracy: 0.7200\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9383 - accuracy: 0.7905 - val_loss: 0.9417 - val_accuracy: 0.7244\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9288 - accuracy: 0.7552 - val_loss: 0.9323 - val_accuracy: 0.8400\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9202 - accuracy: 0.7733 - val_loss: 0.9241 - val_accuracy: 0.8267\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9088 - accuracy: 0.7562 - val_loss: 0.9157 - val_accuracy: 0.7933\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9010 - accuracy: 0.7905 - val_loss: 0.9078 - val_accuracy: 0.8044\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8923 - accuracy: 0.7752 - val_loss: 0.8996 - val_accuracy: 0.6644\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8828 - accuracy: 0.7800 - val_loss: 0.8890 - val_accuracy: 0.7844\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8744 - accuracy: 0.8095 - val_loss: 0.8791 - val_accuracy: 0.8378\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8612 - accuracy: 0.7905 - val_loss: 0.8749 - val_accuracy: 0.7133\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8540 - accuracy: 0.8000 - val_loss: 0.8606 - val_accuracy: 0.8289\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8451 - accuracy: 0.7790 - val_loss: 0.8534 - val_accuracy: 0.7244\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8355 - accuracy: 0.8076 - val_loss: 0.8446 - val_accuracy: 0.8289\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8268 - accuracy: 0.8105 - val_loss: 0.8352 - val_accuracy: 0.8289\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8191 - accuracy: 0.7933 - val_loss: 0.8286 - val_accuracy: 0.8044\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8099 - accuracy: 0.8124 - val_loss: 0.8207 - val_accuracy: 0.8222\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8015 - accuracy: 0.8019 - val_loss: 0.8151 - val_accuracy: 0.7489\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7933 - accuracy: 0.8181 - val_loss: 0.8059 - val_accuracy: 0.8356\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7867 - accuracy: 0.8324 - val_loss: 0.7978 - val_accuracy: 0.8422\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7813 - accuracy: 0.8086 - val_loss: 0.7911 - val_accuracy: 0.8556\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7723 - accuracy: 0.8181 - val_loss: 0.7848 - val_accuracy: 0.8444\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7654 - accuracy: 0.8486 - val_loss: 0.7799 - val_accuracy: 0.8356\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7586 - accuracy: 0.8343 - val_loss: 0.7724 - val_accuracy: 0.8311\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7523 - accuracy: 0.8295 - val_loss: 0.7652 - val_accuracy: 0.8489\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7448 - accuracy: 0.8467 - val_loss: 0.7626 - val_accuracy: 0.8511\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7401 - accuracy: 0.8562 - val_loss: 0.7540 - val_accuracy: 0.8644\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7327 - accuracy: 0.8486 - val_loss: 0.7528 - val_accuracy: 0.7822\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7261 - accuracy: 0.8514 - val_loss: 0.7476 - val_accuracy: 0.7933\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7225 - accuracy: 0.8581 - val_loss: 0.7381 - val_accuracy: 0.8400\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7145 - accuracy: 0.8390 - val_loss: 0.7320 - val_accuracy: 0.8556\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7122 - accuracy: 0.8438 - val_loss: 0.7285 - val_accuracy: 0.8489\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7050 - accuracy: 0.8571 - val_loss: 0.7271 - val_accuracy: 0.8289\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6984 - accuracy: 0.8705 - val_loss: 0.7253 - val_accuracy: 0.8200\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6969 - accuracy: 0.8514 - val_loss: 0.7133 - val_accuracy: 0.8533\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6901 - accuracy: 0.8467 - val_loss: 0.7095 - val_accuracy: 0.8578\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.8581 - val_loss: 0.7022 - val_accuracy: 0.8422\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.8552 - val_loss: 0.7035 - val_accuracy: 0.7667\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6768 - accuracy: 0.8571 - val_loss: 0.6931 - val_accuracy: 0.8556\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6701 - accuracy: 0.8543 - val_loss: 0.6895 - val_accuracy: 0.8533\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6635 - accuracy: 0.8705 - val_loss: 0.6827 - val_accuracy: 0.8356\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6626 - accuracy: 0.8600 - val_loss: 0.6858 - val_accuracy: 0.8356\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6547 - accuracy: 0.8619 - val_loss: 0.6850 - val_accuracy: 0.8133\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.8695 - val_loss: 0.6699 - val_accuracy: 0.8644\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6458 - accuracy: 0.8686 - val_loss: 0.6728 - val_accuracy: 0.8222\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.8524 - val_loss: 0.6697 - val_accuracy: 0.7378\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.8676 - val_loss: 0.6562 - val_accuracy: 0.8489\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6315 - accuracy: 0.8571 - val_loss: 0.6529 - val_accuracy: 0.8178\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.8657 - val_loss: 0.6500 - val_accuracy: 0.8333\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.8629 - val_loss: 0.6472 - val_accuracy: 0.8511\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.8619 - val_loss: 0.6403 - val_accuracy: 0.8533\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6104 - accuracy: 0.8552 - val_loss: 0.6360 - val_accuracy: 0.8244\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.6117 - accuracy: 0.8600 - val_loss: 0.6622 - val_accuracy: 0.7222\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6040 - accuracy: 0.8533 - val_loss: 0.6218 - val_accuracy: 0.8556\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.8581 - val_loss: 0.6218 - val_accuracy: 0.8578\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5949 - accuracy: 0.8667 - val_loss: 0.6450 - val_accuracy: 0.7800\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5867 - accuracy: 0.8581 - val_loss: 0.6144 - val_accuracy: 0.8533\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5865 - accuracy: 0.8610 - val_loss: 0.6097 - val_accuracy: 0.8356\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8629 - val_loss: 0.6127 - val_accuracy: 0.8622\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.5755 - accuracy: 0.8695 - val_loss: 0.6220 - val_accuracy: 0.8067\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[131  13   4]\n",
            " [ 21 122   0]\n",
            " [ 27  22 110]]\n",
            "\n",
            "P-Score: 0.825, R-Score: 0.810, F-Score: 0.807\n",
            "[0.8066666666666666, 0.8246086399383388, 0.8100352958843525, 0.8068057935947843, 0.8630973688920708, 0.8695701692444362, 0.8390390974518576, 0.8572355451961217]\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_81 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_83 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.3406 - accuracy: 0.3343 - val_loss: 1.1615 - val_accuracy: 0.3267\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1416 - accuracy: 0.3095 - val_loss: 1.1172 - val_accuracy: 0.2533\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1128 - accuracy: 0.1762 - val_loss: 1.1071 - val_accuracy: 0.3267\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1074 - accuracy: 0.3286 - val_loss: 1.1049 - val_accuracy: 0.4533\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1059 - accuracy: 0.4133 - val_loss: 1.1040 - val_accuracy: 0.4267\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1044 - accuracy: 0.4229 - val_loss: 1.1031 - val_accuracy: 0.4133\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1033 - accuracy: 0.4181 - val_loss: 1.1022 - val_accuracy: 0.4000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1020 - accuracy: 0.4048 - val_loss: 1.1006 - val_accuracy: 0.4333\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1008 - accuracy: 0.4162 - val_loss: 1.0994 - val_accuracy: 0.4422\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1000 - accuracy: 0.4105 - val_loss: 1.0986 - val_accuracy: 0.4289\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0985 - accuracy: 0.4143 - val_loss: 1.0972 - val_accuracy: 0.4667\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0974 - accuracy: 0.4143 - val_loss: 1.0963 - val_accuracy: 0.4578\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0964 - accuracy: 0.4362 - val_loss: 1.0956 - val_accuracy: 0.4356\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0953 - accuracy: 0.3924 - val_loss: 1.0942 - val_accuracy: 0.4867\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0943 - accuracy: 0.4610 - val_loss: 1.0938 - val_accuracy: 0.4111\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0934 - accuracy: 0.4257 - val_loss: 1.0929 - val_accuracy: 0.4044\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0918 - accuracy: 0.4619 - val_loss: 1.0929 - val_accuracy: 0.3533\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0911 - accuracy: 0.4010 - val_loss: 1.0912 - val_accuracy: 0.3733\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0901 - accuracy: 0.4295 - val_loss: 1.0900 - val_accuracy: 0.3867\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0889 - accuracy: 0.4219 - val_loss: 1.0888 - val_accuracy: 0.4133\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0878 - accuracy: 0.4076 - val_loss: 1.0875 - val_accuracy: 0.4556\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0869 - accuracy: 0.4752 - val_loss: 1.0870 - val_accuracy: 0.3822\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0855 - accuracy: 0.4257 - val_loss: 1.0857 - val_accuracy: 0.4178\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0848 - accuracy: 0.4219 - val_loss: 1.0845 - val_accuracy: 0.4556\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0834 - accuracy: 0.4371 - val_loss: 1.0833 - val_accuracy: 0.4844\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0824 - accuracy: 0.4314 - val_loss: 1.0821 - val_accuracy: 0.5156\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0814 - accuracy: 0.5038 - val_loss: 1.0815 - val_accuracy: 0.4289\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0801 - accuracy: 0.4895 - val_loss: 1.0808 - val_accuracy: 0.3733\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0789 - accuracy: 0.4143 - val_loss: 1.0788 - val_accuracy: 0.5044\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0774 - accuracy: 0.5933 - val_loss: 1.0785 - val_accuracy: 0.3733\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0767 - accuracy: 0.4981 - val_loss: 1.0775 - val_accuracy: 0.3689\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0749 - accuracy: 0.3981 - val_loss: 1.0751 - val_accuracy: 0.5822\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0738 - accuracy: 0.5152 - val_loss: 1.0739 - val_accuracy: 0.5422\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0723 - accuracy: 0.5219 - val_loss: 1.0727 - val_accuracy: 0.5289\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0707 - accuracy: 0.5857 - val_loss: 1.0722 - val_accuracy: 0.4000\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0698 - accuracy: 0.4667 - val_loss: 1.0704 - val_accuracy: 0.4444\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0679 - accuracy: 0.4810 - val_loss: 1.0683 - val_accuracy: 0.5756\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0662 - accuracy: 0.6333 - val_loss: 1.0674 - val_accuracy: 0.4489\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0647 - accuracy: 0.6219 - val_loss: 1.0666 - val_accuracy: 0.4044\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0628 - accuracy: 0.4648 - val_loss: 1.0632 - val_accuracy: 0.6644\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0610 - accuracy: 0.7171 - val_loss: 1.0625 - val_accuracy: 0.4356\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0596 - accuracy: 0.5724 - val_loss: 1.0605 - val_accuracy: 0.4733\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0575 - accuracy: 0.5562 - val_loss: 1.0585 - val_accuracy: 0.5311\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0549 - accuracy: 0.6562 - val_loss: 1.0575 - val_accuracy: 0.4489\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.5086 - val_loss: 1.0537 - val_accuracy: 0.7667\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0510 - accuracy: 0.6905 - val_loss: 1.0518 - val_accuracy: 0.7089\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0482 - accuracy: 0.5857 - val_loss: 1.0488 - val_accuracy: 0.8356\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0458 - accuracy: 0.7543 - val_loss: 1.0469 - val_accuracy: 0.7556\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0434 - accuracy: 0.7000 - val_loss: 1.0446 - val_accuracy: 0.7178\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0405 - accuracy: 0.7790 - val_loss: 1.0427 - val_accuracy: 0.5711\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0379 - accuracy: 0.6924 - val_loss: 1.0398 - val_accuracy: 0.5778\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0343 - accuracy: 0.6362 - val_loss: 1.0358 - val_accuracy: 0.7178\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0314 - accuracy: 0.7467 - val_loss: 1.0330 - val_accuracy: 0.6289\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0276 - accuracy: 0.7371 - val_loss: 1.0295 - val_accuracy: 0.6356\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0237 - accuracy: 0.7067 - val_loss: 1.0255 - val_accuracy: 0.7489\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0198 - accuracy: 0.7219 - val_loss: 1.0212 - val_accuracy: 0.7911\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0151 - accuracy: 0.8305 - val_loss: 1.0174 - val_accuracy: 0.6867\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0105 - accuracy: 0.7914 - val_loss: 1.0128 - val_accuracy: 0.6911\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0053 - accuracy: 0.7267 - val_loss: 1.0070 - val_accuracy: 0.7822\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9995 - accuracy: 0.7943 - val_loss: 1.0013 - val_accuracy: 0.7689\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9931 - accuracy: 0.8105 - val_loss: 0.9950 - val_accuracy: 0.7867\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9853 - accuracy: 0.8219 - val_loss: 0.9838 - val_accuracy: 0.8378\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9728 - accuracy: 0.7657 - val_loss: 0.9675 - val_accuracy: 0.7044\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9609 - accuracy: 0.7562 - val_loss: 0.9590 - val_accuracy: 0.8044\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9510 - accuracy: 0.7771 - val_loss: 0.9496 - val_accuracy: 0.7956\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9404 - accuracy: 0.7886 - val_loss: 0.9421 - val_accuracy: 0.8178\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9298 - accuracy: 0.7686 - val_loss: 0.9346 - val_accuracy: 0.7933\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9201 - accuracy: 0.8095 - val_loss: 0.9220 - val_accuracy: 0.8244\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9098 - accuracy: 0.7962 - val_loss: 0.9170 - val_accuracy: 0.7600\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8992 - accuracy: 0.7990 - val_loss: 0.9032 - val_accuracy: 0.8067\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8886 - accuracy: 0.7895 - val_loss: 0.8923 - val_accuracy: 0.8089\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8773 - accuracy: 0.7943 - val_loss: 0.8840 - val_accuracy: 0.7289\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.7876 - val_loss: 0.8735 - val_accuracy: 0.7911\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8599 - accuracy: 0.7857 - val_loss: 0.8639 - val_accuracy: 0.7978\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8502 - accuracy: 0.7648 - val_loss: 0.8578 - val_accuracy: 0.7911\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8409 - accuracy: 0.7867 - val_loss: 0.8454 - val_accuracy: 0.7733\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8328 - accuracy: 0.7895 - val_loss: 0.8377 - val_accuracy: 0.7889\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8238 - accuracy: 0.7848 - val_loss: 0.8317 - val_accuracy: 0.7667\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8155 - accuracy: 0.7962 - val_loss: 0.8220 - val_accuracy: 0.7822\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8093 - accuracy: 0.7838 - val_loss: 0.8183 - val_accuracy: 0.7533\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[123  23   2]\n",
            " [ 19 117   7]\n",
            " [ 16  44  99]]\n",
            "\n",
            "P-Score: 0.777, R-Score: 0.757, F-Score: 0.754\n",
            "[0.7533333333333333, 0.7770057481807618, 0.7573014695656205, 0.7536969775368485, 0.8575935206729908, 0.7999703879182708, 0.7958568371912079, 0.8178069152608232]\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_84 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_86 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1672 - accuracy: 0.1162 - val_loss: 1.1562 - val_accuracy: 0.0956\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1550 - accuracy: 0.1676 - val_loss: 1.1499 - val_accuracy: 0.1911\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1482 - accuracy: 0.2933 - val_loss: 1.1429 - val_accuracy: 0.2111\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1435 - accuracy: 0.2695 - val_loss: 1.1383 - val_accuracy: 0.2511\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1380 - accuracy: 0.2629 - val_loss: 1.1345 - val_accuracy: 0.2778\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1335 - accuracy: 0.3124 - val_loss: 1.1300 - val_accuracy: 0.2689\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1290 - accuracy: 0.3219 - val_loss: 1.1255 - val_accuracy: 0.2644\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1248 - accuracy: 0.3048 - val_loss: 1.1212 - val_accuracy: 0.2689\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1207 - accuracy: 0.2686 - val_loss: 1.1179 - val_accuracy: 0.2956\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1167 - accuracy: 0.2438 - val_loss: 1.1149 - val_accuracy: 0.3133\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1129 - accuracy: 0.3390 - val_loss: 1.1106 - val_accuracy: 0.3022\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1095 - accuracy: 0.2590 - val_loss: 1.1079 - val_accuracy: 0.3222\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1061 - accuracy: 0.3448 - val_loss: 1.1040 - val_accuracy: 0.3333\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.1015 - accuracy: 0.3352 - val_loss: 1.1013 - val_accuracy: 0.3133\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0986 - accuracy: 0.3571 - val_loss: 1.0967 - val_accuracy: 0.3222\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0946 - accuracy: 0.3600 - val_loss: 1.0934 - val_accuracy: 0.4156\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0914 - accuracy: 0.4257 - val_loss: 1.0899 - val_accuracy: 0.4200\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0878 - accuracy: 0.4419 - val_loss: 1.0859 - val_accuracy: 0.4067\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0841 - accuracy: 0.4476 - val_loss: 1.0828 - val_accuracy: 0.4333\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0803 - accuracy: 0.4867 - val_loss: 1.0790 - val_accuracy: 0.4356\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0767 - accuracy: 0.4800 - val_loss: 1.0756 - val_accuracy: 0.4822\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0732 - accuracy: 0.5124 - val_loss: 1.0717 - val_accuracy: 0.4556\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0689 - accuracy: 0.4724 - val_loss: 1.0685 - val_accuracy: 0.4978\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0649 - accuracy: 0.5295 - val_loss: 1.0639 - val_accuracy: 0.4867\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0607 - accuracy: 0.5238 - val_loss: 1.0573 - val_accuracy: 0.4756\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0525 - accuracy: 0.4486 - val_loss: 1.0500 - val_accuracy: 0.5022\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0468 - accuracy: 0.4857 - val_loss: 1.0459 - val_accuracy: 0.5133\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0405 - accuracy: 0.5552 - val_loss: 1.0389 - val_accuracy: 0.4978\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0350 - accuracy: 0.5381 - val_loss: 1.0335 - val_accuracy: 0.5111\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0298 - accuracy: 0.5552 - val_loss: 1.0288 - val_accuracy: 0.5111\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0243 - accuracy: 0.5524 - val_loss: 1.0239 - val_accuracy: 0.5111\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0184 - accuracy: 0.5505 - val_loss: 1.0180 - val_accuracy: 0.5133\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0126 - accuracy: 0.5724 - val_loss: 1.0123 - val_accuracy: 0.5133\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0062 - accuracy: 0.5676 - val_loss: 1.0053 - val_accuracy: 0.5444\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9987 - accuracy: 0.5829 - val_loss: 0.9987 - val_accuracy: 0.5889\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9928 - accuracy: 0.6162 - val_loss: 0.9921 - val_accuracy: 0.5533\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9850 - accuracy: 0.6010 - val_loss: 0.9846 - val_accuracy: 0.6244\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9781 - accuracy: 0.6133 - val_loss: 0.9773 - val_accuracy: 0.6333\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9690 - accuracy: 0.6495 - val_loss: 0.9677 - val_accuracy: 0.6956\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9579 - accuracy: 0.6362 - val_loss: 0.9557 - val_accuracy: 0.6711\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9422 - accuracy: 0.6752 - val_loss: 0.9407 - val_accuracy: 0.6667\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9285 - accuracy: 0.6486 - val_loss: 0.9298 - val_accuracy: 0.6711\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9165 - accuracy: 0.6676 - val_loss: 0.9221 - val_accuracy: 0.6378\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9082 - accuracy: 0.6733 - val_loss: 0.9122 - val_accuracy: 0.6933\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8982 - accuracy: 0.6933 - val_loss: 0.9065 - val_accuracy: 0.6467\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8902 - accuracy: 0.7000 - val_loss: 0.8979 - val_accuracy: 0.6556\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8815 - accuracy: 0.6990 - val_loss: 0.8891 - val_accuracy: 0.6711\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8743 - accuracy: 0.7029 - val_loss: 0.8827 - val_accuracy: 0.6733\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8650 - accuracy: 0.6781 - val_loss: 0.8750 - val_accuracy: 0.6778\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8594 - accuracy: 0.6962 - val_loss: 0.8690 - val_accuracy: 0.6467\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8515 - accuracy: 0.6990 - val_loss: 0.8634 - val_accuracy: 0.6400\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8443 - accuracy: 0.6771 - val_loss: 0.8555 - val_accuracy: 0.6800\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8382 - accuracy: 0.6819 - val_loss: 0.8496 - val_accuracy: 0.6756\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8313 - accuracy: 0.6829 - val_loss: 0.8442 - val_accuracy: 0.6622\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8253 - accuracy: 0.7000 - val_loss: 0.8395 - val_accuracy: 0.6556\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8186 - accuracy: 0.6981 - val_loss: 0.8440 - val_accuracy: 0.6200\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8152 - accuracy: 0.6819 - val_loss: 0.8298 - val_accuracy: 0.6578\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8084 - accuracy: 0.6867 - val_loss: 0.8293 - val_accuracy: 0.6600\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.6895 - val_loss: 0.8234 - val_accuracy: 0.6622\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7999 - accuracy: 0.6905 - val_loss: 0.8169 - val_accuracy: 0.6644\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7965 - accuracy: 0.6914 - val_loss: 0.8117 - val_accuracy: 0.6644\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7921 - accuracy: 0.6771 - val_loss: 0.8096 - val_accuracy: 0.6622\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7861 - accuracy: 0.6962 - val_loss: 0.8035 - val_accuracy: 0.6667\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7827 - accuracy: 0.6829 - val_loss: 0.8047 - val_accuracy: 0.6711\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7806 - accuracy: 0.6848 - val_loss: 0.7991 - val_accuracy: 0.6600\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7744 - accuracy: 0.6771 - val_loss: 0.7951 - val_accuracy: 0.6622\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7746 - accuracy: 0.6857 - val_loss: 0.7917 - val_accuracy: 0.6667\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7704 - accuracy: 0.6876 - val_loss: 0.7890 - val_accuracy: 0.6489\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7660 - accuracy: 0.6771 - val_loss: 0.7912 - val_accuracy: 0.6689\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7634 - accuracy: 0.6867 - val_loss: 0.7836 - val_accuracy: 0.6556\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7623 - accuracy: 0.6724 - val_loss: 0.7833 - val_accuracy: 0.6600\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7570 - accuracy: 0.6743 - val_loss: 0.7804 - val_accuracy: 0.6644\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7554 - accuracy: 0.6933 - val_loss: 0.7749 - val_accuracy: 0.6733\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.6790 - val_loss: 0.7735 - val_accuracy: 0.6689\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7524 - accuracy: 0.6810 - val_loss: 0.7751 - val_accuracy: 0.6644\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7504 - accuracy: 0.6771 - val_loss: 0.7723 - val_accuracy: 0.6778\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7466 - accuracy: 0.6924 - val_loss: 0.7679 - val_accuracy: 0.6756\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7469 - accuracy: 0.6962 - val_loss: 0.7711 - val_accuracy: 0.6667\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7432 - accuracy: 0.6933 - val_loss: 0.7792 - val_accuracy: 0.6600\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7413 - accuracy: 0.6867 - val_loss: 0.7650 - val_accuracy: 0.6711\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[108  29  11]\n",
            " [ 17  74  52]\n",
            " [ 11  28 120]]\n",
            "\n",
            "P-Score: 0.672, R-Score: 0.667, F-Score: 0.667\n",
            "[0.6711111111111111, 0.6715802827200208, 0.6673097427814408, 0.6674879172160207, 0.818507248970825, 0.6659073825197604, 0.7691110678856253, 0.7511752331254037]\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_87 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.2210 - accuracy: 0.3114 - val_loss: 1.1408 - val_accuracy: 0.3200\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1389 - accuracy: 0.3019 - val_loss: 1.1191 - val_accuracy: 0.3089\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1232 - accuracy: 0.2095 - val_loss: 1.1157 - val_accuracy: 0.2978\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1189 - accuracy: 0.2562 - val_loss: 1.1127 - val_accuracy: 0.3244\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1150 - accuracy: 0.2895 - val_loss: 1.1083 - val_accuracy: 0.3356\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1110 - accuracy: 0.3000 - val_loss: 1.1050 - val_accuracy: 0.3200\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1065 - accuracy: 0.2952 - val_loss: 1.1013 - val_accuracy: 0.3200\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1030 - accuracy: 0.3057 - val_loss: 1.0987 - val_accuracy: 0.3200\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1001 - accuracy: 0.3038 - val_loss: 1.0968 - val_accuracy: 0.3289\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0978 - accuracy: 0.2924 - val_loss: 1.0946 - val_accuracy: 0.3267\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0952 - accuracy: 0.3057 - val_loss: 1.0933 - val_accuracy: 0.3378\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0930 - accuracy: 0.3200 - val_loss: 1.0913 - val_accuracy: 0.3356\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0913 - accuracy: 0.3276 - val_loss: 1.0884 - val_accuracy: 0.3289\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0892 - accuracy: 0.3086 - val_loss: 1.0866 - val_accuracy: 0.3333\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0873 - accuracy: 0.3010 - val_loss: 1.0846 - val_accuracy: 0.3311\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0854 - accuracy: 0.3229 - val_loss: 1.0830 - val_accuracy: 0.3400\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0836 - accuracy: 0.3219 - val_loss: 1.0809 - val_accuracy: 0.3378\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0814 - accuracy: 0.3124 - val_loss: 1.0790 - val_accuracy: 0.3400\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0797 - accuracy: 0.3248 - val_loss: 1.0771 - val_accuracy: 0.3489\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0771 - accuracy: 0.3343 - val_loss: 1.0763 - val_accuracy: 0.3644\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0745 - accuracy: 0.3676 - val_loss: 1.0733 - val_accuracy: 0.3689\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0719 - accuracy: 0.3419 - val_loss: 1.0708 - val_accuracy: 0.3667\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0691 - accuracy: 0.3533 - val_loss: 1.0663 - val_accuracy: 0.3622\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0658 - accuracy: 0.3600 - val_loss: 1.0637 - val_accuracy: 0.3756\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0622 - accuracy: 0.3486 - val_loss: 1.0582 - val_accuracy: 0.4089\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0572 - accuracy: 0.4038 - val_loss: 1.0548 - val_accuracy: 0.4111\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0531 - accuracy: 0.4276 - val_loss: 1.0517 - val_accuracy: 0.4222\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0486 - accuracy: 0.4419 - val_loss: 1.0483 - val_accuracy: 0.4711\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0445 - accuracy: 0.4886 - val_loss: 1.0407 - val_accuracy: 0.4978\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0397 - accuracy: 0.5076 - val_loss: 1.0389 - val_accuracy: 0.5333\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0343 - accuracy: 0.5667 - val_loss: 1.0314 - val_accuracy: 0.5822\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.5876 - val_loss: 1.0246 - val_accuracy: 0.5911\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.5914 - val_loss: 1.0205 - val_accuracy: 0.5400\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.5610 - val_loss: 1.0150 - val_accuracy: 0.6000\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0100 - accuracy: 0.5905 - val_loss: 1.0073 - val_accuracy: 0.5911\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0036 - accuracy: 0.5848 - val_loss: 1.0027 - val_accuracy: 0.6333\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9969 - accuracy: 0.6133 - val_loss: 0.9946 - val_accuracy: 0.6133\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9893 - accuracy: 0.6010 - val_loss: 0.9874 - val_accuracy: 0.6156\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9815 - accuracy: 0.6257 - val_loss: 0.9806 - val_accuracy: 0.6022\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9729 - accuracy: 0.6229 - val_loss: 0.9724 - val_accuracy: 0.6244\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9640 - accuracy: 0.6067 - val_loss: 0.9677 - val_accuracy: 0.6200\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9562 - accuracy: 0.6305 - val_loss: 0.9560 - val_accuracy: 0.6267\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9465 - accuracy: 0.6410 - val_loss: 0.9478 - val_accuracy: 0.6222\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.9366 - accuracy: 0.6114 - val_loss: 0.9428 - val_accuracy: 0.6467\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9280 - accuracy: 0.6505 - val_loss: 0.9320 - val_accuracy: 0.6600\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9202 - accuracy: 0.6152 - val_loss: 0.9206 - val_accuracy: 0.6422\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9091 - accuracy: 0.6352 - val_loss: 0.9122 - val_accuracy: 0.6556\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9000 - accuracy: 0.6467 - val_loss: 0.9043 - val_accuracy: 0.6822\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.6524 - val_loss: 0.8969 - val_accuracy: 0.6578\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.8834 - accuracy: 0.6400 - val_loss: 0.8879 - val_accuracy: 0.6711\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8747 - accuracy: 0.6505 - val_loss: 0.8801 - val_accuracy: 0.6711\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8649 - accuracy: 0.6533 - val_loss: 0.8742 - val_accuracy: 0.6622\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8559 - accuracy: 0.6619 - val_loss: 0.8727 - val_accuracy: 0.6622\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8511 - accuracy: 0.6629 - val_loss: 0.8568 - val_accuracy: 0.6667\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8429 - accuracy: 0.6600 - val_loss: 0.8495 - val_accuracy: 0.6289\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8357 - accuracy: 0.6543 - val_loss: 0.8449 - val_accuracy: 0.6800\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8288 - accuracy: 0.6705 - val_loss: 0.8450 - val_accuracy: 0.6756\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.6829 - val_loss: 0.8317 - val_accuracy: 0.6778\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8172 - accuracy: 0.6733 - val_loss: 0.8330 - val_accuracy: 0.6911\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8122 - accuracy: 0.6848 - val_loss: 0.8215 - val_accuracy: 0.6844\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8063 - accuracy: 0.6762 - val_loss: 0.8232 - val_accuracy: 0.6556\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8001 - accuracy: 0.6876 - val_loss: 0.8134 - val_accuracy: 0.6333\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7964 - accuracy: 0.6705 - val_loss: 0.8072 - val_accuracy: 0.6956\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7908 - accuracy: 0.6981 - val_loss: 0.8046 - val_accuracy: 0.6911\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7868 - accuracy: 0.6962 - val_loss: 0.8009 - val_accuracy: 0.6978\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7843 - accuracy: 0.6800 - val_loss: 0.7992 - val_accuracy: 0.7022\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7779 - accuracy: 0.7057 - val_loss: 0.7928 - val_accuracy: 0.7044\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.7057 - val_loss: 0.7896 - val_accuracy: 0.7000\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7728 - accuracy: 0.7000 - val_loss: 0.7895 - val_accuracy: 0.7156\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7689 - accuracy: 0.7133 - val_loss: 0.7853 - val_accuracy: 0.7000\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 3ms/step - loss: 0.7641 - accuracy: 0.6971 - val_loss: 0.7814 - val_accuracy: 0.7067\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7624 - accuracy: 0.7152 - val_loss: 0.7778 - val_accuracy: 0.7222\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7597 - accuracy: 0.7076 - val_loss: 0.7770 - val_accuracy: 0.7000\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.7105 - val_loss: 0.7739 - val_accuracy: 0.7156\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7555 - accuracy: 0.7143 - val_loss: 0.7700 - val_accuracy: 0.7111\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7502 - accuracy: 0.7248 - val_loss: 0.7723 - val_accuracy: 0.7289\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.7487 - accuracy: 0.7286 - val_loss: 0.7650 - val_accuracy: 0.7111\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7455 - accuracy: 0.7086 - val_loss: 0.7649 - val_accuracy: 0.7378\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7439 - accuracy: 0.7190 - val_loss: 0.7685 - val_accuracy: 0.6911\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.7248 - val_loss: 0.7632 - val_accuracy: 0.7022\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[129   6  13]\n",
            " [ 26  57  60]\n",
            " [ 26   3 130]]\n",
            "\n",
            "P-Score: 0.739, R-Score: 0.696, F-Score: 0.683\n",
            "[0.7022222222222222, 0.7389125448755854, 0.6959443610387007, 0.6826270395096068, 0.8497180955790227, 0.6846427188446732, 0.7833754781819361, 0.7725787642018774]\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.762222   0.766777  0.762328  0.762656  0.847324  0.781053  0.838131   \n",
            "1  0.653333   0.665278  0.653118  0.657050  0.823474  0.662024  0.735136   \n",
            "2  0.780000   0.793944  0.782849  0.780209  0.851038  0.832783  0.827303   \n",
            "3  0.735556   0.736990  0.733344  0.734505  0.828575  0.740963  0.832653   \n",
            "4  0.733333   0.738174  0.732030  0.733729  0.825197  0.745177  0.828665   \n",
            "5  0.664444   0.678282  0.659618  0.662686  0.807969  0.647992  0.781106   \n",
            "6  0.806667   0.824609  0.810035  0.806806  0.863097  0.869570  0.839039   \n",
            "7  0.753333   0.777006  0.757301  0.753697  0.857594  0.799970  0.795857   \n",
            "8  0.671111   0.671580  0.667310  0.667488  0.818507  0.665907  0.769111   \n",
            "9  0.702222   0.738913  0.695944  0.682627  0.849718  0.684643  0.783375   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.822169  \n",
            "1       0.740211  \n",
            "2       0.837041  \n",
            "3       0.800730  \n",
            "4       0.799680  \n",
            "5       0.745689  \n",
            "6       0.857236  \n",
            "7       0.817807  \n",
            "8       0.751175  \n",
            "9       0.772579  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.04869618 0.02860203 0.02270177]\n",
            " [0.0032593  0.04441226 0.05232845]\n",
            " [0.07739821 0.01269505 0.00990673]\n",
            " ...\n",
            " [0.01886055 0.03848315 0.04265628]\n",
            " [0.00173533 0.03881037 0.05945429]\n",
            " [0.04649197 0.02719045 0.02631758]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed00cd6",
      "metadata": {
        "id": "eed00cd6"
      },
      "source": [
        "### Training the model using SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "train_x = load('train_x.npy')\n",
        "test_x = load('train_y.npy')\n",
        "train_y = load('test_x.npy')\n",
        "test_y = load('test_y.npy')"
      ],
      "metadata": {
        "id": "mrX_hU_lRvO1"
      },
      "id": "mrX_hU_lRvO1",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc(model, test_x, test_y, n_classes):\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  roc_auc = {}\n",
        "\n",
        "  y_pred = model.predict(test_x)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  prediction = pd.get_dummies(y_pred).values\n",
        "  print(n_classes)\n",
        "  for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "\n",
        "  return roc_auc"
      ],
      "metadata": {
        "id": "42cgkcYuRwLv"
      },
      "id": "42cgkcYuRwLv",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_avg_AUC_ROC(y_pred, test_y, n_classes, label_names, figsize=(6.4, 4.8), average=\"macro\"):\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "\n",
        "  #y_pred = model.predict(test_x, batch_size=64, verbose=1)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  \n",
        "  for i in range(n_classes):\n",
        "    #fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i].astype(int) ,y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "      # roc for each class\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.set_xlim([0.0, 1.0])\n",
        "  ax.set_ylim([0.0, 1.05])\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive Rate')\n",
        "  ax.set_title('Receiver operating characteristic example')\n",
        "  for i in range(n_classes):\n",
        "      ax.plot(fpr[i], tpr[i], label='ROC curve (area = {}) for {}'.format('{0:.2f}'.format(roc_auc[i]), label_names[i]))\n",
        "  ax.legend(loc=\"best\")\n",
        "  ax.grid(alpha=.4)\n",
        "  sns.despine()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "qpu_rcUFRwJZ"
      },
      "id": "qpu_rcUFRwJZ",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(train_x, train_y)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "\n",
        "grid_predictions = grid.predict(test_x)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(test_y, grid_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQ7ZJYxbRwGl",
        "outputId": "4dcc19d6-3e12-4978-e58c-6d34d2b68f80"
      },
      "id": "EQ7ZJYxbRwGl",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.600 total time=   0.3s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.576 total time=   0.2s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.567 total time=   0.2s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.552 total time=   0.1s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=   0.2s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.343 total time=   0.3s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.343 total time=   0.3s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.343 total time=   0.4s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.2s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.2s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.3s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.2s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.4s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.867 total time=   0.1s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.867 total time=   0.1s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.852 total time=   0.1s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.871 total time=   0.1s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.600 total time=   0.1s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.576 total time=   0.1s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.948 total time=   0.0s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.910 total time=   0.0s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.895 total time=   0.0s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.924 total time=   0.0s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.895 total time=   0.0s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.0s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.867 total time=   0.0s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.0s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.871 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.600 total time=   0.1s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.576 total time=   0.1s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.967 total time=   0.0s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.938 total time=   0.0s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.948 total time=   0.0s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.957 total time=   0.0s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.938 total time=   0.0s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.948 total time=   0.0s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.924 total time=   0.0s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.867 total time=   0.0s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.867 total time=   0.0s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.0s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.871 total time=   0.0s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.600 total time=   0.1s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.576 total time=   0.1s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.343 total time=   0.1s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.971 total time=   0.0s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.938 total time=   0.0s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.943 total time=   0.0s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.952 total time=   0.0s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.943 total time=   0.0s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.962 total time=   0.0s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.933 total time=   0.0s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.933 total time=   0.0s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.967 total time=   0.0s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.0s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.948 total time=   0.0s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.905 total time=   0.0s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.929 total time=   0.0s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.900 total time=   0.0s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.867 total time=   0.0s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.867 total time=   0.0s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.0s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.871 total time=   0.0s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.600 total time=   0.1s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.576 total time=   0.1s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "{'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
            "SVC(C=100, gamma=1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.93      0.89      0.91       148\n",
            "         1.0       0.97      0.98      0.98       143\n",
            "         2.0       0.92      0.95      0.93       159\n",
            "\n",
            "    accuracy                           0.94       450\n",
            "   macro avg       0.94      0.94      0.94       450\n",
            "weighted avg       0.94      0.94      0.94       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 3\n",
        "NAME = \"Landsat9_DATA\"\n",
        "Model_name = \"SVM\"\n",
        "columns = ['Accuracy', 'precision', 'recall', 'F1_score', \"AUC_0\", \"AUC_1\", \"AUC_2\", \"Aggregate_AUC\"]\n",
        "df = pd.DataFrame(columns = columns)\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "model = SVC(C=100, kernel='rbf', gamma=1, probability=True)\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "yTestPredicted = model.predict(test_x)\n",
        "n_classes = 3\n",
        "Accuracy = accuracy_score(test_y, yTestPredicted)\n",
        "cMatrix = confusion_matrix(test_y, yTestPredicted)\n",
        "pScore = precision_score(test_y, yTestPredicted, average='macro')\n",
        "rScore = recall_score(test_y, yTestPredicted, average='macro')\n",
        "fscore = f1_score(test_y, yTestPredicted, average='macro')\n",
        "\n",
        "print(\"Confusion matrix:\\n\", cMatrix)\n",
        "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n",
        "\n",
        "#This function calculates all the evaluation metrics for every iteration\n",
        "roc_auc = roc(model, test_x, test_y, n_classes)\n",
        "\n",
        "sum_of_roc_scores = 0\n",
        "for i in range(n_classes):\n",
        "  sum_of_roc_scores = sum_of_roc_scores + roc_auc[i]\n",
        "\n",
        "aggregate_roc_score = sum_of_roc_scores/n_classes\n",
        "\n",
        "\n",
        "print(\"Confusion matrix:\\n\", cMatrix)\n",
        "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n",
        "\n",
        "result_dict = {'Accuracy': Accuracy, 'precision': pScore, 'recall' : rScore, 'F1_score': fscore, \"AUC_0\": roc_auc[0]\n",
        "                   , \"AUC_1\": roc_auc[1], \"AUC_2\": roc_auc[2], \"Aggregate_AUC\": aggregate_roc_score}\n",
        "df = df.append(result_dict, ignore_index = True)\n",
        "print(df)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "y_pred = model.predict_proba(test_x)\n",
        "plot_avg_AUC_ROC(y_pred, test_y, 3, label_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "bdUb32FQRwBd",
        "outputId": "23371ca7-aeba-4107-cf3f-8549f7acea6c"
      },
      "id": "bdUb32FQRwBd",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[131   4  13]\n",
            " [  2 140   1]\n",
            " [  8   0 151]]\n",
            "\n",
            "P-Score: 0.939, R-Score: 0.938, F-Score: 0.938\n",
            "3\n",
            "Confusion matrix:\n",
            " [[131   4  13]\n",
            " [  2 140   1]\n",
            " [  8   0 151]]\n",
            "\n",
            "P-Score: 0.939, R-Score: 0.938, F-Score: 0.938\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.937778   0.938817  0.937947  0.938094  0.926011  0.982996  0.950788   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.953265  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cnn_cx_pip",
      "language": "python",
      "name": "cnn_cx_pip"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}