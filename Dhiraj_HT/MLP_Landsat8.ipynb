{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "864cc267",
      "metadata": {
        "id": "864cc267"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAioQNlo66wB",
        "outputId": "54d85a90-80b5-408b-b4b4-99097a277e93"
      },
      "id": "fAioQNlo66wB",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/New_Alteration_zones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRsfP11r69ax",
        "outputId": "e3c7bc8f-7c90-453a-b528-c4440d36f513"
      },
      "id": "oRsfP11r69ax",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/New_Alteration_zones\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contextily\n",
        "!pip install pyrsgis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wt2dsfu6-MD",
        "outputId": "d2545516-3e85-479d-8ad4-8c96f589d699"
      },
      "id": "-Wt2dsfu6-MD",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting contextily\n",
            "  Downloading contextily-1.2.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: geopy in /usr/local/lib/python3.7/dist-packages (from contextily) (1.17.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from contextily) (1.2.0)\n",
            "Collecting xyzservices\n",
            "  Downloading xyzservices-2022.9.0-py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from contextily) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from contextily) (2.23.0)\n",
            "Collecting mercantile\n",
            "  Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from contextily) (7.1.2)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: geographiclib<2,>=1.49 in /usr/local/lib/python3.7/dist-packages (from geopy->contextily) (1.52)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (1.21.6)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->contextily) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->contextily) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->contextily) (1.15.0)\n",
            "Requirement already satisfied: click>=3.0 in /usr/local/lib/python3.7/dist-packages (from mercantile->contextily) (7.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (57.4.0)\n",
            "Collecting click-plugins\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (2022.9.24)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.1-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from rasterio->contextily) (22.1.0)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->contextily) (2.10)\n",
            "Installing collected packages: snuggs, cligj, click-plugins, affine, xyzservices, rasterio, mercantile, contextily\n",
            "Successfully installed affine-2.3.1 click-plugins-1.1.1 cligj-0.7.2 contextily-1.2.0 mercantile-1.2.1 rasterio-1.2.10 snuggs-1.4.7 xyzservices-2022.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyrsgis\n",
            "  Downloading pyrsgis-0.4.1-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: pyrsgis\n",
            "Successfully installed pyrsgis-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0e0c0e57",
      "metadata": {
        "id": "0e0c0e57"
      },
      "outputs": [],
      "source": [
        "import contextily as cx\n",
        "from ipywidgets import interact\n",
        "from math import floor\n",
        "import matplotlib as mpl\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.convert import array_to_table\n",
        "from pyrsgis.ml import imageChipsFromArray\n",
        "import random\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model, Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3255c2ce",
      "metadata": {
        "id": "3255c2ce"
      },
      "source": [
        "### Training the model using MLP"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd train_Landsat8/MLP_Landsat8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7O9mBCgk6K_x",
        "outputId": "af5039aa-2e11-4146-cd28-d584a45354cf"
      },
      "id": "7O9mBCgk6K_x",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/New_Alteration_zones/train_Landsat8/MLP_Landsat8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "train_x = load('train_x.npy')\n",
        "test_x = load('train_y.npy')\n",
        "train_y = load('test_x.npy')\n",
        "test_y = load('test_y.npy')\n",
        "train_y = pd.get_dummies(train_y, drop_first=False).values\n",
        "test_y = pd.get_dummies(test_y, drop_first=False).values"
      ],
      "metadata": {
        "id": "wSzNeB-F6OLT"
      },
      "id": "wSzNeB-F6OLT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metric(history, metric):    #For plotting any graph relating to any model\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-1j-Movr6Pkn"
      },
      "id": "-1j-Movr6Pkn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_avg_AUC_ROC(y_pred, test_y, n_classes, label_names, figsize=(6.4, 4.8), average=\"macro\"):\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "\n",
        "  #y_pred = model.predict(test_x, batch_size=64, verbose=1)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  \n",
        "  for i in range(n_classes):\n",
        "    #fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i].astype(int) ,y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "      # roc for each class\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.set_xlim([0.0, 1.0])\n",
        "  ax.set_ylim([0.0, 1.05])\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive Rate')\n",
        "  ax.set_title('Receiver operating characteristic example')\n",
        "  for i in range(n_classes):\n",
        "      ax.plot(fpr[i], tpr[i], label='ROC curve (area = {}) for {}'.format('{0:.2f}'.format(roc_auc[i]), label_names[i]))\n",
        "  ax.legend(loc=\"best\")\n",
        "  ax.grid(alpha=.4)\n",
        "  sns.despine()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "F0BYpBML6Sha"
      },
      "id": "F0BYpBML6Sha",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc(model, test_x, test_y, n_classes):\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  roc_auc = {}\n",
        "\n",
        "  y_pred = model.predict(test_x, batch_size=64, verbose=1)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  prediction = pd.get_dummies(y_pred.argmax(axis = 1),drop_first=False).values\n",
        "  print(n_classes)\n",
        "  for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "  return roc_auc"
      ],
      "metadata": {
        "id": "2Bzzg_4h6UpH"
      },
      "id": "2Bzzg_4h6UpH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epSrzx1JyX6l",
        "outputId": "c240d5dd-3295-4e51-a6cd-5bcfbe69b93b"
      },
      "id": "epSrzx1JyX6l",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1050, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############## ORiginal Model Code ###################\n",
        "def MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y):\n",
        "  best_accuracy = 0\n",
        "  best_model = tf.keras.models.Sequential()\n",
        "  best_history = None\n",
        "\n",
        "  columns = ['Accuracy', 'precision', 'recall', 'F1_score', \"AUC_0\", \"AUC_1\", \"AUC_2\", \"Aggregate_AUC\"]\n",
        "  df = pd.DataFrame(columns = columns)\n",
        "\n",
        "  for i in range(experimental_runs):\n",
        "    #Model_name = \"CNN_RMSPROP\"\n",
        "\n",
        "    model = tf.keras.models.Sequential()\n",
        "    model.add(tf.keras.layers.Dense(7, activation='selu', input_shape=(train_x.shape[1], )))\n",
        "    model.add(tf.keras.layers.Dense(5, activation='selu'))\n",
        "    model.add(tf.keras.layers.Dense(3, activation='softmax'))\n",
        "    print(model.summary())\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=optimiser_type, metrics=['accuracy'])\n",
        "    history = model.fit(train_x, train_y, epochs = 80, validation_data = (test_x, test_y))\n",
        "\n",
        "    sum_y_pred = 0\n",
        "    # predict for the test dataset\n",
        "    yTestPredicted = model.predict(test_x)\n",
        "    sum_y_pred = sum_y_pred + yTestPredicted\n",
        "    # calculate and display error metrics\n",
        "    yTestPredicted_ = yTestPredicted.argmax(axis=1)\n",
        "\n",
        "    n_classes = 3\n",
        "    test_y_dummies = test_y.argmax(axis = 1)\n",
        "    Accuracy = accuracy_score(test_y_dummies, yTestPredicted_)\n",
        "    cMatrix = confusion_matrix(test_y_dummies, yTestPredicted_)\n",
        "    pScore = precision_score(test_y_dummies, yTestPredicted_, average='macro')\n",
        "    rScore = recall_score(test_y_dummies, yTestPredicted_, average='macro')\n",
        "    fscore = f1_score(test_y_dummies, yTestPredicted_, average='macro')\n",
        "\n",
        "    #This function calculates all the evaluation metrics for every iteration\n",
        "    roc_auc = roc(model, test_x, test_y_dummies, n_classes)\n",
        "    result_array = [Accuracy, pScore, rScore, fscore]\n",
        "\n",
        "\n",
        "    sum_of_roc_scores = 0\n",
        "    for i in range(n_classes):\n",
        "      result_array.append(roc_auc[i])\n",
        "      sum_of_roc_scores = sum_of_roc_scores + roc_auc[i]\n",
        "\n",
        "    aggregate_roc_score = sum_of_roc_scores/n_classes\n",
        "    result_array.append(aggregate_roc_score)\n",
        "\n",
        "    print(\"Confusion matrix:\\n\", cMatrix)\n",
        "    print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n",
        "    \n",
        "    if best_accuracy < Accuracy:\n",
        "      best_model = model\n",
        "      best_accuracy = Accuracy\n",
        "      best_history = history\n",
        "\n",
        "    print(result_array)\n",
        "    result_dict = {'Accuracy': Accuracy, 'precision': pScore, 'recall' : rScore, 'F1_score': fscore, \"AUC_0\": result_array[4]\n",
        "                   , \"AUC_1\": result_array[5], \"AUC_2\": result_array[6], \"Aggregate_AUC\": result_array[7]}\n",
        "    df = df.append(result_dict, ignore_index = True)\n",
        "  print(df)\n",
        "  return best_model, best_history, sum_y_pred/experimental_runs, df"
      ],
      "metadata": {
        "id": "39UBxl7w6WtL"
      },
      "id": "39UBxl7w6WtL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(train_y.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pArJPkixDKm",
        "outputId": "f899b835-3e47-48b4-be40-7e0caf844c95"
      },
      "id": "6pArJPkixDKm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1050, 7)\n",
            "(1050,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'MLP_RMSPROP'\n",
        "NAME = 'Landsat8_DATA'\n",
        "optimiser_type = 'rmsprop'\n",
        "experimental_runs = 10\n",
        "\n",
        "best_model, best_history, avg_y_pred, df = MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "best_model.save('Best_model_{}_{}'.format(NAME, Model_name))\n",
        "plot_metric(best_history, \"loss\")\n",
        "print(\"\")\n",
        "plot_metric(best_history, \"accuracy\")\n",
        "# plot_AUC_ROC(best_model, test_x, test_y, 3, label_names)\n",
        "# print(\"\")\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "print(avg_y_pred)\n",
        "test_y_dummies = test_y.argmax(axis = 1)\n",
        "plot_avg_AUC_ROC(avg_y_pred, test_y_dummies, 3, label_names)\n",
        "print(\"\")\n",
        "avg_y_pred = avg_y_pred.argmax(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6fuxgZCA6hl6",
        "outputId": "0eb72077-8372-4069-c5ea-bcdb3afeb13c"
      },
      "id": "6fuxgZCA6hl6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_37\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_68 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_69 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.2416 - accuracy: 0.3352 - val_loss: 1.1741 - val_accuracy: 0.3222\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1353 - accuracy: 0.3381 - val_loss: 1.1110 - val_accuracy: 0.3222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0933 - accuracy: 0.3429 - val_loss: 1.0867 - val_accuracy: 0.3222\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0820 - accuracy: 0.3848 - val_loss: 1.0785 - val_accuracy: 0.4622\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0754 - accuracy: 0.4467 - val_loss: 1.0718 - val_accuracy: 0.4489\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0667 - accuracy: 0.4219 - val_loss: 1.0602 - val_accuracy: 0.4889\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0563 - accuracy: 0.5200 - val_loss: 1.0517 - val_accuracy: 0.5422\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0463 - accuracy: 0.5686 - val_loss: 1.0421 - val_accuracy: 0.7289\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0336 - accuracy: 0.6571 - val_loss: 1.0287 - val_accuracy: 0.6044\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0224 - accuracy: 0.6657 - val_loss: 1.0187 - val_accuracy: 0.6000\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0111 - accuracy: 0.6505 - val_loss: 1.0092 - val_accuracy: 0.7244\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9987 - accuracy: 0.6924 - val_loss: 0.9969 - val_accuracy: 0.6733\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9886 - accuracy: 0.6581 - val_loss: 0.9898 - val_accuracy: 0.7578\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9751 - accuracy: 0.7019 - val_loss: 0.9748 - val_accuracy: 0.7067\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9613 - accuracy: 0.6895 - val_loss: 0.9564 - val_accuracy: 0.6067\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9415 - accuracy: 0.6714 - val_loss: 0.9397 - val_accuracy: 0.6578\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9260 - accuracy: 0.6724 - val_loss: 0.9258 - val_accuracy: 0.6711\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9103 - accuracy: 0.6943 - val_loss: 0.9144 - val_accuracy: 0.5956\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8969 - accuracy: 0.6581 - val_loss: 0.8977 - val_accuracy: 0.6556\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8809 - accuracy: 0.6619 - val_loss: 0.8859 - val_accuracy: 0.7400\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8666 - accuracy: 0.6724 - val_loss: 0.8703 - val_accuracy: 0.7178\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8501 - accuracy: 0.7067 - val_loss: 0.8562 - val_accuracy: 0.7089\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8388 - accuracy: 0.6752 - val_loss: 0.8432 - val_accuracy: 0.7222\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8231 - accuracy: 0.7133 - val_loss: 0.8300 - val_accuracy: 0.7311\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8104 - accuracy: 0.7048 - val_loss: 0.8167 - val_accuracy: 0.7222\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7985 - accuracy: 0.7219 - val_loss: 0.8052 - val_accuracy: 0.7156\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7863 - accuracy: 0.7133 - val_loss: 0.7941 - val_accuracy: 0.6933\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7738 - accuracy: 0.7257 - val_loss: 0.7842 - val_accuracy: 0.7378\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7629 - accuracy: 0.7610 - val_loss: 0.7833 - val_accuracy: 0.8067\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7492 - accuracy: 0.7667 - val_loss: 0.7602 - val_accuracy: 0.7556\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7386 - accuracy: 0.7629 - val_loss: 0.7492 - val_accuracy: 0.7822\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7265 - accuracy: 0.7648 - val_loss: 0.7398 - val_accuracy: 0.7889\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7163 - accuracy: 0.8057 - val_loss: 0.7319 - val_accuracy: 0.8133\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7063 - accuracy: 0.7819 - val_loss: 0.7259 - val_accuracy: 0.6778\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6973 - accuracy: 0.7857 - val_loss: 0.7108 - val_accuracy: 0.7600\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6850 - accuracy: 0.8029 - val_loss: 0.6985 - val_accuracy: 0.8156\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6757 - accuracy: 0.8229 - val_loss: 0.6921 - val_accuracy: 0.7556\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6665 - accuracy: 0.8095 - val_loss: 0.6820 - val_accuracy: 0.8378\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.8371 - val_loss: 0.6696 - val_accuracy: 0.8333\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.8419 - val_loss: 0.6679 - val_accuracy: 0.7222\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6344 - accuracy: 0.8324 - val_loss: 0.6519 - val_accuracy: 0.8533\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6258 - accuracy: 0.8524 - val_loss: 0.6445 - val_accuracy: 0.8511\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6144 - accuracy: 0.8562 - val_loss: 0.6508 - val_accuracy: 0.7756\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.8429 - val_loss: 0.6265 - val_accuracy: 0.8222\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5959 - accuracy: 0.8648 - val_loss: 0.6147 - val_accuracy: 0.8378\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.8562 - val_loss: 0.6015 - val_accuracy: 0.8533\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5766 - accuracy: 0.8581 - val_loss: 0.5927 - val_accuracy: 0.8622\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.8657 - val_loss: 0.5802 - val_accuracy: 0.8511\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5580 - accuracy: 0.8733 - val_loss: 0.5761 - val_accuracy: 0.8667\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5490 - accuracy: 0.8771 - val_loss: 0.5635 - val_accuracy: 0.8600\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5376 - accuracy: 0.8714 - val_loss: 0.5518 - val_accuracy: 0.8489\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5304 - accuracy: 0.8676 - val_loss: 0.5455 - val_accuracy: 0.8622\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5194 - accuracy: 0.8781 - val_loss: 0.5448 - val_accuracy: 0.8267\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5089 - accuracy: 0.8686 - val_loss: 0.5285 - val_accuracy: 0.8644\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5024 - accuracy: 0.8733 - val_loss: 0.5158 - val_accuracy: 0.8511\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.8695 - val_loss: 0.5066 - val_accuracy: 0.8556\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.8686 - val_loss: 0.5004 - val_accuracy: 0.8511\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4741 - accuracy: 0.8724 - val_loss: 0.4936 - val_accuracy: 0.8444\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.8790 - val_loss: 0.4812 - val_accuracy: 0.8578\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8790 - val_loss: 0.4807 - val_accuracy: 0.8444\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8752 - val_loss: 0.4724 - val_accuracy: 0.8667\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8762 - val_loss: 0.4612 - val_accuracy: 0.8467\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4335 - accuracy: 0.8762 - val_loss: 0.4532 - val_accuracy: 0.8556\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8781 - val_loss: 0.4428 - val_accuracy: 0.8622\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4187 - accuracy: 0.8781 - val_loss: 0.4406 - val_accuracy: 0.8689\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4097 - accuracy: 0.8838 - val_loss: 0.4327 - val_accuracy: 0.8600\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4076 - accuracy: 0.8857 - val_loss: 0.4226 - val_accuracy: 0.8533\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4022 - accuracy: 0.8762 - val_loss: 0.4157 - val_accuracy: 0.8711\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3918 - accuracy: 0.8790 - val_loss: 0.4078 - val_accuracy: 0.8622\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8848 - val_loss: 0.4197 - val_accuracy: 0.8800\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3773 - accuracy: 0.8933 - val_loss: 0.4162 - val_accuracy: 0.8556\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3762 - accuracy: 0.8771 - val_loss: 0.3943 - val_accuracy: 0.8533\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3678 - accuracy: 0.8876 - val_loss: 0.3885 - val_accuracy: 0.8622\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3626 - accuracy: 0.8867 - val_loss: 0.3878 - val_accuracy: 0.8756\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.8867 - val_loss: 0.3802 - val_accuracy: 0.8511\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.8867 - val_loss: 0.3792 - val_accuracy: 0.8756\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3465 - accuracy: 0.8838 - val_loss: 0.3876 - val_accuracy: 0.8800\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3456 - accuracy: 0.8857 - val_loss: 0.3656 - val_accuracy: 0.8711\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8857 - val_loss: 0.3644 - val_accuracy: 0.8822\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3345 - accuracy: 0.8886 - val_loss: 0.3472 - val_accuracy: 0.8711\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[146   3   5]\n",
            " [  0 124  21]\n",
            " [  3  26 122]]\n",
            "\n",
            "P-Score: 0.872, R-Score: 0.870, F-Score: 0.871\n",
            "[0.8711111111111111, 0.8715492041587579, 0.8703904605708671, 0.8706548821477735, 0.9689584064584065, 0.8800452232899942, 0.8604952490642098, 0.9031662929375369]\n",
            "Model: \"sequential_38\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_71 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1844 - accuracy: 0.3295 - val_loss: 1.0916 - val_accuracy: 0.3422\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0803 - accuracy: 0.3676 - val_loss: 1.0712 - val_accuracy: 0.7333\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0653 - accuracy: 0.5429 - val_loss: 1.0606 - val_accuracy: 0.7867\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0572 - accuracy: 0.6124 - val_loss: 1.0550 - val_accuracy: 0.7111\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0502 - accuracy: 0.6933 - val_loss: 1.0469 - val_accuracy: 0.7289\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0418 - accuracy: 0.7019 - val_loss: 1.0405 - val_accuracy: 0.6622\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0334 - accuracy: 0.7629 - val_loss: 1.0298 - val_accuracy: 0.8000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0218 - accuracy: 0.7714 - val_loss: 1.0188 - val_accuracy: 0.7311\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0070 - accuracy: 0.7419 - val_loss: 1.0034 - val_accuracy: 0.6400\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9874 - accuracy: 0.7676 - val_loss: 0.9838 - val_accuracy: 0.5667\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9629 - accuracy: 0.6733 - val_loss: 0.9653 - val_accuracy: 0.7956\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9447 - accuracy: 0.7143 - val_loss: 0.9417 - val_accuracy: 0.8178\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9251 - accuracy: 0.7438 - val_loss: 0.9227 - val_accuracy: 0.7333\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9043 - accuracy: 0.7857 - val_loss: 0.9062 - val_accuracy: 0.6578\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8855 - accuracy: 0.7781 - val_loss: 0.8870 - val_accuracy: 0.7267\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8655 - accuracy: 0.7886 - val_loss: 0.8657 - val_accuracy: 0.8400\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8336 - accuracy: 0.8410 - val_loss: 0.8324 - val_accuracy: 0.8600\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8101 - accuracy: 0.8457 - val_loss: 0.8141 - val_accuracy: 0.8533\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7873 - accuracy: 0.8390 - val_loss: 0.7966 - val_accuracy: 0.8578\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7671 - accuracy: 0.8486 - val_loss: 0.7693 - val_accuracy: 0.8511\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7465 - accuracy: 0.8400 - val_loss: 0.7565 - val_accuracy: 0.8556\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7257 - accuracy: 0.8581 - val_loss: 0.7436 - val_accuracy: 0.7533\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7061 - accuracy: 0.8476 - val_loss: 0.7060 - val_accuracy: 0.8378\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6798 - accuracy: 0.8590 - val_loss: 0.6908 - val_accuracy: 0.8644\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6597 - accuracy: 0.8667 - val_loss: 0.6763 - val_accuracy: 0.8733\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.8638 - val_loss: 0.6504 - val_accuracy: 0.8400\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6251 - accuracy: 0.8552 - val_loss: 0.6428 - val_accuracy: 0.8622\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6082 - accuracy: 0.8724 - val_loss: 0.6203 - val_accuracy: 0.8467\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5909 - accuracy: 0.8667 - val_loss: 0.6059 - val_accuracy: 0.8533\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5780 - accuracy: 0.8600 - val_loss: 0.5833 - val_accuracy: 0.8667\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5595 - accuracy: 0.8705 - val_loss: 0.5883 - val_accuracy: 0.8733\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5488 - accuracy: 0.8667 - val_loss: 0.5553 - val_accuracy: 0.8689\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5326 - accuracy: 0.8648 - val_loss: 0.5411 - val_accuracy: 0.8644\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5183 - accuracy: 0.8705 - val_loss: 0.5388 - val_accuracy: 0.8422\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5064 - accuracy: 0.8676 - val_loss: 0.5200 - val_accuracy: 0.8556\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4919 - accuracy: 0.8752 - val_loss: 0.5066 - val_accuracy: 0.8578\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4785 - accuracy: 0.8743 - val_loss: 0.4895 - val_accuracy: 0.8689\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4688 - accuracy: 0.8752 - val_loss: 0.4875 - val_accuracy: 0.8511\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.8857 - val_loss: 0.4705 - val_accuracy: 0.8778\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8781 - val_loss: 0.4647 - val_accuracy: 0.8711\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8733 - val_loss: 0.4473 - val_accuracy: 0.8756\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8848 - val_loss: 0.4495 - val_accuracy: 0.8467\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4103 - accuracy: 0.8886 - val_loss: 0.4269 - val_accuracy: 0.8822\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4038 - accuracy: 0.8819 - val_loss: 0.4174 - val_accuracy: 0.8822\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3931 - accuracy: 0.8848 - val_loss: 0.4094 - val_accuracy: 0.8800\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.3836 - accuracy: 0.8867 - val_loss: 0.4004 - val_accuracy: 0.8711\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3760 - accuracy: 0.8829 - val_loss: 0.3875 - val_accuracy: 0.8733\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.3655 - accuracy: 0.8886 - val_loss: 0.4006 - val_accuracy: 0.8556\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.3606 - accuracy: 0.8914 - val_loss: 0.3831 - val_accuracy: 0.8689\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 14ms/step - loss: 0.3498 - accuracy: 0.8876 - val_loss: 0.3702 - val_accuracy: 0.8800\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 12ms/step - loss: 0.3490 - accuracy: 0.8848 - val_loss: 0.3590 - val_accuracy: 0.8867\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.3373 - accuracy: 0.8933 - val_loss: 0.3546 - val_accuracy: 0.8889\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.3321 - accuracy: 0.8905 - val_loss: 0.3481 - val_accuracy: 0.8867\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3249 - accuracy: 0.8829 - val_loss: 0.3420 - val_accuracy: 0.8844\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3209 - accuracy: 0.8914 - val_loss: 0.3613 - val_accuracy: 0.8622\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3176 - accuracy: 0.8905 - val_loss: 0.3307 - val_accuracy: 0.8800\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3089 - accuracy: 0.8990 - val_loss: 0.3331 - val_accuracy: 0.8800\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3030 - accuracy: 0.8981 - val_loss: 0.3266 - val_accuracy: 0.8711\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2983 - accuracy: 0.8990 - val_loss: 0.3462 - val_accuracy: 0.8600\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2959 - accuracy: 0.8914 - val_loss: 0.3063 - val_accuracy: 0.8889\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2901 - accuracy: 0.9000 - val_loss: 0.3027 - val_accuracy: 0.8889\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2880 - accuracy: 0.8962 - val_loss: 0.3100 - val_accuracy: 0.8889\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2854 - accuracy: 0.8924 - val_loss: 0.2974 - val_accuracy: 0.8889\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2789 - accuracy: 0.9000 - val_loss: 0.3044 - val_accuracy: 0.8956\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.9000 - val_loss: 0.3000 - val_accuracy: 0.8889\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.8962 - val_loss: 0.2967 - val_accuracy: 0.8956\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2684 - accuracy: 0.9105 - val_loss: 0.2844 - val_accuracy: 0.8889\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2656 - accuracy: 0.9038 - val_loss: 0.3019 - val_accuracy: 0.8844\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2674 - accuracy: 0.9010 - val_loss: 0.2891 - val_accuracy: 0.8889\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2607 - accuracy: 0.9057 - val_loss: 0.2742 - val_accuracy: 0.8978\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2566 - accuracy: 0.9076 - val_loss: 0.2969 - val_accuracy: 0.8733\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2539 - accuracy: 0.9105 - val_loss: 0.2681 - val_accuracy: 0.8933\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2514 - accuracy: 0.9057 - val_loss: 0.2732 - val_accuracy: 0.8956\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2515 - accuracy: 0.9086 - val_loss: 0.2619 - val_accuracy: 0.9000\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2474 - accuracy: 0.9086 - val_loss: 0.2591 - val_accuracy: 0.8956\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2466 - accuracy: 0.9067 - val_loss: 0.2597 - val_accuracy: 0.8933\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2429 - accuracy: 0.9114 - val_loss: 0.2765 - val_accuracy: 0.8733\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2398 - accuracy: 0.9038 - val_loss: 0.2665 - val_accuracy: 0.8867\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2385 - accuracy: 0.9095 - val_loss: 0.2631 - val_accuracy: 0.8978\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2384 - accuracy: 0.9133 - val_loss: 0.2727 - val_accuracy: 0.8889\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[141   4   9]\n",
            " [  0 133  12]\n",
            " [  1  24 126]]\n",
            "\n",
            "P-Score: 0.892, R-Score: 0.889, F-Score: 0.889\n",
            "[0.8888888888888888, 0.8920625200478232, 0.8890876269958253, 0.889207110782318, 0.9561030186030186, 0.9127190503109102, 0.8821014861901704, 0.916974518368033]\n",
            "Model: \"sequential_39\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_74 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_75 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_76 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1147 - accuracy: 0.3305 - val_loss: 1.0990 - val_accuracy: 0.2711\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0958 - accuracy: 0.3086 - val_loss: 1.0912 - val_accuracy: 0.2911\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0875 - accuracy: 0.3381 - val_loss: 1.0844 - val_accuracy: 0.4089\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0809 - accuracy: 0.4143 - val_loss: 1.0803 - val_accuracy: 0.3267\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0715 - accuracy: 0.3857 - val_loss: 1.0730 - val_accuracy: 0.4178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0659 - accuracy: 0.5019 - val_loss: 1.0628 - val_accuracy: 0.5044\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0564 - accuracy: 0.5400 - val_loss: 1.0558 - val_accuracy: 0.4644\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0406 - accuracy: 0.5390 - val_loss: 1.0408 - val_accuracy: 0.4533\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0272 - accuracy: 0.5390 - val_loss: 1.0306 - val_accuracy: 0.4800\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0150 - accuracy: 0.5705 - val_loss: 1.0156 - val_accuracy: 0.5556\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0043 - accuracy: 0.5886 - val_loss: 1.0051 - val_accuracy: 0.6356\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9923 - accuracy: 0.5790 - val_loss: 0.9950 - val_accuracy: 0.6889\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9805 - accuracy: 0.6057 - val_loss: 0.9811 - val_accuracy: 0.5689\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9670 - accuracy: 0.6133 - val_loss: 0.9734 - val_accuracy: 0.5356\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9543 - accuracy: 0.5981 - val_loss: 0.9577 - val_accuracy: 0.6733\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9418 - accuracy: 0.6076 - val_loss: 0.9437 - val_accuracy: 0.6467\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9282 - accuracy: 0.6352 - val_loss: 0.9313 - val_accuracy: 0.5911\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9131 - accuracy: 0.6086 - val_loss: 0.9172 - val_accuracy: 0.6467\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8992 - accuracy: 0.6333 - val_loss: 0.9109 - val_accuracy: 0.5489\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8843 - accuracy: 0.6162 - val_loss: 0.8908 - val_accuracy: 0.5844\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8691 - accuracy: 0.6067 - val_loss: 0.8745 - val_accuracy: 0.5800\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8556 - accuracy: 0.6238 - val_loss: 0.8649 - val_accuracy: 0.5733\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8419 - accuracy: 0.6267 - val_loss: 0.8534 - val_accuracy: 0.5733\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8287 - accuracy: 0.6171 - val_loss: 0.8376 - val_accuracy: 0.6222\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8164 - accuracy: 0.6543 - val_loss: 0.8258 - val_accuracy: 0.6333\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8039 - accuracy: 0.6495 - val_loss: 0.8137 - val_accuracy: 0.6822\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7941 - accuracy: 0.6705 - val_loss: 0.8044 - val_accuracy: 0.6422\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7841 - accuracy: 0.6771 - val_loss: 0.7936 - val_accuracy: 0.6956\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7713 - accuracy: 0.6943 - val_loss: 0.7911 - val_accuracy: 0.6422\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7651 - accuracy: 0.6924 - val_loss: 0.7751 - val_accuracy: 0.6956\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7551 - accuracy: 0.6933 - val_loss: 0.7667 - val_accuracy: 0.7156\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.7133 - val_loss: 0.7615 - val_accuracy: 0.7378\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7369 - accuracy: 0.7124 - val_loss: 0.7628 - val_accuracy: 0.6578\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7299 - accuracy: 0.7152 - val_loss: 0.7445 - val_accuracy: 0.7578\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7227 - accuracy: 0.7257 - val_loss: 0.7348 - val_accuracy: 0.7378\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7168 - accuracy: 0.7333 - val_loss: 0.7319 - val_accuracy: 0.7333\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7095 - accuracy: 0.7333 - val_loss: 0.7224 - val_accuracy: 0.7556\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6982 - accuracy: 0.7495 - val_loss: 0.7151 - val_accuracy: 0.7578\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6952 - accuracy: 0.7438 - val_loss: 0.7087 - val_accuracy: 0.7756\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.7571 - val_loss: 0.7032 - val_accuracy: 0.7533\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6814 - accuracy: 0.7657 - val_loss: 0.6943 - val_accuracy: 0.7822\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.7562 - val_loss: 0.6904 - val_accuracy: 0.7800\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6670 - accuracy: 0.7724 - val_loss: 0.6822 - val_accuracy: 0.7911\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6633 - accuracy: 0.7810 - val_loss: 0.6801 - val_accuracy: 0.7933\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6569 - accuracy: 0.7762 - val_loss: 0.6703 - val_accuracy: 0.7978\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6469 - accuracy: 0.7838 - val_loss: 0.6631 - val_accuracy: 0.8089\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6419 - accuracy: 0.7981 - val_loss: 0.6550 - val_accuracy: 0.7889\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6330 - accuracy: 0.8019 - val_loss: 0.6470 - val_accuracy: 0.8022\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6289 - accuracy: 0.8095 - val_loss: 0.6489 - val_accuracy: 0.8000\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.8057 - val_loss: 0.6385 - val_accuracy: 0.8022\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.8190 - val_loss: 0.6450 - val_accuracy: 0.8022\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6085 - accuracy: 0.8238 - val_loss: 0.6203 - val_accuracy: 0.8311\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6000 - accuracy: 0.8152 - val_loss: 0.6145 - val_accuracy: 0.8089\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5915 - accuracy: 0.8229 - val_loss: 0.6024 - val_accuracy: 0.8267\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5814 - accuracy: 0.8286 - val_loss: 0.5996 - val_accuracy: 0.8133\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5759 - accuracy: 0.8343 - val_loss: 0.5916 - val_accuracy: 0.8244\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5670 - accuracy: 0.8362 - val_loss: 0.5853 - val_accuracy: 0.8289\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5579 - accuracy: 0.8371 - val_loss: 0.5912 - val_accuracy: 0.8333\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5526 - accuracy: 0.8410 - val_loss: 0.5765 - val_accuracy: 0.8400\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5446 - accuracy: 0.8457 - val_loss: 0.5687 - val_accuracy: 0.8133\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5403 - accuracy: 0.8371 - val_loss: 0.5497 - val_accuracy: 0.8511\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5311 - accuracy: 0.8495 - val_loss: 0.5425 - val_accuracy: 0.8556\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.8581 - val_loss: 0.5412 - val_accuracy: 0.8400\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5139 - accuracy: 0.8476 - val_loss: 0.5372 - val_accuracy: 0.8489\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5053 - accuracy: 0.8448 - val_loss: 0.5183 - val_accuracy: 0.8400\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.8533 - val_loss: 0.5113 - val_accuracy: 0.8467\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.8600 - val_loss: 0.5031 - val_accuracy: 0.8489\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4825 - accuracy: 0.8590 - val_loss: 0.4949 - val_accuracy: 0.8533\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4763 - accuracy: 0.8590 - val_loss: 0.4854 - val_accuracy: 0.8556\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.8571 - val_loss: 0.4805 - val_accuracy: 0.8489\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4600 - accuracy: 0.8638 - val_loss: 0.4715 - val_accuracy: 0.8600\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8657 - val_loss: 0.4647 - val_accuracy: 0.8600\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8667 - val_loss: 0.4692 - val_accuracy: 0.8622\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4389 - accuracy: 0.8600 - val_loss: 0.4522 - val_accuracy: 0.8578\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4314 - accuracy: 0.8714 - val_loss: 0.4463 - val_accuracy: 0.8689\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8743 - val_loss: 0.4365 - val_accuracy: 0.8667\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4165 - accuracy: 0.8714 - val_loss: 0.4336 - val_accuracy: 0.8711\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4111 - accuracy: 0.8724 - val_loss: 0.4299 - val_accuracy: 0.8578\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4018 - accuracy: 0.8724 - val_loss: 0.4195 - val_accuracy: 0.8533\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3957 - accuracy: 0.8790 - val_loss: 0.4092 - val_accuracy: 0.8622\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[137   9   8]\n",
            " [  0 128  17]\n",
            " [  8  20 123]]\n",
            "\n",
            "P-Score: 0.864, R-Score: 0.862, F-Score: 0.862\n",
            "[0.8622222222222222, 0.8637317638305998, 0.8623128489079619, 0.8622708513293023, 0.9312916812916813, 0.8938383267382701, 0.865478748145031, 0.8968695853916607]\n",
            "Model: \"sequential_40\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_77 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_78 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_79 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.0837 - accuracy: 0.4295 - val_loss: 1.0716 - val_accuracy: 0.5733\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0635 - accuracy: 0.5362 - val_loss: 1.0587 - val_accuracy: 0.7022\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0509 - accuracy: 0.6629 - val_loss: 1.0475 - val_accuracy: 0.6200\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0378 - accuracy: 0.6067 - val_loss: 1.0385 - val_accuracy: 0.6311\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0274 - accuracy: 0.6505 - val_loss: 1.0288 - val_accuracy: 0.5111\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0164 - accuracy: 0.6457 - val_loss: 1.0144 - val_accuracy: 0.6733\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0032 - accuracy: 0.6705 - val_loss: 1.0035 - val_accuracy: 0.6800\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9910 - accuracy: 0.6524 - val_loss: 0.9901 - val_accuracy: 0.6311\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9759 - accuracy: 0.6533 - val_loss: 0.9774 - val_accuracy: 0.5733\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9603 - accuracy: 0.6143 - val_loss: 0.9608 - val_accuracy: 0.6600\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9452 - accuracy: 0.6343 - val_loss: 0.9471 - val_accuracy: 0.5956\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9292 - accuracy: 0.6286 - val_loss: 0.9325 - val_accuracy: 0.6400\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9144 - accuracy: 0.6267 - val_loss: 0.9180 - val_accuracy: 0.6378\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9001 - accuracy: 0.6219 - val_loss: 0.9043 - val_accuracy: 0.6689\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8851 - accuracy: 0.6324 - val_loss: 0.8928 - val_accuracy: 0.6822\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8724 - accuracy: 0.6543 - val_loss: 0.8874 - val_accuracy: 0.5822\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8599 - accuracy: 0.6219 - val_loss: 0.8660 - val_accuracy: 0.6978\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8477 - accuracy: 0.6467 - val_loss: 0.8550 - val_accuracy: 0.6333\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8338 - accuracy: 0.6600 - val_loss: 0.8431 - val_accuracy: 0.6267\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8219 - accuracy: 0.6400 - val_loss: 0.8283 - val_accuracy: 0.6822\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8067 - accuracy: 0.6524 - val_loss: 0.8143 - val_accuracy: 0.7000\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7915 - accuracy: 0.6829 - val_loss: 0.8046 - val_accuracy: 0.6289\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7791 - accuracy: 0.6533 - val_loss: 0.7906 - val_accuracy: 0.6578\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7682 - accuracy: 0.6610 - val_loss: 0.7791 - val_accuracy: 0.6844\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7598 - accuracy: 0.6752 - val_loss: 0.7727 - val_accuracy: 0.6578\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7497 - accuracy: 0.6762 - val_loss: 0.7762 - val_accuracy: 0.6222\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7421 - accuracy: 0.6686 - val_loss: 0.7525 - val_accuracy: 0.7089\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.6657 - val_loss: 0.7513 - val_accuracy: 0.6533\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7273 - accuracy: 0.6733 - val_loss: 0.7406 - val_accuracy: 0.6844\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7227 - accuracy: 0.6819 - val_loss: 0.7344 - val_accuracy: 0.7267\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7167 - accuracy: 0.6819 - val_loss: 0.7293 - val_accuracy: 0.6978\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7116 - accuracy: 0.6857 - val_loss: 0.7263 - val_accuracy: 0.6933\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7072 - accuracy: 0.6867 - val_loss: 0.7187 - val_accuracy: 0.7422\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7041 - accuracy: 0.6810 - val_loss: 0.7133 - val_accuracy: 0.7467\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6986 - accuracy: 0.7095 - val_loss: 0.7094 - val_accuracy: 0.7400\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.7057 - val_loss: 0.7249 - val_accuracy: 0.6733\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6943 - accuracy: 0.7038 - val_loss: 0.7012 - val_accuracy: 0.7578\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6889 - accuracy: 0.7162 - val_loss: 0.7024 - val_accuracy: 0.7133\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6839 - accuracy: 0.7057 - val_loss: 0.6959 - val_accuracy: 0.7467\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6798 - accuracy: 0.7143 - val_loss: 0.7050 - val_accuracy: 0.6978\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6748 - accuracy: 0.7248 - val_loss: 0.6860 - val_accuracy: 0.7400\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6715 - accuracy: 0.7257 - val_loss: 0.7049 - val_accuracy: 0.6978\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6655 - accuracy: 0.7352 - val_loss: 0.6775 - val_accuracy: 0.7400\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.7324 - val_loss: 0.6807 - val_accuracy: 0.7378\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6588 - accuracy: 0.7381 - val_loss: 0.6699 - val_accuracy: 0.7667\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6514 - accuracy: 0.7400 - val_loss: 0.6600 - val_accuracy: 0.7800\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6459 - accuracy: 0.7581 - val_loss: 0.6566 - val_accuracy: 0.7733\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.7476 - val_loss: 0.6563 - val_accuracy: 0.7533\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6371 - accuracy: 0.7543 - val_loss: 0.6435 - val_accuracy: 0.7778\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6293 - accuracy: 0.7752 - val_loss: 0.6410 - val_accuracy: 0.7800\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6268 - accuracy: 0.7743 - val_loss: 0.6341 - val_accuracy: 0.7844\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.7752 - val_loss: 0.6245 - val_accuracy: 0.7978\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6095 - accuracy: 0.7876 - val_loss: 0.6221 - val_accuracy: 0.7867\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.7867 - val_loss: 0.6120 - val_accuracy: 0.8000\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5967 - accuracy: 0.7905 - val_loss: 0.6039 - val_accuracy: 0.8089\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5921 - accuracy: 0.7952 - val_loss: 0.6069 - val_accuracy: 0.8022\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5831 - accuracy: 0.7981 - val_loss: 0.5971 - val_accuracy: 0.8089\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5779 - accuracy: 0.8057 - val_loss: 0.5910 - val_accuracy: 0.8133\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5687 - accuracy: 0.7981 - val_loss: 0.5763 - val_accuracy: 0.8178\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5646 - accuracy: 0.8143 - val_loss: 0.5798 - val_accuracy: 0.8111\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5570 - accuracy: 0.8181 - val_loss: 0.5723 - val_accuracy: 0.8089\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5484 - accuracy: 0.8190 - val_loss: 0.5571 - val_accuracy: 0.8289\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.8305 - val_loss: 0.5469 - val_accuracy: 0.8267\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5340 - accuracy: 0.8190 - val_loss: 0.5569 - val_accuracy: 0.8133\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5253 - accuracy: 0.8305 - val_loss: 0.5342 - val_accuracy: 0.8378\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.8267 - val_loss: 0.5290 - val_accuracy: 0.8356\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5121 - accuracy: 0.8352 - val_loss: 0.5183 - val_accuracy: 0.8333\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5002 - accuracy: 0.8390 - val_loss: 0.5179 - val_accuracy: 0.8400\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4981 - accuracy: 0.8410 - val_loss: 0.5066 - val_accuracy: 0.8422\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.8400 - val_loss: 0.4960 - val_accuracy: 0.8444\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4819 - accuracy: 0.8410 - val_loss: 0.4960 - val_accuracy: 0.8511\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4702 - accuracy: 0.8467 - val_loss: 0.5176 - val_accuracy: 0.8222\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.8476 - val_loss: 0.4870 - val_accuracy: 0.8578\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4597 - accuracy: 0.8514 - val_loss: 0.4738 - val_accuracy: 0.8444\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.8533 - val_loss: 0.4689 - val_accuracy: 0.8400\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4477 - accuracy: 0.8543 - val_loss: 0.4727 - val_accuracy: 0.8578\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4398 - accuracy: 0.8600 - val_loss: 0.4487 - val_accuracy: 0.8467\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4345 - accuracy: 0.8562 - val_loss: 0.4458 - val_accuracy: 0.8556\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4284 - accuracy: 0.8571 - val_loss: 0.4432 - val_accuracy: 0.8622\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4222 - accuracy: 0.8648 - val_loss: 0.4561 - val_accuracy: 0.8400\n",
            "15/15 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[123  23   8]\n",
            " [  0 137   8]\n",
            " [  6  27 118]]\n",
            "\n",
            "P-Score: 0.856, R-Score: 0.842, F-Score: 0.841\n",
            "[0.84, 0.8555685692913372, 0.8416619461835264, 0.8408764435959696, 0.8892155142155143, 0.8904465799886941, 0.8639726239783827, 0.8812115727275304]\n",
            "Model: \"sequential_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_80 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_81 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_82 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 13ms/step - loss: 1.0993 - accuracy: 0.3352 - val_loss: 1.0912 - val_accuracy: 0.4533\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0873 - accuracy: 0.4171 - val_loss: 1.0808 - val_accuracy: 0.4800\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0751 - accuracy: 0.4819 - val_loss: 1.0694 - val_accuracy: 0.5400\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0630 - accuracy: 0.4952 - val_loss: 1.0579 - val_accuracy: 0.6156\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0507 - accuracy: 0.5143 - val_loss: 1.0462 - val_accuracy: 0.6178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0379 - accuracy: 0.5667 - val_loss: 1.0342 - val_accuracy: 0.5978\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0245 - accuracy: 0.5619 - val_loss: 1.0220 - val_accuracy: 0.6222\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0097 - accuracy: 0.5981 - val_loss: 1.0078 - val_accuracy: 0.6178\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9951 - accuracy: 0.6162 - val_loss: 0.9932 - val_accuracy: 0.5800\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9796 - accuracy: 0.5905 - val_loss: 0.9808 - val_accuracy: 0.6133\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9635 - accuracy: 0.5914 - val_loss: 0.9672 - val_accuracy: 0.6022\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9497 - accuracy: 0.6238 - val_loss: 0.9524 - val_accuracy: 0.5511\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9338 - accuracy: 0.5933 - val_loss: 0.9379 - val_accuracy: 0.5511\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9184 - accuracy: 0.5943 - val_loss: 0.9207 - val_accuracy: 0.6067\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9029 - accuracy: 0.6029 - val_loss: 0.9059 - val_accuracy: 0.5911\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8877 - accuracy: 0.6257 - val_loss: 0.8964 - val_accuracy: 0.5467\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8737 - accuracy: 0.6219 - val_loss: 0.8834 - val_accuracy: 0.5644\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8621 - accuracy: 0.6619 - val_loss: 0.8693 - val_accuracy: 0.5489\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8494 - accuracy: 0.6190 - val_loss: 0.8560 - val_accuracy: 0.5600\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8365 - accuracy: 0.6171 - val_loss: 0.8449 - val_accuracy: 0.5711\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8261 - accuracy: 0.6133 - val_loss: 0.8357 - val_accuracy: 0.5622\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8149 - accuracy: 0.6086 - val_loss: 0.8247 - val_accuracy: 0.6556\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8045 - accuracy: 0.6448 - val_loss: 0.8152 - val_accuracy: 0.6356\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7941 - accuracy: 0.6324 - val_loss: 0.8133 - val_accuracy: 0.6111\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7898 - accuracy: 0.6819 - val_loss: 0.8023 - val_accuracy: 0.5756\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7816 - accuracy: 0.5990 - val_loss: 0.7944 - val_accuracy: 0.7067\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7742 - accuracy: 0.6800 - val_loss: 0.7948 - val_accuracy: 0.5600\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7697 - accuracy: 0.6219 - val_loss: 0.7846 - val_accuracy: 0.7089\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.6581 - val_loss: 0.7794 - val_accuracy: 0.7289\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7578 - accuracy: 0.6790 - val_loss: 0.7752 - val_accuracy: 0.6422\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7537 - accuracy: 0.6495 - val_loss: 0.7753 - val_accuracy: 0.6956\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7479 - accuracy: 0.6819 - val_loss: 0.7644 - val_accuracy: 0.6800\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7474 - accuracy: 0.6886 - val_loss: 0.7618 - val_accuracy: 0.6422\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7449 - accuracy: 0.6543 - val_loss: 0.7589 - val_accuracy: 0.7044\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7417 - accuracy: 0.6848 - val_loss: 0.7565 - val_accuracy: 0.7000\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7392 - accuracy: 0.6629 - val_loss: 0.7578 - val_accuracy: 0.7022\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7374 - accuracy: 0.6838 - val_loss: 0.7518 - val_accuracy: 0.7089\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7338 - accuracy: 0.6705 - val_loss: 0.7539 - val_accuracy: 0.7356\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7349 - accuracy: 0.6952 - val_loss: 0.7508 - val_accuracy: 0.6889\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7299 - accuracy: 0.6714 - val_loss: 0.7480 - val_accuracy: 0.7422\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7293 - accuracy: 0.7000 - val_loss: 0.7499 - val_accuracy: 0.7000\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7276 - accuracy: 0.6800 - val_loss: 0.7469 - val_accuracy: 0.7089\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7289 - accuracy: 0.6971 - val_loss: 0.7439 - val_accuracy: 0.7178\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7242 - accuracy: 0.6867 - val_loss: 0.7410 - val_accuracy: 0.7111\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7242 - accuracy: 0.6790 - val_loss: 0.7652 - val_accuracy: 0.6756\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7206 - accuracy: 0.6962 - val_loss: 0.7432 - val_accuracy: 0.7133\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7231 - accuracy: 0.6952 - val_loss: 0.7414 - val_accuracy: 0.6956\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.7010 - val_loss: 0.7421 - val_accuracy: 0.6733\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7206 - accuracy: 0.6905 - val_loss: 0.7368 - val_accuracy: 0.6756\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7201 - accuracy: 0.6790 - val_loss: 0.7331 - val_accuracy: 0.7533\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7170 - accuracy: 0.7114 - val_loss: 0.7507 - val_accuracy: 0.6267\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7138 - accuracy: 0.6876 - val_loss: 0.7303 - val_accuracy: 0.7556\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7142 - accuracy: 0.7200 - val_loss: 0.7341 - val_accuracy: 0.6867\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7127 - accuracy: 0.6971 - val_loss: 0.7354 - val_accuracy: 0.6667\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7118 - accuracy: 0.6981 - val_loss: 0.7285 - val_accuracy: 0.7711\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7138 - accuracy: 0.7200 - val_loss: 0.7333 - val_accuracy: 0.6911\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7086 - accuracy: 0.6981 - val_loss: 0.7272 - val_accuracy: 0.7444\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7092 - accuracy: 0.7200 - val_loss: 0.7240 - val_accuracy: 0.7689\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.7314 - val_loss: 0.7354 - val_accuracy: 0.6889\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7050 - accuracy: 0.7286 - val_loss: 0.7368 - val_accuracy: 0.6667\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.7219 - val_loss: 0.7186 - val_accuracy: 0.7444\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7018 - accuracy: 0.7248 - val_loss: 0.7231 - val_accuracy: 0.7067\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7008 - accuracy: 0.7210 - val_loss: 0.7131 - val_accuracy: 0.7622\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6974 - accuracy: 0.7257 - val_loss: 0.7117 - val_accuracy: 0.7756\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6966 - accuracy: 0.7390 - val_loss: 0.7127 - val_accuracy: 0.7733\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6955 - accuracy: 0.7486 - val_loss: 0.7120 - val_accuracy: 0.7156\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6922 - accuracy: 0.7305 - val_loss: 0.7262 - val_accuracy: 0.7000\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.7390 - val_loss: 0.7129 - val_accuracy: 0.7556\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6898 - accuracy: 0.7533 - val_loss: 0.7007 - val_accuracy: 0.7756\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6847 - accuracy: 0.7486 - val_loss: 0.7032 - val_accuracy: 0.7689\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6858 - accuracy: 0.7524 - val_loss: 0.6963 - val_accuracy: 0.7889\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6811 - accuracy: 0.7438 - val_loss: 0.6941 - val_accuracy: 0.7911\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6816 - accuracy: 0.7657 - val_loss: 0.6908 - val_accuracy: 0.7778\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6801 - accuracy: 0.7648 - val_loss: 0.6953 - val_accuracy: 0.7467\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6738 - accuracy: 0.7457 - val_loss: 0.6941 - val_accuracy: 0.7844\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6735 - accuracy: 0.7600 - val_loss: 0.6817 - val_accuracy: 0.7800\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6683 - accuracy: 0.7571 - val_loss: 0.6734 - val_accuracy: 0.7756\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.7629 - val_loss: 0.6687 - val_accuracy: 0.7711\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6492 - accuracy: 0.7762 - val_loss: 0.6595 - val_accuracy: 0.8044\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.7829 - val_loss: 0.6611 - val_accuracy: 0.8089\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[132  13   9]\n",
            " [ 13 115  17]\n",
            " [ 24  10 117]]\n",
            "\n",
            "P-Score: 0.811, R-Score: 0.808, F-Score: 0.809\n",
            "[0.8088888888888889, 0.8108600800908494, 0.808360247501604, 0.8086588922345951, 0.8660714285714286, 0.8588468061051442, 0.8439389576734811, 0.8562857307833514]\n",
            "Model: \"sequential_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_83 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_84 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_85 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1289 - accuracy: 0.3381 - val_loss: 1.1102 - val_accuracy: 0.3222\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1035 - accuracy: 0.3390 - val_loss: 1.0998 - val_accuracy: 0.3244\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0932 - accuracy: 0.3581 - val_loss: 1.0932 - val_accuracy: 0.3244\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0826 - accuracy: 0.4181 - val_loss: 1.0812 - val_accuracy: 0.4244\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0757 - accuracy: 0.4743 - val_loss: 1.0737 - val_accuracy: 0.4489\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0678 - accuracy: 0.5238 - val_loss: 1.0669 - val_accuracy: 0.4933\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0602 - accuracy: 0.5410 - val_loss: 1.0591 - val_accuracy: 0.6711\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0517 - accuracy: 0.5914 - val_loss: 1.0539 - val_accuracy: 0.4422\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0430 - accuracy: 0.5933 - val_loss: 1.0430 - val_accuracy: 0.5400\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0328 - accuracy: 0.5914 - val_loss: 1.0321 - val_accuracy: 0.7178\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0224 - accuracy: 0.6410 - val_loss: 1.0226 - val_accuracy: 0.7356\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0130 - accuracy: 0.6752 - val_loss: 1.0123 - val_accuracy: 0.7200\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0026 - accuracy: 0.6743 - val_loss: 1.0053 - val_accuracy: 0.6156\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9912 - accuracy: 0.6657 - val_loss: 0.9953 - val_accuracy: 0.6000\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9807 - accuracy: 0.6848 - val_loss: 0.9852 - val_accuracy: 0.6000\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9689 - accuracy: 0.6771 - val_loss: 0.9708 - val_accuracy: 0.7000\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9556 - accuracy: 0.7276 - val_loss: 0.9551 - val_accuracy: 0.7644\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9410 - accuracy: 0.7295 - val_loss: 0.9417 - val_accuracy: 0.7533\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9263 - accuracy: 0.7333 - val_loss: 0.9295 - val_accuracy: 0.7178\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9113 - accuracy: 0.7276 - val_loss: 0.9180 - val_accuracy: 0.6756\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8972 - accuracy: 0.7181 - val_loss: 0.8984 - val_accuracy: 0.7578\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8825 - accuracy: 0.7343 - val_loss: 0.8870 - val_accuracy: 0.7422\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8695 - accuracy: 0.7286 - val_loss: 0.8727 - val_accuracy: 0.7511\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8547 - accuracy: 0.7343 - val_loss: 0.8586 - val_accuracy: 0.7622\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8406 - accuracy: 0.7343 - val_loss: 0.8461 - val_accuracy: 0.7444\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8285 - accuracy: 0.7390 - val_loss: 0.8362 - val_accuracy: 0.7400\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8129 - accuracy: 0.7305 - val_loss: 0.8291 - val_accuracy: 0.7089\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8020 - accuracy: 0.7390 - val_loss: 0.8102 - val_accuracy: 0.7578\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7902 - accuracy: 0.7495 - val_loss: 0.7980 - val_accuracy: 0.7422\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7768 - accuracy: 0.7429 - val_loss: 0.7907 - val_accuracy: 0.7356\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7676 - accuracy: 0.7438 - val_loss: 0.7746 - val_accuracy: 0.7689\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7563 - accuracy: 0.7438 - val_loss: 0.7679 - val_accuracy: 0.7489\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7471 - accuracy: 0.7438 - val_loss: 0.7686 - val_accuracy: 0.7400\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7373 - accuracy: 0.7533 - val_loss: 0.7491 - val_accuracy: 0.7533\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7289 - accuracy: 0.7590 - val_loss: 0.7359 - val_accuracy: 0.7622\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7172 - accuracy: 0.7629 - val_loss: 0.7433 - val_accuracy: 0.7422\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7099 - accuracy: 0.7600 - val_loss: 0.7221 - val_accuracy: 0.7733\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7009 - accuracy: 0.7524 - val_loss: 0.7100 - val_accuracy: 0.7667\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6934 - accuracy: 0.7571 - val_loss: 0.7027 - val_accuracy: 0.7667\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6859 - accuracy: 0.7629 - val_loss: 0.7000 - val_accuracy: 0.7778\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6808 - accuracy: 0.7619 - val_loss: 0.6987 - val_accuracy: 0.7756\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6721 - accuracy: 0.7638 - val_loss: 0.6872 - val_accuracy: 0.7778\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6650 - accuracy: 0.7771 - val_loss: 0.6776 - val_accuracy: 0.7933\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6574 - accuracy: 0.7724 - val_loss: 0.6733 - val_accuracy: 0.7867\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6547 - accuracy: 0.7771 - val_loss: 0.6678 - val_accuracy: 0.7800\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6469 - accuracy: 0.7762 - val_loss: 0.6568 - val_accuracy: 0.7956\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6388 - accuracy: 0.7714 - val_loss: 0.6501 - val_accuracy: 0.7800\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.7781 - val_loss: 0.6459 - val_accuracy: 0.7667\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6248 - accuracy: 0.7810 - val_loss: 0.6365 - val_accuracy: 0.7800\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6202 - accuracy: 0.7933 - val_loss: 0.6287 - val_accuracy: 0.7956\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.7924 - val_loss: 0.6242 - val_accuracy: 0.7889\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6104 - accuracy: 0.7857 - val_loss: 0.6157 - val_accuracy: 0.8089\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5992 - accuracy: 0.7914 - val_loss: 0.6166 - val_accuracy: 0.7889\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5955 - accuracy: 0.7990 - val_loss: 0.6045 - val_accuracy: 0.8089\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5898 - accuracy: 0.8029 - val_loss: 0.6250 - val_accuracy: 0.7844\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5847 - accuracy: 0.8029 - val_loss: 0.5967 - val_accuracy: 0.8178\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.5797 - accuracy: 0.8105 - val_loss: 0.5880 - val_accuracy: 0.8089\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5699 - accuracy: 0.8057 - val_loss: 0.5848 - val_accuracy: 0.8133\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5646 - accuracy: 0.8105 - val_loss: 0.5782 - val_accuracy: 0.8044\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5610 - accuracy: 0.8105 - val_loss: 0.5782 - val_accuracy: 0.8222\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5553 - accuracy: 0.8133 - val_loss: 0.5642 - val_accuracy: 0.8311\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5500 - accuracy: 0.8171 - val_loss: 0.5663 - val_accuracy: 0.8267\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5406 - accuracy: 0.8238 - val_loss: 0.5616 - val_accuracy: 0.8133\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5353 - accuracy: 0.8219 - val_loss: 0.5512 - val_accuracy: 0.8289\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5284 - accuracy: 0.8324 - val_loss: 0.5450 - val_accuracy: 0.8289\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5252 - accuracy: 0.8210 - val_loss: 0.5443 - val_accuracy: 0.8267\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5187 - accuracy: 0.8314 - val_loss: 0.5346 - val_accuracy: 0.8267\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5141 - accuracy: 0.8267 - val_loss: 0.5230 - val_accuracy: 0.8311\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5041 - accuracy: 0.8295 - val_loss: 0.5287 - val_accuracy: 0.8200\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5015 - accuracy: 0.8381 - val_loss: 0.5256 - val_accuracy: 0.8356\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4963 - accuracy: 0.8333 - val_loss: 0.5074 - val_accuracy: 0.8356\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4899 - accuracy: 0.8371 - val_loss: 0.5069 - val_accuracy: 0.8356\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.8362 - val_loss: 0.4986 - val_accuracy: 0.8400\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4804 - accuracy: 0.8333 - val_loss: 0.4933 - val_accuracy: 0.8289\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.8600 - val_loss: 0.5083 - val_accuracy: 0.8378\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.8476 - val_loss: 0.4836 - val_accuracy: 0.8356\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4643 - accuracy: 0.8505 - val_loss: 0.4788 - val_accuracy: 0.8444\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4600 - accuracy: 0.8495 - val_loss: 0.4932 - val_accuracy: 0.8400\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.8533 - val_loss: 0.4816 - val_accuracy: 0.8333\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4544 - accuracy: 0.8438 - val_loss: 0.4718 - val_accuracy: 0.8356\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[129  18   7]\n",
            " [  0 134  11]\n",
            " [ 16  22 113]]\n",
            "\n",
            "P-Score: 0.841, R-Score: 0.837, F-Score: 0.835\n",
            "[0.8355555555555556, 0.840788511596619, 0.8367148798525825, 0.8348066952488145, 0.8918041418041417, 0.8964951950254381, 0.8440718509823031, 0.8774570626039608]\n",
            "Model: \"sequential_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_86 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_87 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.3300 - accuracy: 0.3381 - val_loss: 1.1744 - val_accuracy: 0.3222\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1226 - accuracy: 0.3381 - val_loss: 1.1045 - val_accuracy: 0.3222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0978 - accuracy: 0.2695 - val_loss: 1.0970 - val_accuracy: 0.2978\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0924 - accuracy: 0.2771 - val_loss: 1.0922 - val_accuracy: 0.3444\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0865 - accuracy: 0.3657 - val_loss: 1.0857 - val_accuracy: 0.1756\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0807 - accuracy: 0.3676 - val_loss: 1.0791 - val_accuracy: 0.3978\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0738 - accuracy: 0.4057 - val_loss: 1.0752 - val_accuracy: 0.4222\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0671 - accuracy: 0.4905 - val_loss: 1.0657 - val_accuracy: 0.4444\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0608 - accuracy: 0.4971 - val_loss: 1.0602 - val_accuracy: 0.5044\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0525 - accuracy: 0.5524 - val_loss: 1.0521 - val_accuracy: 0.5267\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0429 - accuracy: 0.5943 - val_loss: 1.0423 - val_accuracy: 0.6200\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0331 - accuracy: 0.6190 - val_loss: 1.0347 - val_accuracy: 0.5178\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0227 - accuracy: 0.6400 - val_loss: 1.0215 - val_accuracy: 0.7489\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0112 - accuracy: 0.6705 - val_loss: 1.0102 - val_accuracy: 0.8333\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9978 - accuracy: 0.7752 - val_loss: 0.9980 - val_accuracy: 0.6778\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9822 - accuracy: 0.7333 - val_loss: 0.9817 - val_accuracy: 0.8222\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9669 - accuracy: 0.7790 - val_loss: 0.9662 - val_accuracy: 0.7889\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9506 - accuracy: 0.7467 - val_loss: 0.9515 - val_accuracy: 0.8067\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9326 - accuracy: 0.7705 - val_loss: 0.9335 - val_accuracy: 0.7689\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9135 - accuracy: 0.7829 - val_loss: 0.9120 - val_accuracy: 0.6978\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8889 - accuracy: 0.7514 - val_loss: 0.8894 - val_accuracy: 0.7911\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8686 - accuracy: 0.7667 - val_loss: 0.8714 - val_accuracy: 0.7844\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8488 - accuracy: 0.7838 - val_loss: 0.8583 - val_accuracy: 0.6956\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8314 - accuracy: 0.7610 - val_loss: 0.8358 - val_accuracy: 0.8178\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8129 - accuracy: 0.7848 - val_loss: 0.8266 - val_accuracy: 0.6933\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7959 - accuracy: 0.7733 - val_loss: 0.8019 - val_accuracy: 0.8267\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7788 - accuracy: 0.7990 - val_loss: 0.7906 - val_accuracy: 0.7311\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7631 - accuracy: 0.7924 - val_loss: 0.7701 - val_accuracy: 0.8156\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7472 - accuracy: 0.7867 - val_loss: 0.7553 - val_accuracy: 0.8022\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7339 - accuracy: 0.7933 - val_loss: 0.7481 - val_accuracy: 0.8067\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7188 - accuracy: 0.8038 - val_loss: 0.7319 - val_accuracy: 0.7622\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7064 - accuracy: 0.8057 - val_loss: 0.7163 - val_accuracy: 0.8200\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6936 - accuracy: 0.8010 - val_loss: 0.7066 - val_accuracy: 0.8222\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.8057 - val_loss: 0.6930 - val_accuracy: 0.8267\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6704 - accuracy: 0.8114 - val_loss: 0.6852 - val_accuracy: 0.8267\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6590 - accuracy: 0.8095 - val_loss: 0.6728 - val_accuracy: 0.8244\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6506 - accuracy: 0.8086 - val_loss: 0.6599 - val_accuracy: 0.8178\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.8105 - val_loss: 0.6502 - val_accuracy: 0.8289\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6301 - accuracy: 0.8171 - val_loss: 0.6437 - val_accuracy: 0.8244\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6176 - accuracy: 0.8143 - val_loss: 0.6464 - val_accuracy: 0.7911\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6096 - accuracy: 0.8095 - val_loss: 0.6275 - val_accuracy: 0.8089\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5999 - accuracy: 0.8143 - val_loss: 0.6279 - val_accuracy: 0.8000\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5922 - accuracy: 0.8267 - val_loss: 0.6221 - val_accuracy: 0.7978\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5817 - accuracy: 0.8276 - val_loss: 0.5956 - val_accuracy: 0.8356\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5700 - accuracy: 0.8314 - val_loss: 0.5877 - val_accuracy: 0.8244\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5618 - accuracy: 0.8333 - val_loss: 0.5800 - val_accuracy: 0.8200\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5534 - accuracy: 0.8362 - val_loss: 0.5699 - val_accuracy: 0.8289\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5455 - accuracy: 0.8352 - val_loss: 0.5594 - val_accuracy: 0.8378\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5398 - accuracy: 0.8305 - val_loss: 0.5567 - val_accuracy: 0.8200\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.8448 - val_loss: 0.5495 - val_accuracy: 0.8178\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5196 - accuracy: 0.8410 - val_loss: 0.5406 - val_accuracy: 0.8489\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5116 - accuracy: 0.8486 - val_loss: 0.5377 - val_accuracy: 0.8356\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5050 - accuracy: 0.8352 - val_loss: 0.5286 - val_accuracy: 0.8489\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4988 - accuracy: 0.8505 - val_loss: 0.5176 - val_accuracy: 0.8378\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4875 - accuracy: 0.8533 - val_loss: 0.5172 - val_accuracy: 0.8356\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4790 - accuracy: 0.8571 - val_loss: 0.5048 - val_accuracy: 0.8556\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4737 - accuracy: 0.8495 - val_loss: 0.4937 - val_accuracy: 0.8444\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.8552 - val_loss: 0.4862 - val_accuracy: 0.8422\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4574 - accuracy: 0.8610 - val_loss: 0.4752 - val_accuracy: 0.8467\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8581 - val_loss: 0.4721 - val_accuracy: 0.8422\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8610 - val_loss: 0.4639 - val_accuracy: 0.8444\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4337 - accuracy: 0.8648 - val_loss: 0.4773 - val_accuracy: 0.8200\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4318 - accuracy: 0.8562 - val_loss: 0.4500 - val_accuracy: 0.8467\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4269 - accuracy: 0.8676 - val_loss: 0.4443 - val_accuracy: 0.8489\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4180 - accuracy: 0.8733 - val_loss: 0.4381 - val_accuracy: 0.8444\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4109 - accuracy: 0.8657 - val_loss: 0.4362 - val_accuracy: 0.8489\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4042 - accuracy: 0.8629 - val_loss: 0.4283 - val_accuracy: 0.8511\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4004 - accuracy: 0.8667 - val_loss: 0.4287 - val_accuracy: 0.8467\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3953 - accuracy: 0.8705 - val_loss: 0.4135 - val_accuracy: 0.8533\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3872 - accuracy: 0.8733 - val_loss: 0.4123 - val_accuracy: 0.8533\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3833 - accuracy: 0.8695 - val_loss: 0.4127 - val_accuracy: 0.8556\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3738 - accuracy: 0.8762 - val_loss: 0.4011 - val_accuracy: 0.8533\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3717 - accuracy: 0.8743 - val_loss: 0.3972 - val_accuracy: 0.8533\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8762 - val_loss: 0.3963 - val_accuracy: 0.8511\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3640 - accuracy: 0.8790 - val_loss: 0.3949 - val_accuracy: 0.8600\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3612 - accuracy: 0.8781 - val_loss: 0.3831 - val_accuracy: 0.8556\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3576 - accuracy: 0.8771 - val_loss: 0.3813 - val_accuracy: 0.8533\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3501 - accuracy: 0.8810 - val_loss: 0.3886 - val_accuracy: 0.8622\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3527 - accuracy: 0.8752 - val_loss: 0.3784 - val_accuracy: 0.8511\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3443 - accuracy: 0.8867 - val_loss: 0.3803 - val_accuracy: 0.8644\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[145   3   6]\n",
            " [  1 131  13]\n",
            " [ 25  13 113]]\n",
            "\n",
            "P-Score: 0.865, R-Score: 0.864, F-Score: 0.863\n",
            "[0.8644444444444445, 0.865056761673303, 0.8644503627604793, 0.8627181795728193, 0.9268603018603019, 0.9254946297343132, 0.8423996101796275, 0.8982515139247474]\n",
            "Model: \"sequential_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_89 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.0988 - accuracy: 0.2990 - val_loss: 1.0909 - val_accuracy: 0.2533\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0896 - accuracy: 0.3676 - val_loss: 1.0865 - val_accuracy: 0.5089\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0810 - accuracy: 0.4514 - val_loss: 1.0768 - val_accuracy: 0.5422\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0734 - accuracy: 0.4819 - val_loss: 1.0701 - val_accuracy: 0.5044\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0670 - accuracy: 0.5124 - val_loss: 1.0642 - val_accuracy: 0.5178\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0594 - accuracy: 0.5305 - val_loss: 1.0563 - val_accuracy: 0.6289\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0518 - accuracy: 0.5819 - val_loss: 1.0490 - val_accuracy: 0.4756\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0392 - accuracy: 0.5486 - val_loss: 1.0364 - val_accuracy: 0.4956\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0297 - accuracy: 0.5667 - val_loss: 1.0251 - val_accuracy: 0.6356\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0184 - accuracy: 0.6476 - val_loss: 1.0151 - val_accuracy: 0.6800\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0065 - accuracy: 0.6581 - val_loss: 1.0085 - val_accuracy: 0.5756\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9915 - accuracy: 0.7219 - val_loss: 0.9887 - val_accuracy: 0.6622\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9735 - accuracy: 0.6838 - val_loss: 0.9676 - val_accuracy: 0.7000\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9525 - accuracy: 0.7152 - val_loss: 0.9527 - val_accuracy: 0.7511\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9362 - accuracy: 0.7514 - val_loss: 0.9340 - val_accuracy: 0.8111\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9202 - accuracy: 0.7724 - val_loss: 0.9192 - val_accuracy: 0.7756\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9008 - accuracy: 0.7600 - val_loss: 0.8984 - val_accuracy: 0.7622\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8812 - accuracy: 0.7771 - val_loss: 0.8790 - val_accuracy: 0.7733\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8621 - accuracy: 0.7819 - val_loss: 0.8646 - val_accuracy: 0.7467\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8459 - accuracy: 0.7857 - val_loss: 0.8460 - val_accuracy: 0.7889\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8284 - accuracy: 0.7800 - val_loss: 0.8285 - val_accuracy: 0.8000\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8110 - accuracy: 0.7867 - val_loss: 0.8107 - val_accuracy: 0.7889\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7916 - accuracy: 0.7733 - val_loss: 0.7949 - val_accuracy: 0.7889\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7748 - accuracy: 0.7886 - val_loss: 0.7870 - val_accuracy: 0.7600\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7609 - accuracy: 0.7838 - val_loss: 0.7645 - val_accuracy: 0.8000\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7434 - accuracy: 0.7848 - val_loss: 0.7487 - val_accuracy: 0.7911\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7306 - accuracy: 0.7914 - val_loss: 0.7351 - val_accuracy: 0.7956\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.7733 - val_loss: 0.7237 - val_accuracy: 0.7889\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.7819 - val_loss: 0.7167 - val_accuracy: 0.7800\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.7867 - val_loss: 0.6998 - val_accuracy: 0.8022\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6824 - accuracy: 0.7990 - val_loss: 0.6929 - val_accuracy: 0.7889\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.7924 - val_loss: 0.6792 - val_accuracy: 0.8000\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6620 - accuracy: 0.7867 - val_loss: 0.6727 - val_accuracy: 0.7911\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6537 - accuracy: 0.7838 - val_loss: 0.6628 - val_accuracy: 0.7911\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6463 - accuracy: 0.7810 - val_loss: 0.6646 - val_accuracy: 0.7844\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6353 - accuracy: 0.7895 - val_loss: 0.6488 - val_accuracy: 0.7933\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6281 - accuracy: 0.7981 - val_loss: 0.6513 - val_accuracy: 0.7956\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6196 - accuracy: 0.7905 - val_loss: 0.6306 - val_accuracy: 0.7889\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6112 - accuracy: 0.7933 - val_loss: 0.6240 - val_accuracy: 0.7867\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6026 - accuracy: 0.7943 - val_loss: 0.6304 - val_accuracy: 0.7911\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5909 - accuracy: 0.8029 - val_loss: 0.6096 - val_accuracy: 0.8067\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5869 - accuracy: 0.7981 - val_loss: 0.6040 - val_accuracy: 0.8044\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5844 - accuracy: 0.8010 - val_loss: 0.5950 - val_accuracy: 0.7911\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5733 - accuracy: 0.8029 - val_loss: 0.5907 - val_accuracy: 0.8089\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5662 - accuracy: 0.7990 - val_loss: 0.5797 - val_accuracy: 0.8111\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5639 - accuracy: 0.8105 - val_loss: 0.5715 - val_accuracy: 0.8111\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5470 - accuracy: 0.8200 - val_loss: 0.6107 - val_accuracy: 0.8000\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5442 - accuracy: 0.8229 - val_loss: 0.5634 - val_accuracy: 0.8200\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5424 - accuracy: 0.8171 - val_loss: 0.5581 - val_accuracy: 0.8200\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5327 - accuracy: 0.8181 - val_loss: 0.5431 - val_accuracy: 0.8244\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5263 - accuracy: 0.8295 - val_loss: 0.5390 - val_accuracy: 0.8311\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5177 - accuracy: 0.8267 - val_loss: 0.5326 - val_accuracy: 0.8311\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.8238 - val_loss: 0.5243 - val_accuracy: 0.8333\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5044 - accuracy: 0.8305 - val_loss: 0.5265 - val_accuracy: 0.8244\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4996 - accuracy: 0.8314 - val_loss: 0.5160 - val_accuracy: 0.8289\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4938 - accuracy: 0.8295 - val_loss: 0.5060 - val_accuracy: 0.8400\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4823 - accuracy: 0.8362 - val_loss: 0.5079 - val_accuracy: 0.8378\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4812 - accuracy: 0.8438 - val_loss: 0.4941 - val_accuracy: 0.8400\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4736 - accuracy: 0.8381 - val_loss: 0.4835 - val_accuracy: 0.8400\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4678 - accuracy: 0.8457 - val_loss: 0.4889 - val_accuracy: 0.8444\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4585 - accuracy: 0.8476 - val_loss: 0.4835 - val_accuracy: 0.8444\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4534 - accuracy: 0.8533 - val_loss: 0.4868 - val_accuracy: 0.8333\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8505 - val_loss: 0.4616 - val_accuracy: 0.8489\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4398 - accuracy: 0.8552 - val_loss: 0.4547 - val_accuracy: 0.8489\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4332 - accuracy: 0.8571 - val_loss: 0.4494 - val_accuracy: 0.8467\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4293 - accuracy: 0.8648 - val_loss: 0.4437 - val_accuracy: 0.8489\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8619 - val_loss: 0.4357 - val_accuracy: 0.8556\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4199 - accuracy: 0.8581 - val_loss: 0.4425 - val_accuracy: 0.8533\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4122 - accuracy: 0.8610 - val_loss: 0.4297 - val_accuracy: 0.8556\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4056 - accuracy: 0.8590 - val_loss: 0.4243 - val_accuracy: 0.8533\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4001 - accuracy: 0.8629 - val_loss: 0.4263 - val_accuracy: 0.8489\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3944 - accuracy: 0.8686 - val_loss: 0.4071 - val_accuracy: 0.8578\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3858 - accuracy: 0.8705 - val_loss: 0.4122 - val_accuracy: 0.8556\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3907 - accuracy: 0.8648 - val_loss: 0.4000 - val_accuracy: 0.8622\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3807 - accuracy: 0.8743 - val_loss: 0.3997 - val_accuracy: 0.8600\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3725 - accuracy: 0.8695 - val_loss: 0.3892 - val_accuracy: 0.8600\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8714 - val_loss: 0.3870 - val_accuracy: 0.8644\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3636 - accuracy: 0.8733 - val_loss: 0.3900 - val_accuracy: 0.8667\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3652 - accuracy: 0.8790 - val_loss: 0.3746 - val_accuracy: 0.8667\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3552 - accuracy: 0.8829 - val_loss: 0.3750 - val_accuracy: 0.8600\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[139   3  12]\n",
            " [  0 128  17]\n",
            " [ 17  14 120]]\n",
            "\n",
            "P-Score: 0.860, R-Score: 0.860, F-Score: 0.860\n",
            "[0.86, 0.8597177964106916, 0.8600193366806749, 0.8598442714126809, 0.9225824850824851, 0.9135104578858112, 0.8488560100998914, 0.8949829843560625]\n",
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_92 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_93 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_94 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1063 - accuracy: 0.5505 - val_loss: 1.0894 - val_accuracy: 0.5378\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0829 - accuracy: 0.5381 - val_loss: 1.0800 - val_accuracy: 0.5400\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0736 - accuracy: 0.5238 - val_loss: 1.0725 - val_accuracy: 0.5467\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0632 - accuracy: 0.5705 - val_loss: 1.0588 - val_accuracy: 0.5222\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0488 - accuracy: 0.5524 - val_loss: 1.0479 - val_accuracy: 0.5378\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0366 - accuracy: 0.5590 - val_loss: 1.0341 - val_accuracy: 0.5200\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0215 - accuracy: 0.5486 - val_loss: 1.0181 - val_accuracy: 0.5511\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0073 - accuracy: 0.5610 - val_loss: 1.0038 - val_accuracy: 0.5422\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9898 - accuracy: 0.5762 - val_loss: 0.9876 - val_accuracy: 0.5444\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9715 - accuracy: 0.5695 - val_loss: 0.9704 - val_accuracy: 0.5467\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9525 - accuracy: 0.5676 - val_loss: 0.9534 - val_accuracy: 0.5333\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9329 - accuracy: 0.5733 - val_loss: 0.9335 - val_accuracy: 0.5489\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9159 - accuracy: 0.5629 - val_loss: 0.9206 - val_accuracy: 0.5333\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8968 - accuracy: 0.5781 - val_loss: 0.9004 - val_accuracy: 0.5467\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8809 - accuracy: 0.5667 - val_loss: 0.8836 - val_accuracy: 0.5622\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8639 - accuracy: 0.5771 - val_loss: 0.8677 - val_accuracy: 0.5644\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8476 - accuracy: 0.6105 - val_loss: 0.8546 - val_accuracy: 0.5444\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8327 - accuracy: 0.5924 - val_loss: 0.8602 - val_accuracy: 0.5667\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8220 - accuracy: 0.5924 - val_loss: 0.8285 - val_accuracy: 0.6289\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8089 - accuracy: 0.6533 - val_loss: 0.8176 - val_accuracy: 0.6000\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7981 - accuracy: 0.6381 - val_loss: 0.8104 - val_accuracy: 0.5933\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7874 - accuracy: 0.6829 - val_loss: 0.7986 - val_accuracy: 0.5978\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7783 - accuracy: 0.6771 - val_loss: 0.7902 - val_accuracy: 0.5978\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7702 - accuracy: 0.6667 - val_loss: 0.7845 - val_accuracy: 0.5956\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7618 - accuracy: 0.6533 - val_loss: 0.7797 - val_accuracy: 0.6689\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7552 - accuracy: 0.6733 - val_loss: 0.7773 - val_accuracy: 0.7889\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7502 - accuracy: 0.7495 - val_loss: 0.7637 - val_accuracy: 0.7067\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7431 - accuracy: 0.6714 - val_loss: 0.7579 - val_accuracy: 0.7778\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7383 - accuracy: 0.7524 - val_loss: 0.7524 - val_accuracy: 0.7467\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7335 - accuracy: 0.7314 - val_loss: 0.7468 - val_accuracy: 0.7689\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7281 - accuracy: 0.7248 - val_loss: 0.7590 - val_accuracy: 0.7200\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7241 - accuracy: 0.7486 - val_loss: 0.7430 - val_accuracy: 0.7111\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7194 - accuracy: 0.7429 - val_loss: 0.7385 - val_accuracy: 0.8044\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7179 - accuracy: 0.7648 - val_loss: 0.7533 - val_accuracy: 0.7178\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7151 - accuracy: 0.7629 - val_loss: 0.7320 - val_accuracy: 0.7089\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7086 - accuracy: 0.7648 - val_loss: 0.7263 - val_accuracy: 0.7289\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7069 - accuracy: 0.7486 - val_loss: 0.7307 - val_accuracy: 0.7911\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7036 - accuracy: 0.7829 - val_loss: 0.7210 - val_accuracy: 0.8089\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7015 - accuracy: 0.7752 - val_loss: 0.7151 - val_accuracy: 0.8089\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6958 - accuracy: 0.7676 - val_loss: 0.7155 - val_accuracy: 0.7444\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6925 - accuracy: 0.7810 - val_loss: 0.7122 - val_accuracy: 0.7889\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6889 - accuracy: 0.8000 - val_loss: 0.7031 - val_accuracy: 0.8000\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6851 - accuracy: 0.7905 - val_loss: 0.7019 - val_accuracy: 0.7956\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6784 - accuracy: 0.8019 - val_loss: 0.7129 - val_accuracy: 0.8067\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6760 - accuracy: 0.7981 - val_loss: 0.6891 - val_accuracy: 0.8022\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6709 - accuracy: 0.8114 - val_loss: 0.6849 - val_accuracy: 0.8133\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6637 - accuracy: 0.8076 - val_loss: 0.7030 - val_accuracy: 0.7467\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6618 - accuracy: 0.8067 - val_loss: 0.6856 - val_accuracy: 0.8200\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6566 - accuracy: 0.8162 - val_loss: 0.6702 - val_accuracy: 0.7911\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6488 - accuracy: 0.8152 - val_loss: 0.6615 - val_accuracy: 0.8244\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6421 - accuracy: 0.8114 - val_loss: 0.6913 - val_accuracy: 0.8044\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6377 - accuracy: 0.8238 - val_loss: 0.6521 - val_accuracy: 0.7978\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6308 - accuracy: 0.8171 - val_loss: 0.6442 - val_accuracy: 0.8067\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6235 - accuracy: 0.8190 - val_loss: 0.6478 - val_accuracy: 0.8356\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.8257 - val_loss: 0.6295 - val_accuracy: 0.8178\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6058 - accuracy: 0.8267 - val_loss: 0.6404 - val_accuracy: 0.8200\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6006 - accuracy: 0.8257 - val_loss: 0.6279 - val_accuracy: 0.8289\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5958 - accuracy: 0.8305 - val_loss: 0.6115 - val_accuracy: 0.8333\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5888 - accuracy: 0.8410 - val_loss: 0.5982 - val_accuracy: 0.8333\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5791 - accuracy: 0.8333 - val_loss: 0.5928 - val_accuracy: 0.8356\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5746 - accuracy: 0.8390 - val_loss: 0.5817 - val_accuracy: 0.8356\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5644 - accuracy: 0.8419 - val_loss: 0.5868 - val_accuracy: 0.7978\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5563 - accuracy: 0.8419 - val_loss: 0.5694 - val_accuracy: 0.8356\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5496 - accuracy: 0.8381 - val_loss: 0.5613 - val_accuracy: 0.8267\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5405 - accuracy: 0.8438 - val_loss: 0.5723 - val_accuracy: 0.8467\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5305 - accuracy: 0.8486 - val_loss: 0.5623 - val_accuracy: 0.8333\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5209 - accuracy: 0.8352 - val_loss: 0.5367 - val_accuracy: 0.8333\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.8552 - val_loss: 0.5376 - val_accuracy: 0.8400\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5095 - accuracy: 0.8514 - val_loss: 0.5177 - val_accuracy: 0.8356\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.8457 - val_loss: 0.5103 - val_accuracy: 0.8422\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.8543 - val_loss: 0.5282 - val_accuracy: 0.8556\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4850 - accuracy: 0.8552 - val_loss: 0.4965 - val_accuracy: 0.8422\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4780 - accuracy: 0.8524 - val_loss: 0.4939 - val_accuracy: 0.8444\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4721 - accuracy: 0.8543 - val_loss: 0.4825 - val_accuracy: 0.8378\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4632 - accuracy: 0.8514 - val_loss: 0.4781 - val_accuracy: 0.8444\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4568 - accuracy: 0.8543 - val_loss: 0.4705 - val_accuracy: 0.8422\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8581 - val_loss: 0.4589 - val_accuracy: 0.8422\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4450 - accuracy: 0.8514 - val_loss: 0.4603 - val_accuracy: 0.8467\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4362 - accuracy: 0.8619 - val_loss: 0.4594 - val_accuracy: 0.8489\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8629 - val_loss: 0.4417 - val_accuracy: 0.8533\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[139   7   8]\n",
            " [  0 125  20]\n",
            " [ 14  17 120]]\n",
            "\n",
            "P-Score: 0.853, R-Score: 0.853, F-Score: 0.853\n",
            "[0.8533333333333334, 0.852744572444533, 0.8531227849565369, 0.8528510602073635, 0.9276500526500527, 0.8916902204635386, 0.8505282509025671, 0.8899561746720529]\n",
            "Model: \"sequential_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_95 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_96 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_97 (Dense)            (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 11ms/step - loss: 1.1022 - accuracy: 0.3705 - val_loss: 1.0954 - val_accuracy: 0.2333\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0925 - accuracy: 0.3019 - val_loss: 1.0898 - val_accuracy: 0.4844\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0875 - accuracy: 0.4352 - val_loss: 1.0838 - val_accuracy: 0.5556\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0817 - accuracy: 0.5400 - val_loss: 1.0788 - val_accuracy: 0.4067\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0761 - accuracy: 0.5152 - val_loss: 1.0731 - val_accuracy: 0.5356\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0699 - accuracy: 0.5381 - val_loss: 1.0690 - val_accuracy: 0.6800\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0644 - accuracy: 0.6419 - val_loss: 1.0597 - val_accuracy: 0.7200\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0544 - accuracy: 0.5933 - val_loss: 1.0509 - val_accuracy: 0.6156\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0461 - accuracy: 0.5952 - val_loss: 1.0438 - val_accuracy: 0.7356\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0360 - accuracy: 0.6829 - val_loss: 1.0348 - val_accuracy: 0.7133\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0244 - accuracy: 0.7133 - val_loss: 1.0275 - val_accuracy: 0.4667\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0159 - accuracy: 0.7057 - val_loss: 1.0129 - val_accuracy: 0.7578\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0039 - accuracy: 0.8362 - val_loss: 1.0051 - val_accuracy: 0.6689\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9922 - accuracy: 0.7781 - val_loss: 0.9897 - val_accuracy: 0.8511\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9791 - accuracy: 0.8448 - val_loss: 0.9768 - val_accuracy: 0.8822\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9635 - accuracy: 0.8610 - val_loss: 0.9651 - val_accuracy: 0.7956\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9477 - accuracy: 0.8295 - val_loss: 0.9480 - val_accuracy: 0.8644\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9316 - accuracy: 0.8486 - val_loss: 0.9338 - val_accuracy: 0.8267\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9146 - accuracy: 0.8638 - val_loss: 0.9146 - val_accuracy: 0.8489\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8956 - accuracy: 0.8610 - val_loss: 0.8957 - val_accuracy: 0.8778\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8768 - accuracy: 0.8562 - val_loss: 0.8836 - val_accuracy: 0.7956\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8604 - accuracy: 0.8714 - val_loss: 0.8679 - val_accuracy: 0.7267\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8436 - accuracy: 0.8638 - val_loss: 0.8443 - val_accuracy: 0.8689\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8211 - accuracy: 0.8619 - val_loss: 0.8343 - val_accuracy: 0.6711\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8054 - accuracy: 0.8771 - val_loss: 0.8089 - val_accuracy: 0.8822\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7820 - accuracy: 0.8762 - val_loss: 0.7883 - val_accuracy: 0.8644\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7598 - accuracy: 0.8676 - val_loss: 0.7672 - val_accuracy: 0.8733\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7418 - accuracy: 0.8829 - val_loss: 0.7476 - val_accuracy: 0.8778\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7222 - accuracy: 0.8924 - val_loss: 0.7283 - val_accuracy: 0.8756\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7085 - accuracy: 0.8790 - val_loss: 0.7158 - val_accuracy: 0.8822\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6882 - accuracy: 0.8714 - val_loss: 0.7039 - val_accuracy: 0.8600\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6708 - accuracy: 0.8829 - val_loss: 0.6842 - val_accuracy: 0.8756\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.8790 - val_loss: 0.6710 - val_accuracy: 0.8511\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6390 - accuracy: 0.8771 - val_loss: 0.6467 - val_accuracy: 0.8689\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6242 - accuracy: 0.8800 - val_loss: 0.6313 - val_accuracy: 0.8667\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6100 - accuracy: 0.8724 - val_loss: 0.6200 - val_accuracy: 0.8756\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5955 - accuracy: 0.8790 - val_loss: 0.6126 - val_accuracy: 0.8444\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.5777 - accuracy: 0.8800 - val_loss: 0.5839 - val_accuracy: 0.8556\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5594 - accuracy: 0.8829 - val_loss: 0.5816 - val_accuracy: 0.8533\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5466 - accuracy: 0.8743 - val_loss: 0.5638 - val_accuracy: 0.8778\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5337 - accuracy: 0.8838 - val_loss: 0.5452 - val_accuracy: 0.8578\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5219 - accuracy: 0.8733 - val_loss: 0.5331 - val_accuracy: 0.8667\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5100 - accuracy: 0.8800 - val_loss: 0.5243 - val_accuracy: 0.8622\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4993 - accuracy: 0.8752 - val_loss: 0.5171 - val_accuracy: 0.8667\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4871 - accuracy: 0.8848 - val_loss: 0.4972 - val_accuracy: 0.8689\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4802 - accuracy: 0.8829 - val_loss: 0.4909 - val_accuracy: 0.8644\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8829 - val_loss: 0.4826 - val_accuracy: 0.8578\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4582 - accuracy: 0.8790 - val_loss: 0.4664 - val_accuracy: 0.8667\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.8800 - val_loss: 0.4584 - val_accuracy: 0.8689\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8848 - val_loss: 0.4508 - val_accuracy: 0.8711\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8876 - val_loss: 0.4406 - val_accuracy: 0.8778\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8857 - val_loss: 0.4339 - val_accuracy: 0.8756\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4115 - accuracy: 0.8924 - val_loss: 0.4292 - val_accuracy: 0.8667\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4080 - accuracy: 0.8876 - val_loss: 0.4181 - val_accuracy: 0.8667\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3986 - accuracy: 0.8857 - val_loss: 0.4103 - val_accuracy: 0.8800\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3922 - accuracy: 0.8857 - val_loss: 0.4031 - val_accuracy: 0.8756\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3859 - accuracy: 0.8886 - val_loss: 0.4090 - val_accuracy: 0.8756\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3800 - accuracy: 0.8905 - val_loss: 0.3880 - val_accuracy: 0.8756\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8971 - val_loss: 0.3898 - val_accuracy: 0.8667\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3652 - accuracy: 0.8905 - val_loss: 0.3844 - val_accuracy: 0.8800\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3583 - accuracy: 0.8933 - val_loss: 0.3714 - val_accuracy: 0.8756\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3498 - accuracy: 0.9000 - val_loss: 0.3701 - val_accuracy: 0.8778\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3454 - accuracy: 0.8943 - val_loss: 0.3586 - val_accuracy: 0.8711\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3430 - accuracy: 0.9000 - val_loss: 0.3502 - val_accuracy: 0.8822\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3323 - accuracy: 0.9010 - val_loss: 0.3674 - val_accuracy: 0.8733\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3321 - accuracy: 0.8971 - val_loss: 0.3667 - val_accuracy: 0.8622\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3245 - accuracy: 0.8971 - val_loss: 0.3601 - val_accuracy: 0.8756\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.3210 - accuracy: 0.8962 - val_loss: 0.3439 - val_accuracy: 0.8711\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3154 - accuracy: 0.9048 - val_loss: 0.3401 - val_accuracy: 0.8711\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3115 - accuracy: 0.9095 - val_loss: 0.3327 - val_accuracy: 0.8733\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.3097 - accuracy: 0.9038 - val_loss: 0.3185 - val_accuracy: 0.8911\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3000 - accuracy: 0.9133 - val_loss: 0.3331 - val_accuracy: 0.8756\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.9019 - val_loss: 0.3096 - val_accuracy: 0.8778\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2949 - accuracy: 0.9038 - val_loss: 0.3372 - val_accuracy: 0.8911\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2901 - accuracy: 0.9105 - val_loss: 0.3237 - val_accuracy: 0.8956\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2908 - accuracy: 0.9048 - val_loss: 0.3034 - val_accuracy: 0.8911\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2825 - accuracy: 0.9124 - val_loss: 0.3071 - val_accuracy: 0.8867\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2832 - accuracy: 0.9200 - val_loss: 0.2999 - val_accuracy: 0.8956\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2797 - accuracy: 0.9048 - val_loss: 0.2914 - val_accuracy: 0.8956\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2734 - accuracy: 0.9086 - val_loss: 0.2825 - val_accuracy: 0.8889\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[146   2   6]\n",
            " [  0 130  15]\n",
            " [  5  22 124]]\n",
            "\n",
            "P-Score: 0.889, R-Score: 0.889, F-Score: 0.888\n",
            "[0.8888888888888888, 0.8887385583891635, 0.8885985750566704, 0.8882600348031566, 0.9655800280800281, 0.9089315997738836, 0.8754789696338791, 0.9166635324959302]\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.871111   0.871549  0.870390  0.870655  0.968958  0.880045  0.860495   \n",
            "1  0.888889   0.892063  0.889088  0.889207  0.956103  0.912719  0.882101   \n",
            "2  0.862222   0.863732  0.862313  0.862271  0.931292  0.893838  0.865479   \n",
            "3  0.840000   0.855569  0.841662  0.840876  0.889216  0.890447  0.863973   \n",
            "4  0.808889   0.810860  0.808360  0.808659  0.866071  0.858847  0.843939   \n",
            "5  0.835556   0.840789  0.836715  0.834807  0.891804  0.896495  0.844072   \n",
            "6  0.864444   0.865057  0.864450  0.862718  0.926860  0.925495  0.842400   \n",
            "7  0.860000   0.859718  0.860019  0.859844  0.922582  0.913510  0.848856   \n",
            "8  0.853333   0.852745  0.853123  0.852851  0.927650  0.891690  0.850528   \n",
            "9  0.888889   0.888739  0.888599  0.888260  0.965580  0.908932  0.875479   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.903166  \n",
            "1       0.916975  \n",
            "2       0.896870  \n",
            "3       0.881212  \n",
            "4       0.856286  \n",
            "5       0.877457  \n",
            "6       0.898252  \n",
            "7       0.894983  \n",
            "8       0.889956  \n",
            "9       0.916664  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3xUVfrH8c+TXkhCEkINvfcWmhRRFOkoCkhTFEXAgg3b6qqs7vpzbeuCIBYQRbq6iihYQFRqQHrvCTWUhBTSz++PO0AICQTI5E4yz/v1yiszd+7c+c5MMs/cc+49R4wxKKWUcl8edgdQSillLy0ESinl5rQQKKWUm9NCoJRSbk4LgVJKuTktBEop5ea0EKhCJSI/iMi9hb2unURkv4jc4oTtGhGp5bg8WUReKsi61/A4Q0Rk8bXmvMx2O4tIbGFvVxU9L7sDKPuJSFKOqwFAGpDluP6QMWZGQbdljOnujHVLOmPMqMLYjohUA/YB3saYTMe2ZwAFfg+V+9FCoDDGlDp3WUT2Aw8YY37OvZ6IeJ37cFFKlRzaNKTydW7XX0SeFZGjwFQRCRWRBSISJyKnHZcjc9xnqYg84Lg8XET+EJG3HOvuE5Hu17hudRFZJiKJIvKziEwUkS/yyV2QjP8QkT8d21ssImVy3D5MRA6IyEkR+dtlXp82InJURDxzLLtDRDY6LrcWkRUiEi8iR0Rkgoj45LOtaSLyWo7r4xz3OSwi9+dat6eI/CUiZ0QkRkReyXHzMsfveBFJEpF2517bHPe/QUTWiEiC4/cNBX1tLkdE6jvuHy8iW0SkT47beojIVsc2D4nI047lZRzvT7yInBKR30VEP5eKmL7g6krKA2FAVWAk1t/MVMf1KsBZYMJl7t8G2AGUAd4EPhERuYZ1vwRWA+HAK8CwyzxmQTIOBu4DygI+wLkPpgbAJMf2KzoeL5I8GGNWAcnAzbm2+6XjchbwhOP5tAO6AGMukxtHhm6OPLcCtYHc/RPJwD1AaaAnMFpEbnfc1snxu7QxppQxZkWubYcB3wPvO57bO8D3IhKe6zlc8tpcIbM38B2w2HG/R4EZIlLXsconWM2MQUAj4FfH8qeAWCACKAe8AOi4N0VMC4G6kmzgZWNMmjHmrDHmpDFmvjEmxRiTCLwO3HiZ+x8wxnxkjMkCPgMqYP3DF3hdEakCtAL+boxJN8b8AXyb3wMWMONUY8xOY8xZYA7QzLH8LmCBMWaZMSYNeMnxGuRnJjAIQESCgB6OZRhj1hpjVhpjMo0x+4EP88iRlwGOfJuNMclYhS/n81tqjNlkjMk2xmx0PF5BtgtW4dhljPnckWsmsB3onWOd/F6by2kLlALecLxHvwILcLw2QAbQQESCjTGnjTHrciyvAFQ1xmQYY343OgBakdNCoK4kzhiTeu6KiASIyIeOppMzWE0RpXM2j+Ry9NwFY0yK42Kpq1y3InAqxzKAmPwCFzDj0RyXU3Jkqphz244P4pP5PRbWt/9+IuIL9APWGWMOOHLUcTR7HHXk+CfW3sGVXJQBOJDr+bURkSWOpq8EYFQBt3tu2wdyLTsAVMpxPb/X5oqZjTE5i2bO7d6JVSQPiMhvItLOsfzfwG5gsYjsFZHnCvY0VGHSQqCuJPe3s6eAukAbY0wwF5oi8mvuKQxHgDARCcixrPJl1r+ejEdybtvxmOH5rWyM2Yr1gdedi5uFwGpi2g7UduR44VoyYDVv5fQl1h5RZWNMCDA5x3av9G36MFaTWU5VgEMFyHWl7VbO1b5/frvGmDXGmL5YzUbfYO1pYIxJNMY8ZYypAfQBnhSRLteZRV0lLQTqagVhtbnHO9qbX3b2Azq+YUcDr4iIj+PbZO/L3OV6Ms4DeolIB0fH7niu/H/yJTAWq+DMzZXjDJAkIvWA0QXMMAcYLiINHIUod/4grD2kVBFpjVWAzonDasqqkc+2FwJ1RGSwiHiJyECgAVYzzvVYhbX38IyIeItIZ6z3aJbjPRsiIiHGmAys1yQbQER6iUgtR19QAla/yuWa4pQTaCFQV+s9wB84AawEfiyixx2C1eF6EngNmI11vkNerjmjMWYL8DDWh/sR4DRWZ+blnGuj/9UYcyLH8qexPqQTgY8cmQuS4QfHc/gVq9nk11yrjAHGi0gi8Hcc364d903B6hP503EkTttc2z4J9MLaazoJPAP0ypX7qhlj0rE++Ltjve4fAPcYY7Y7VhkG7Hc0kY3Cej/B6gz/GUgCVgAfGGOWXE8WdfVE+2VUcSQis4Htxhin75EoVdLpHoEqFkSklYjUFBEPx+GVfbHampVS10nPLFbFRXngK6yO21hgtDHmL3sjKVUyaNOQUkq5OW0aUkopN1fsmobKlCljqlWrZncMpZQqVtauXXvCGBOR123FrhBUq1aN6Ohou2MopVSxIiK5zyg/T5uGlFLKzWkhUEopN+e0QiAin4rIcRHZnM/tQ0Rko4hsEpHlItLUWVmUUkrlz5l9BNOwxoCfns/t+4AbjTGnxZqAZArWePRKKTeTkZFBbGwsqampV15ZXZafnx+RkZF4e3sX+D5OKwTGmGVizZ+a3+3Lc1xdST6TfyilSr7Y2FiCgoKoVq0a+c9bpK7EGMPJkyeJjY2levXqBb6fq/QRjAB+yO9GERkpItEiEh0XF1eEsZRSRSE1NZXw8HAtAtdJRAgPD7/qPSvbC4GI3IRVCJ7Nbx1jzBRjTJQxJioiIs/DYJVSxZwWgcJxLa+jrYVARJoAHwN9HcPjOs2Oo4n864dtJKZmOPNhlFKq2LGtEDjmof0KGGaM2ensx4s5lcKHv+1l57FEZz+UUkoVK848fHQm1kQTdUUkVkRGiMgoERnlWOXvWCNJfiAi60XEqacL16sQBMD2o1oIlFIXi4+P54MPPrjq+/Xo0YP4+Pirvt/w4cOZN2/eVd/PWZx51NCgK9z+APCAsx4/t0ql/Qny9WKHFgKlVC7nCsGYMWMuWp6ZmYmXV/4fkwsXLnR2tCJR7MYaulYiQp3yQWw/ooVAKVf26ndb2Hr4TKFus0HFYF7u3TDf25977jn27NlDs2bN8Pb2xs/Pj9DQULZv387OnTu5/fbbiYmJITU1lbFjxzJy5EjgwthnSUlJdO/enQ4dOrB8+XIqVarE//73P/z9/a+Y7ZdffuHpp58mMzOTVq1aMWnSJHx9fXnuuef49ttv8fLyomvXrrz11lvMnTuXV199FU9PT0JCQli2bFmhvD5uUwgA6pUP4rsNhzHG6BEKSqnz3njjDTZv3sz69etZunQpPXv2ZPPmzeePxf/0008JCwvj7NmztGrVijvvvJPw8PCLtrFr1y5mzpzJRx99xIABA5g/fz5Dhw697OOmpqYyfPhwfvnlF+rUqcM999zDpEmTGDZsGF9//TXbt29HRM43P40fP55FixZRqVKla2qSyo/bFYIZqzI5eiaVCiFXrtRKqaJ3uW/uRaV169YXnZD1/vvv8/XXXwMQExPDrl27LikE1atXp1mzZgC0bNmS/fv3X/FxduzYQfXq1alTpw4A9957LxMnTuSRRx7Bz8+PESNG0KtXL3r16gVA+/btGT58OAMGDKBfv36F8VQBFziPoCjVLR8MoM1DSqnLCgwMPH956dKl/Pzzz6xYsYINGzbQvHnzPE/Y8vX1PX/Z09OTzMzMa358Ly8vVq9ezV133cWCBQvo1q0bAJMnT+a1114jJiaGli1bcvJk4Rx1716FoJweOaSUulRQUBCJiXl/LiQkJBAaGkpAQADbt29n5cqVhfa4devWZf/+/ezevRuAzz//nBtvvJGkpCQSEhLo0aMH7777Lhs2bABgz549tGnThvHjxxMREUFMTEyh5HCrpqGQAG8qhvix42jhdkQppYq38PBw2rdvT6NGjfD396dcuXLnb+vWrRuTJ0+mfv361K1bl7Zt2xba4/r5+TF16lT69+9/vrN41KhRnDp1ir59+5KamooxhnfeeQeAcePGsWvXLowxdOnShaZNC2fQ5mI3eX1UVJS5nhnK7pu6miMJqfz4eKdCTKWUuh7btm2jfv36dscoMfJ6PUVkrTEmKq/13appCKx+gj1xSWRkZdsdRSmlXILbFYL6FYLIyDLsjUu2O4pSqoR7+OGHadas2UU/U6dOtTvWJdyqjwCgbvlzHcZnzl9WSilnmDhxot0RCsTt9ghqlCmFl4fokUNKKeXgdoXAx8uDWmVL6ZhDSinl4HaFAKzmoe1H9BBSpZQCNy4EhxNSSTirk9QopZRbFoL6jqEmdJIapdS1KlWqVL637d+/n0aNGhVhmuvjXoXg2BYgx5FD2jyklFJudPjoXzPg20dgwHQq1OtFkJ+XHjmklCv64Tk4uqlwt1m+MXR/47KrPPfcc1SuXJmHH34YgFdeeQUvLy+WLFnC6dOnycjI4LXXXqNv375X9dCpqamMHj2a6OhovLy8eOedd7jpppvYsmUL9913H+np6WRnZzN//nwqVqzIgAEDiI2NJSsri5deeomBAwde89MuKPcpBA1vh7VTYd4IZNjX1C8frEcOKaXOGzhwII8//vj5QjBnzhwWLVrEY489RnBwMCdOnKBt27b06dPnquYzmThxIiLCpk2b2L59O127dmXnzp1MnjyZsWPHMmTIENLT08nKymLhwoVUrFiR77//HrAGvCsK7lMIfAJh8Bz49DaYOYhO1d5n8nZ/4hLTiAjyvfL9lVJF4wrf3J2lefPmHD9+nMOHDxMXF0doaCjly5fniSeeYNmyZXh4eHDo0CGOHTtG+fLlC7zdP/74g0cffRSAevXqUbVqVXbu3Em7du14/fXXiY2NpV+/ftSuXZvGjRvz1FNP8eyzz9KrVy86duzorKd7EffqIwgIg6FfgW8pRh4cR7nso/Sd8AebDxVN1VVKubb+/fszb948Zs+ezcCBA5kxYwZxcXGsXbuW9evXU65cuTznIrgWgwcP5ttvv8Xf358ePXrw66+/UqdOHdatW0fjxo158cUXGT9+fKE81pW4VyEAKF0Zhs7Hx6TzQ+l/0yp7PXdOWs7/1h+yO5lSymYDBw5k1qxZzJs3j/79+5OQkEDZsmXx9vZmyZIlHDhw4Kq32bFjR2bMmAHAzp07OXjwIHXr1mXv3r3UqFGDxx57jL59+7Jx40YOHz5MQEAAQ4cOZdy4caxbt66wn2Ke3KdpKKey9a1iMP8B/pMxnjWBbXl69gDWHWjDqM41dRpLpdxUw4YNSUxMpFKlSlSoUIEhQ4bQu3dvGjduTFRUFPXq1bvqbY4ZM4bRo0fTuHFjvLy8mDZtGr6+vsyZM4fPP/8cb29vypcvzwsvvMCaNWsYN24cHh4eeHt7M2nSJCc8y0u53XwEF8lMg5UfYJa9RVZGKjMzb2JRdhvCG3ZmeIdaNK8SWjiPo5S6LJ2PoHBd7XwE7rlHcI6XL3R4Amk6CK9f/sHQTXMZlvUTZ3a8y6/bmvJd6Vuo0e52ejerQkiAt91plVLKKdy7EJwTVB5un4h0/z/YuwT/rd/TbfuP3J64nP0/fsj7P3Qnvm5/+t9QnzbVw67q0DGlVMm1adMmhg0bdtEyX19fVq1aZVOia6OFICffUlC/N971e+OdlYHZ9h1ll03gpePTSNw9m2+338C34V3p0KU3tzWqiKeHFgSlCosxpth9yWrcuDHr16+3O8ZFrqW53737CAoqNpqslZMx277DKyuVIyaMZd4d8L5hNN07tMHfx7No8yhVwuzbt4+goCDCw8OLXTFwJcYYTp48SWJiItWrV7/otsv1EWghuBppSWTv+IG4FTMIO/I7WUb4TPqS1nYsgzvUpUwpPTFNqWuRkZFBbGxsoR2j7878/PyIjIzE2/vifk0tBE5g4g9y6psXCN//HYdNGP/OHkq1TsMYdVNNfL10D0Ep5VouVwjc74SyQiKlqxA+/Au47wfCIyryruf7tPn9Hh5+dwar952yO55SShWYFoLrVfUGfMcsg17v0dLvCJOTx7L5k9G8Mnc5KemZdqdTSqkr0kJQGDw8Ieo+vB//C9P8Hu7zWsSYzYN48f2PiTmVYnc6pZS6LC0EhSkgDO++/0FGLqFUcGneSPobH/73df7cfcLuZEoplS+nFQIR+VREjovI5nxuFxF5X0R2i8hGEWnhrCxFrmJzAsYsJSuyLa+ZCWya9jif/L7H7lRKKZUnZ+4RTAO6Xeb27kBtx89IoGhGVyoq/qH43/cNGc2HM8rrOyotfohPf9thdyqllLqE0wqBMWYZcLnDZ/oC041lJVBaRCo4K48tPL3x7vMe2bf9i26eayj/8yPMXrnX7lRKKXURO/sIKgExOa7HOpZdQkRGiki0iETHxcUVSbhCI4JHuzFk3vo6PTxX4/H9WL5bH2t3KqWUOq9YdBYbY6YYY6KMMVERERF2x7kmXu0fIaPjs/T3XMbJ+U/x67ajdkdSSinA3kJwCKic43qkY1mJ5X3z86S3GsVwzx/ZOes59sQl2R1JKaVsLQTfAvc4jh5qCyQYY47YmMf5RPDp8QYpjYYwSr5mxcdPk5qRZXcqpZSbc9ow1CIyE+gMlBGRWOBlwBvAGDMZWAj0AHYDKcB9zsriUkQI6DeBI8mpDN03k58+8ufWMe/anUop5cacVgiMMYOucLsBHnbW47s0Dw8qDPuYTZNSufX4p2ydFUCDu1+3O5VSyk0Vi87iEsnDg/ojP+M3v1tosH0CJxa9aXcipZSb0kJgIy9vb+o+NJ1FcgNhK/5J3F8L7I6klHJDWghsVj40kPL3fMouquD7v4c4vG+73ZGUUm5GC4ELaFq9Agz4HMgmcfogDh7TQeqUUkVHC4GLqNugKae7TqCu2cvGDx9gv55joJQqIloIXEjVG+4krsVYemUv4esP/86h+LN2R1JKuQEtBC4motfLnKnalScyP2HGpNeJS0yzO5JSqoTTQuBqPDwJHvYFCRU78XTqBKZO+j8SUjLsTqWUKsG0ELgiL19Chs/mTPk2PJX8DlMmv01yms5/rJRyDi0ErsongNL3z+dMmeY8nvAm0z56l8ysbLtTKaVKIC0Ersy3FKEPfkN8WBNGx73O9x+/gjUyh1JKFR4tBK7OL4SIMT+wN7wTfY/8h+hPHgMtBkqpQqSFoDjw9qfmw1+xPLQvrWKns//jYZClHchKqcKhhaCYEE8vWj08lbkhw6l26DuOTLsHsnUuA6XU9dNCUIx4e3nSfczbTAu8nwoxCzk8/QHI1g5kpdT10UJQzJTy9eKOR95kpv9gKu7/ikMzH9E+A6XUddFCUAyF+HvT/ZH3mOfbj0q7ZhA7Z5wWA6XUNdNCUEyVDvSly6OT+c6nB5HbPiJm4Vt2R1JKFVNaCIqx0FK+tHv0U37zbEelNa8Tu3y23ZGUUsWQFoJirkyQPzVHzWCr1KLM4kc4suV3uyMppYoZLQQlQGREOIH3zuUEpfGbO4QTB3WWM6VUwWkhKCGqV6tO4p0z8TCZJE/rT0Z6qt2RlFLFhBaCEqR+4yh2t3+bqtkHiZ73tt1xlFLFhBaCEqbFLQPZ7NeC+js/4NSJ43bHUUoVA1oIShjx8CC4z78INslsnv2y3XGUUsWAFoISqEqDtmwo0502x+ewc8dmu+MopVycFoISquaAN8gWD45//Tedw0ApdVlaCEqo4HJV2V1zOB1Sl7J82WK74yilXJgWghKswV0vcVpKE77kWeK041gplQ8tBCWYp38wSbe9S01zkNMf9iYj+bTdkZRSLkgLQQlXuW0/1rZ5j2rpuzj+QQ84G293JKWUi9FC4Aba9riH+TX/SUTSDuKn9NJioJS6iFMLgYh0E5EdIrJbRJ7L4/YqIrJERP4SkY0i0sOZedzZnYNH8nbpFwk8tZXUT3pB8km7IymlXITTCoGIeAITge5AA2CQiDTItdqLwBxjTHPgbuADZ+Vxdz5eHtw/YgxPez6LnNhB1qfd4cwRu2MppVyAM/cIWgO7jTF7jTHpwCygb651DBDsuBwCHHZiHrdXLtiPYfc8yP2Zz5J+6iBmajc4fcDuWEopmzmzEFQCYnJcj3Usy+kVYKiIxAILgUedmEcBUdXC6NG7P4NSnyf1zCn4tBuc3GN3LKWUjezuLB4ETDPGRAI9gM9F5JJMIjJSRKJFJDouLq7IQ5Y0Q9pUpUHrm7kj5QXS0s7C3OGQlWF3LKWUTZxZCA4BlXNcj3Qsy2kEMAfAGLMC8APK5N6QMWaKMSbKGBMVERHhpLju5ZXeDSlVpSlPnr0fjm6EZTrnsVLuypmFYA1QW0Sqi4gPVmfwt7nWOQh0ARCR+liFQL/yFwEfLw8+GNqCdQHt+V5uxCz7Nxz+y+5YSikbOK0QGGMygUeARcA2rKODtojIeBHp41jtKeBBEdkAzASGGx0hrciUDfJj+v2teYPhnCCEzPkPQWaa3bGUUkVMitvnblRUlImOjrY7Romy7uBpJn30IR95/ou0to/h2+0fdkdSShUyEVlrjInK6za7O4uVC2hRJZShw0YwO+smvFdOIH39HLsjKaWKkBYCBcCNdSIo1ef/2JBdA59vHiR7/oM6FIVSbkILgTqvZ6u6rL9lJu9m3InZNB8zqT3sW2Z3LKWUk2khUBe5r1MdUtuPo1/ayyRkeMBnvWHR37QTWakSTAuBusSz3epRvWkn2p1+hT1VB8CKCfDRzXBsq93RlFJOoIVAXcLDQ3jzrqa0rBVJ1113sLHTFEg6BlM6w6oP7Y6nlCpkWghUnny8PJg0tAV1ywVx99IQtt6+CGp0hh+egQMr7I6nlCpEBSoEIjJWRILF8omIrBORrs4Op+wV5OfN1PtaERrgwz2z9xF7ywcQGAHL3rQ7mlKqEBV0j+B+Y8wZoCsQCgwD3nBaKuUyygX78dn9rcjIyuaezzeT0nI07PkVYvWkPqVKioIWAnH87gF8bozZkmOZKuFqlQ3i43ujiI0/ywNbm2L8w+A33StQqqQoaCFYKyKLsQrBIhEJArKdF0u5mlbVwvjPwGasPJTGPJ8+sGsRHF5vdyylVCEoaCEYATwHtDLGpADewH1OS6VcUvfGFfhXv8aMP9aBFI9SZOtegVIlQkELQTtghzEmXkSGYs01nOC8WMpVDWxVhbE9WzIlvSseO74n+8gmuyMppa5TQQvBJCBFRJpiDR29B5jutFTKpT3QsQY+7R8m0fiza/YLkK2thEoVZwUtBJmOeQL6AhOMMROBIOfFUq5udLeWrK44jLrxyzj6yd2Qnmx3JKXUNSpoIUgUkeexDhv93jGvsLfzYilXJyJ0vP8NPgm4n7KHFpPx8W2QEGt3LKXUNShoIRgIpGGdT3AUa/7hfzstlSoWfLw9uXH4eEZljSMzbg9myk0Qs9ruWEqpq1SgQuD48J8BhIhILyDVGKN9BIpaZYNo330IvVNfITHbF6b2gDUfQzGb+U4pd1bQISYGAKuB/sAAYJWI3OXMYKr4uKddVSrWbs4tSS+TXLkjfP8UfDMGMs7aHU0pVQAFbRr6G9Y5BPcaY+4BWgMvOS+WKk5EhH/f1YR07xDuih9LavtxsOFL+ORWOH3A7nhKqSsoaCHwMMYcz3H95FXcV7mBcsF+TBjUgt0nUhi252bSBsyC+IPw5QDdM1DKxRX0w/xHEVkkIsNFZDjwPbDQebFUcdShdhneG9ic6AOnGbO6DJn9PoW47fDT3+2OppS6jIJ2Fo8DpgBNHD9TjDHPOjOYKp56NqnAa7c34pftx3nmrzKYNmNg9RTYucjuaEqpfHgVdEVjzHxgvhOzqBJiSJuqnE5O563FOwlqdSevlPsN+WYMjFkBpcraHU8plctl9whEJFFEzuTxkygiZ4oqpCp+Hr6pFqM71+SzNcd43fcpTHqSdSSRHlaqlMu5bCEwxgQZY4Lz+AkyxgQXVUhV/IgIz3arx4s96/PxTj+mBY6A3T/BzEGwd6kWBKVcSIGbhpS6Fg90rEF4KR/GzQWf4FMMOvgjHjt/gPBaEDUCWj0AXj52x1TKrWkhUE53R/NIQgN8GP2FJ9OD+zH7tmOU3vIZLHoejmyAOyaD6IR3StlFzwVQRaJz3bJMH9GaQ0mGvn9Ecuiu76DzC7BxFqyYYHc8pdyaFgJVZFpVC+PzEa05lZzOgMkrONjoYWjQ1zrPYNdPdsdTym1pIVBFqnmVUGY+2Jbk9EwGTFnF3g5vQdmGMO9+iNtpdzyl3JIWAlXkGlUKYeaDbcnMzuauTzaw9cbJ4OkDM++GM4ftjqeU29FCoGxRv0Iwc0fdQICPJ3fNimVD+wmQdAw+7AT7frc7nlJuxamFQES6icgOEdktIs/ls84AEdkqIltE5Etn5lGupXqZQOaPvoHKoQHctdCwtNMs8A+F6X1h+X/1XAOliojTCoGIeAITge5AA2CQiDTItU5t4HmgvTGmIfC4s/Io11Qu2I85D7WjaWRp7vv+DHOaT4d6PWHxi1a/QVam3RGVKvGcuUfQGthtjNlrjEkHZgF9c63zIDDRGHMaINdQ18pNhAR48/mINnSuE8Ez3+3lw3IvQ5eXYctXsPhvdsdTqsRzZiGoBMTkuB7rWJZTHaCOiPwpIitFpFteGxKRkSISLSLRcXFxToqr7OTv48mHw6Lo1aQC//pxB2+l9MS0HQOrJsO6z+2Op1SJZveZxV5AbaAzEAksE5HGxpj4nCsZY6ZgDYNNVFSUNhyXUD5eHvzn7uaU8vViwpLdJLYZyMs1tuGx4AkoUweqtLE7olIlkjMLwSGgco7rkY5lOcUCq4wxGcA+EdmJVRjWODGXcmGeHsK/+jUm2N+bKcv2srPCQ3xWah8+s4fC8AVwai/sWWINXBfZCm6faHdkpYo9ZzYNrQFqi0h1EfEB7ga+zbXON1h7A4hIGaymor1OzKSKARHhhR71mTy0BdsTPLn91COkpybDxNbWuQbrpoOHJ6z/Qg81VaoQOK0QGGMygUeARcA2YI4xZouIjBeRPo7VFgEnRWQrsAQYZ4w56axMqnjp1qgCi57oRLmaTRmW8iQLQgaTPuQbeO4APPgrBEdancnZ2XZHVapYE1PMjtWOiooy0dHRdsdQRcgYw2fL9/Pqgq10qFWGj+6Jws/bEzbMhq9Hwu2Todkgu2Mq5dJEZASUz2MAABsRSURBVK0xJiqv2/TMYuXyRITh7avz5p1N+GP3CUZ+vpbUjCxo3B8qNodfxkN6it0xlSq2tBCoYqN/VGX+r18Tlu2M46HP15KaZaDr65B4GFZop7FS10oLgSpWBrSqzBv9GvPbzjiGfLyKLT6NoF4v+ONdSDxmdzyliiUtBKrYubt1Ff5zdzP2xiXR+79/8DZDMFlpMO8+SNKT05W6WloIVLHUt1kllj59E8NvqM6kjfB89miyYqJhckc4sMLueEoVK1oIVLEVEuDN33s34MfHO7K3Qk96nX2F05nemGk9rdFLdcA6pQpEDx9VJUJGVjbPzd/E4nU7+bLsdBqfWQbiCcGVILQqhNeCTuMgJPdwV0q5h8sdPmr3WENKFQpvTw/e6t+Ed0P96f3LQzwZ2ZlRdZLxSTwIpw/Ahlmw7zcYvhCCK9gdVymXooVAlRgiwpO31qFSaT9e+NqD/6UF8OGwltQqGwQHV8EX/eCzXjD8ewgqb3dcpVyG9hGoEmdgqyp8MaINCWcz6DPhTxZsPGyNXDpkHpw5Ap/10aOLlMpBC4EqkdrVDGfBox2pXyGYR778i1e/20J6pTYwZA4kxFjF4PR+u2Mq5RK0EKgSq3yIH7NGtuW+9tWY+ud+ev33d9Z5NITBs+HMYetQ083z7Y6plO20EKgSzdvTg5d7N2Tq8FYkpmZy56TlvLo5nJT7l0JEPWte5P89AunJdkdVyjZaCJRbuKleWRY/0Ymhbaoy9c/9dJ22n/W3fgkdn4K/voApN0F8zJU3pFQJpIVAuY0gP2/+cXsj5o5qhzEwYEo0M4OGwz3fQOJR+PQ2iNtpd0ylipwWAuV2WlULY8GjHWhTI4znv9rEs+vCSBv2HWRlwNRucPgvuyMqVaS0ECi3FBrow7T7WvPozbWYHR3DXV8nEnvHV+AdCNN6w6Z51t5BWpLdUZVyOh1iQrm9n7Ye4+m5G8jMyubtbmXptm4UnNhxYQXfYGjQF3q+A14+9gVV6jpcbogJLQRKAYfiz/L4rL9Ys/80A5uF80qLVPxTj1uHmcbtgA1fQs2bYeAX4BNod1ylrppOVanUFVQq7c/MB9sytktt5m44yS1fZTM3vR2Z7R6DOyZBnwmwd6l1IlrKKbvjKlWotBAo5eDl6cETt9Zh9kPtCC/lw7h5G7ntvWUs3HSE7GZDYcB0OLoRpnaHY1vtjqtUodGmIaXyYIxh0ZZjvL14B7uOJxFVNZS3+jelWuJamDkY0hMhvDbU7wX1ekOlFiBid2yl8qV9BEpdo6xsw/x1sby2YCuZ2Ya/9azP4Po+yPYFsO072P8HmCxoPgx6/wc8PO2OrFSetBAodZ2OJJzlmXkb+X3XCTrXjeCNfk0oH+Jn9Rcsfx/+eBca3gF3TNEji5RL0s5ipa5ThRB/PruvNeP7NmTl3pN0eXspU5btId2nNNzyCnR9DbZ8DbMGQ8ZZu+MqdVV0j0Cpq3TgZDL/WLCVn7cdp2ZEIK/2aUSH2mUgeioseAIio6BsfYg/aP2Ip3XYadl6dkdXbkz3CJQqRFXDA/n43lZ8OjyKzGzD0E9WMWbGWg7Xuhvu/BiOb4cdP0JaIlRoCqnxMGsQnD1td3Sl8qR7BEpdh9SMLD5atpeJS3cjCI92qcUD7avj452j0/jgSpjWC6p3hMFzwVNniFVFT/cIlHISP29PHu1Sm5+fvJFOdcrw5o876Paf31m6I8dUmFXaQs+3YM+v8PPL9oVVKh9aCJQqBJGhAXw4LIpp97XCAMOnruGBz9aw/4RjwpuWw6HVg7BiAqz/0s6oSl1Cm4aUKmRpmVlM/XM///1lFxlZhhEdqzO2S238PLLh8ztg/+/WIHadX9AOZFVk9DwCpWxw/Ewqb/y4na/WHaJuuSDeu7sZ9cME/nwfVn5gTY/ZZADc+CyE17Q7rirhtBAoZaOlO47z9NyNnDmbwTPd6nJ/++p4nD0Ff74Hqz+CzFSo0w3ajobqnXSoCuUUtnUWi0g3EdkhIrtF5LnLrHeniBgRyTOkUsVZ57plWfR4R26sG8Fr329j4JQVfLMzleQbX4axG6DTOIhdDdP7wKQb4K8Z1mxpShURp+0RiIgnsBO4FYgF1gCDjDFbc60XBHwP+ACPGGMu+3Vf9whUcWWMYfaaGP77624OxZ/Fz9uDWxuU5+5WlWlftRRsngcrJ8GxzVC6CnR4EpoN0SErVKGwa4+gNbDbGLPXGJMOzAL65rHeP4D/A1KdmEUp24kId7euwu/P3MTcUe24q2Ukf+yKY8jHqxgxYxP7Kt8Bo/6AQbMhMAIWPA7vN7OmzcxLzBqYN8KaUlOp6+DMQlAJiMlxPdax7DwRaQFUNsZ8f7kNichIEYkWkei4uLjCT6pUEfLwEFpVC+O12xuz8oUuPN+9Hqv2naLru7/xzx+2k1i1CzzwCwz9CkqVg/kjYN79F85MzsqEpf8Hn95m7UVM7Q5HN9v7pFSxZtt5BCLiAbwDPHWldY0xU4wxUcaYqIiICOeHU6qI+Hp58tCNNfn16Ru5o3klPvp9L53eXMKHy/ZytkpnGPET3PwibP0ffHADbJwL03rC0n9C47vgwSXg5Wsti11r99NRxZQz+wjaAa8YY25zXH8ewBjzL8f1EGAPkOS4S3ngFNDncv0E2kegSrJNsQm8tXgHv+2MIyLIl0duqsXAVpXxi9sIX42EEzvBNxh6vgNN+lt3On3A6mhOPgGD50C19vY+CeWSbDl8VES8sDqLuwCHsDqLBxtjtuSz/lLgae0sVgpW7zvFW4t3sHrfKcICfRjYqjJDWkQQuf8rqN0VQqtefIczR2B6X4g/ALeOt85i9tCBA9QFtnQWG2MygUeARcA2YI4xZouIjBeRPs56XKVKgtbVw5g9si1fPtCGqKqhfPjbHjq+u5IRW5uxPink0jsEV4D7FkK1jvDDMzDjTjhzuOiDq2JJTyhTqhg4HH+WmasP8uWqg5xMTueO5pV4pltdKoT4X7yiMRD9KSx+ETx9oOfb0OhOPUlN6ZnFSpUUSWmZfLBkNx//sQ8PgZGdanJ7s4pULxOI5PywP7Ebvh4Jh9ZCzS7Q4986jIWb00KgVAkTcyqFN37czvcbjwBQMcSP9rXK0LluWbo1Ko+nh1iHma75GJa8bg1j0f5x6PgkePtfYet5OBtvHbnU9G7rKCVV7GghUKqEOnAymd93nWD5nhMs33OS+JQMGlYM5pU+DWlVLcxaKfEoLH4JNs0Bn1JQuTVUuQGqtoPIVlf+YE9LhOm3w6Fo6Pw8dM53tBjlwrQQKOUGsrINCzcd4Z8Lt3EkIZU+TSvyWJfaRAT5EuDjiXfMCtg8Hw6ugOOOkV78QqwhsRsPgKrtLz3SKD0FZvS37lO+MRzfBg+vhLAaRf8E1XXRQqCUG0lJz2Ty0j1MXraX9Mzs88t9PD1oEhnC+L6NaFA60/pw3/otbF8A6UkQVBEa3gENb4dKUZCdAbMGw+5frLmYq94AE1pZvwfPuboO6GNbILAslNITQu2ihUApNxRzKoU/dp8gOS2TlPQsElMz+GrdIeLPZvBgxxqM7VIbfx9P61v/joXWmEZ7foGsdAiuBEHlrc7mPv+FFvdYG10+ARb/De6eCfV6FCzIzkVWQancxjrEVdlCC4FSCoD4lHT+uXAbc6JjqRIWwKM31+LGuhGUDfKzVkhNgB0/wtZvYO9vcMvL0OahCxvIyoDJHa1JdR5eBT4Bl3/A/X/AF3dah7KmnYERP0PlVs57gipfWgiUUhdZvucEL36zmb1x1pzKDSsG06lOBL2aVKBhxTxOWMtp/x/W2EZtRkOtLnB6v/UjAg3ugEotrMuH1sFnfSC4IgyZCx92guodYeAXTn9+6lJaCJRSl8jONmw9cobfdsbx28441h04TWa2oXGlEAa2qkyfZhUJ9vPO+85fjYSNsy9c9/IHk2U1K4XVtDqg104D31Jw/yKrGPzyD/j9bXgkGsrUKpLnqC7QQqCUuqL4lHS++esQs9bEsP1oIn7eHrSoEkrzKqVpUSWUZpVLE17Kcahp6hnY/bPVlxBaDUqVtZqVtn0LG+dYew2lysL9P144wijpOLzbCJoNgt7/se15uistBEqpAjPGsCE2gW/+OkT0gVNsO5JIVrb1OVE2yJe65YOoVz6IJpGl6dqwHL5enpduJPEoeHhBYJmLly94wpqK8/FNEFSuCJ6NOkcLgVLqmp1Nz2LToQTWx5xmx9Ekdhw7w65jSaRlZlM+2I8HO9VgUOvKBPh4XXljJ/fAf1tChyesjmhVZLQQKKUKVVa24Y/dJ/hgyW5W7TtFaIA3w9pWpWeTitQpV+ricY9ym3MP7FkKT24B36CLb0s4BH99YR222n6szq1QiLQQKKWcZu2BU0xcsoclO45jDFQLD+C2RuW5pX45mkaWxscr19nKh9bCRzdDUAWo2BzKN4HSlWHbd7BrMZhs8A+zpuZs9zDc/BJ4Ow5vTT5hdVInHIIqbayhMq72JLWM1AvbcyNaCJRSTnc8MZWfth7jx81HWbHnJJnZBn9vT6KqhdKuZjiNKoZQOSyAiqX98N32tXWi2ZEN1qxrGGt+5mZDrJPXAiPgp5esIbUj6kP7x6yT3nb8ANmZ4OkLWWnWA5epY42ZVLYBlGsI5RrlXxyip8L3T0GzwdDtX5fukeRmjFWYPPLoBylmtBAopYpUwtkMVuw5ycq9J1m+5wQ7jyWdv00Eygf70apaGLc1LE/n6v4EJsdCRF3wzHW46q6f4H+PQNJRCChjjX7afKh1iOqRDXDgTziwHI6sh6RjF+5Xs4t1ZFLpyheWLf+vNU9D2QbWmEmlq8AdH1qD7+UlOwvmDofT+6wT4Yr5XoQWAqWUrU4kpbHneBIxp88ScyqF/Y5RU08lp+Pj5UH7muHUKRdE+RA/KoT4U7G0H1XDAwnx97aaiI5tdYyU6pP/gySfsMY0ilkFf7wH4gG3vQYt7oWlb8Bvb1jnN/T72Gqe+vohiD9o9UXc/OKlRejnV+GPd6zLHZ+GLi857wUqAloIlFIuJzMrm+gDp1m85Ri/7TxOzOmzFw2SBxAW6EPV8ADqlguie+MKtK8ZjpdnAWbYPb3f2pPY/zuE14KTu61mp97vg6fj6Ka0RFj0Aqybbk3x2f8zCAy3bts8H+bdDy2HW8NqbJwNI3+D8o0K9TUoSloIlFIuzxjDqeR0jiSkEnv6LAdPJbPvRAoHTiazKTaBxLRMwgN96NmkAp0d4yOFl/IhLNAn73MZsrNh7afWN/tmg+G2f106zDbA+pnw3Virj+LuGdayT7pChaZw73fWyKwTW0NIZXjg52LbX6CFQClVrKVlZrF0Rxzfrj/Mz9uOkZZrz6FCiB9NI0vTtHJpmkaG0KxK6QvnNWRnXfnD+9BamDXUaobyC7HWH7nUOjsarJFZ54+wikm7MRful5lmDah3LXNCr5tudZh3eBIiW155/TRHP4tvqat/LLQQKKVKkKS0THYcPcPJpHROJqdzIjGN3XFJbIiJZ//JFMCae6Fl1VA61ilDx1oR1KsQhPeVmpQSj1nnOBzZAPf/YB3aeo4x8OVAq6npzk+sdfYugdhoq7mo17tQqQAf5ue29dubsPSf4OFtzfvQ4Hbo8ve855XOSIXoT+D3d6DVA3DT8wV8pS6mhUAp5RZOJ6ezPjaeFXtO8vuuE2w7cgYALw+hSlgANSJKUSUsgMTUDI4lpnH8TCppmdl0qVeWO1pUokG5QCTtDASEXbrx+Bj4oK3VVCQeVqGo3NbqT0g6BlH3Wx3K/qH5B8zOgh+ehTUfQdPB0O2fsHKSNc9DVhrU721tt1xD67DZXYvgt39D4mGo0dk6pyIyz8/yK9JCoJRyS8cTU1mx5yQ7jyWyNy6ZPXFJxJw6S4i/N+WCfSkb7EdWtuH3XXFkZBnqlguid9MKtKoWRpPI0tbEPTnFrIbEI1bn8rlikXoGlvwTVn8IAeFQ6xarg7pMbWtAPrCakDJTrfMitnwNNzwGt46/0KSUeAyWvWmdJ3Hm0MWPGdnaKjDVO13Xa6GFQCmlLuN0cjoLNh3hq3Wx/HUwHrD2IupXCKZRpRBqRgRSIyKQ6mVKERnqn3cz05GNsOR163fi4fwf7NZ/WCfI5SfllDWn9LGt1sittbpcWx9ELloIlFKqgE4lp/PXwdOsO3iadQfi2XrkDAlnM87f7iFQIcSfKmEBVA7zv2iwPQ8RapYNpGUFH2p7HsUzIcbqePbyBS8/KFXetrkYLlcICjBcoFJKuY+wQB+61C9Hl/oXhsk+nZzO3hNJ7IlLJuZUCgdPpRBzKoUlO+JIy8g6v15mtiEl3boe6ONJw0oRhAX44O/jib+PJyH+mTSocJgmkSFUCQu4/OB8RUgLgVJKXUFooA8tA8NoWTWPTuQcjDEcPJXCuoOn+etgPFsOn2HfiWRSMjI5m55FwtkMMrKsVphgPy8aVQqhTrkgapcrRZ1yQVQJCyDE3xs/76I9V0ELgVJKFRIRoWp4IFXDA7mjeeQlt2dkZbPzWCKbYhPYeCiBLYfPMDc6huT0rIvW8/P2oLS/D37eHniIgFjNTne3qswDHWsUem4tBEopVUS8PT1oWDGEhhVDuNuxzBjDofiz7DqWRGz8Wc6czSA+JZ34lAzSMrMxQLYxYKDMualCC5kWAqWUspGIEBkaQGRogG0ZCjB6k1JKqZJMC4FSSrk5LQRKKeXmnFoIRKSbiOwQkd0i8lwetz8pIltFZKOI/CIiVZ2ZRyml1KWcVghExBOYCHQHGgCDRKRBrtX+AqKMMU2AecCbzsqjlFIqb87cI2gN7DbG7DXGpAOzgL45VzDGLDHGpDiurgQuPfBWKaWUUzmzEFQCYnJcj3Usy88I4Ie8bhCRkSISLSLRcXFxhRhRKaWUS3QWi8hQIAr4d163G2OmGGOijDFRERERRRtOKaVKOGeeUHYIqJzjeqRj2UVE5Bbgb8CNxpi0K2107dq1J0TkwFXkKAOcuIr1i4qr5gLXzeaqucB1s7lqLnDdbK6aC64vW74H4zhtGGoR8QJ2Al2wCsAaYLAxZkuOdZpjdRJ3M8bsclKO6PyGXrWTq+YC183mqrnAdbO5ai5w3Wyumgucl81pTUPGmEzgEWARsA2YY4zZIiLjRaSPY7V/A6WAuSKyXkS+dVYepZRSeXPqWEPGmIXAwlzL/p7j8i3OfHyllFJX5hKdxU42xe4A+XDVXOC62Vw1F7huNlfNBa6bzVVzgZOyFbupKpVSShUud9gjUEopdRlaCJRSys2V2EJwpQHvijjLpyJyXEQ251gWJiI/icgux+9QG3JVFpEljoH/tojIWBfK5iciq0VkgyPbq47l1UVkleN9nS0iPkWdzZHDU0T+EpEFLpZrv4hschyFF+1Y5grvZ2kRmSci20Vkm4i0c5FcdR2v1bmfMyLyuItke8Lxt79ZRGY6/iec8ndWIgtBAQe8K0rTgG65lj0H/GKMqQ384rhe1DKBp4wxDYC2wMOO18kVsqUBNxtjmgLNgG4i0hb4P+BdY0wt4DTW0CR2GIt1WPQ5rpIL4CZjTLMcx5u7wvv5H+BHY0w9oCnWa2d7LmPMDsdr1QxoCaQAX9udTUQqAY9hDcrZCPAE7sZZf2fGmBL3A7QDFuW4/jzwvM2ZqgGbc1zfAVRwXK4A7HCB1+1/wK2ulg0IANYBbbDOqvTK630uwjyRWB8ONwMLAHGFXI7H3g+UybXM1vcTCAH24Tg4xVVy5ZGzK/CnK2TjwlhtYViH+S8AbnPW31mJ3CPg6ge8s0M5Y8wRx+WjQDk7w4hINaA5sAoXyeZoflkPHAd+AvYA8cY6WRHse1/fA54Bsh3Xw10kF4ABFovIWhEZ6Vhm9/tZHYgDpjqa0z4WkUAXyJXb3cBMx2VbsxljDgFvAQeBI0ACsBYn/Z2V1EJQrBirvNt2HK+IlALmA48bY87kvM3ObMaYLGPtskdiDWtez44cOYlIL+C4MWat3Vny0cEY0wKrWfRhEemU80ab3k8voAUwyRjTHEgmV1OLC/wP+AB9gLm5b7Mjm6NPoi9WEa0IBHJp83KhKamFoEAD3tnsmIhUAHD8Pm5HCBHxxioCM4wxX7lStnOMMfHAEqxd4dKOcazAnve1PdBHRPZjzbFxM1b7t925gPPfJDHGHMdq626N/e9nLBBrjFnluD4PqzDYnSun7sA6Y8wxx3W7s90C7DPGxBljMoCvsP72nPJ3VlILwRqgtqOH3Qdrl8/VxjH6FrjXcflerPb5IiUiAnwCbDPGvONi2SJEpLTjsj9W38U2rIJwl13ZjDHPG2MijTHVsP6ufjXGDLE7F4CIBIpI0LnLWG3em7H5/TTGHAViRKSuY1EXYKvduXIZxIVmIbA/20GgrYgEOP5Pz71mzvk7s7NzxsmdLT2wRj/dA/zN5iwzsdr5MrC+HY3Aalf+BdgF/AyE2ZCrA9Yu70ZgveOnh4tka4I1lelGrA+zvzuW1wBWA7uxduN9bXxfOwMLXCWXI8MGx8+Wc3/3LvJ+NgOiHe/nN0CoK+RyZAsETgIhOZbZng14Fdju+Pv/HPB11t+ZDjGhlFJurqQ2DSmllCogLQRKKeXmtBAopZSb00KglFJuTguBUkq5OS0ESjmISFaukSgLbaAxEakmOUafVcqVOHXOYqWKmbPGGtJCKbeiewRKXYFjjP83HeP8rxaRWo7l1UTkVxHZKCK/iEgVx/JyIvK1Yy6FDSJyg2NTniLykWOM+cWOM6YRkcfEmhNio4jMsulpKjemhUCpC/xzNQ0NzHFbgjGmMTABa/RRgP8CnxljmgAzgPcdy98HfjPWXAotsM7yBagNTDTGNATigTsdy58Dmju2M8pZT06p/OiZxUo5iEiSMaZUHsv3Y02Ss9cxSN9RY0y4iJzAGrM+w7H8iDGmjIjEAZHGmLQc26gG/GSsiU4QkWcBb2PMayLyI5CENfTCN8aYJCc/VaUuonsEShWMyefy1UjLcTmLC310PbFm1GsBrMkxuqRSRUILgVIFMzDH7xWOy8uxRiAFGAL87rj8CzAazk+uE5LfRkXEA6hsjFkCPIs1m9cleyVKOZN+81DqAn/HjGjn/GiMOXcIaaiIbMT6Vj/IsexRrFm3xmHNwHWfY/lYYIqIjMD65j8aa/TZvHgCXziKhQDvG2v+BaWKjPYRKHUFjj6CKGPMCbuzKOUM2jSklFJuTvcIlFLKzekegVJKuTktBEop5ea0ECillJvTQqCUUm5OC4FSSrm5/wcQOk9Lw1V5EwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00019015 0.00041561 0.09939425]\n",
            " [0.00597752 0.07513227 0.01889022]\n",
            " [0.0035764  0.09517413 0.00124947]\n",
            " ...\n",
            " [0.00594402 0.09197426 0.00208172]\n",
            " [0.03331861 0.02692301 0.03975838]\n",
            " [0.01042301 0.08770167 0.00187532]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'MLP_ADAM'\n",
        "NAME = 'Landsat8_DATA'\n",
        "optimiser_type = 'adam'\n",
        "experimental_runs = 10\n",
        "\n",
        "best_model, best_history, avg_y_pred, df = MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "best_model.save('Best_model_{}_{}'.format(NAME, Model_name))\n",
        "plot_metric(best_history, \"loss\")\n",
        "print(\"\")\n",
        "plot_metric(best_history, \"accuracy\")\n",
        "# plot_AUC_ROC(best_model, test_x, test_y, 3, label_names)\n",
        "# print(\"\")\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "print(avg_y_pred)\n",
        "test_y_dummies = test_y.argmax(axis = 1)\n",
        "plot_avg_AUC_ROC(avg_y_pred, test_y_dummies, 3, label_names)\n",
        "print(\"\")\n",
        "avg_y_pred = avg_y_pred.argmax(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gLl3OB2T6kdO",
        "outputId": "963dbf71-8eb9-4d67-a0ea-110cd6cceffe"
      },
      "id": "gLl3OB2T6kdO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_98 (Dense)            (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_99 (Dense)            (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0753 - accuracy: 0.5581 - val_loss: 1.0673 - val_accuracy: 0.7311\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0653 - accuracy: 0.6105 - val_loss: 1.0629 - val_accuracy: 0.5844\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0589 - accuracy: 0.6552 - val_loss: 1.0547 - val_accuracy: 0.6689\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0512 - accuracy: 0.6695 - val_loss: 1.0482 - val_accuracy: 0.7067\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0433 - accuracy: 0.7314 - val_loss: 1.0391 - val_accuracy: 0.7044\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0279 - accuracy: 0.6762 - val_loss: 1.0216 - val_accuracy: 0.7444\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0155 - accuracy: 0.7505 - val_loss: 1.0121 - val_accuracy: 0.8378\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0028 - accuracy: 0.7438 - val_loss: 0.9966 - val_accuracy: 0.8467\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9858 - accuracy: 0.7886 - val_loss: 0.9808 - val_accuracy: 0.8489\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9702 - accuracy: 0.7952 - val_loss: 0.9636 - val_accuracy: 0.7867\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9505 - accuracy: 0.8038 - val_loss: 0.9475 - val_accuracy: 0.7467\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9316 - accuracy: 0.8086 - val_loss: 0.9256 - val_accuracy: 0.8044\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9086 - accuracy: 0.8390 - val_loss: 0.9046 - val_accuracy: 0.8356\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8868 - accuracy: 0.8371 - val_loss: 0.8842 - val_accuracy: 0.8622\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8665 - accuracy: 0.8495 - val_loss: 0.8616 - val_accuracy: 0.8400\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8417 - accuracy: 0.8571 - val_loss: 0.8436 - val_accuracy: 0.8000\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8202 - accuracy: 0.8514 - val_loss: 0.8175 - val_accuracy: 0.8422\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7957 - accuracy: 0.8533 - val_loss: 0.7967 - val_accuracy: 0.8267\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7708 - accuracy: 0.8552 - val_loss: 0.7762 - val_accuracy: 0.8556\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7502 - accuracy: 0.8619 - val_loss: 0.7519 - val_accuracy: 0.8511\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7260 - accuracy: 0.8581 - val_loss: 0.7427 - val_accuracy: 0.8622\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7111 - accuracy: 0.8571 - val_loss: 0.7171 - val_accuracy: 0.8067\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6860 - accuracy: 0.8610 - val_loss: 0.6925 - val_accuracy: 0.8467\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.8648 - val_loss: 0.6772 - val_accuracy: 0.8311\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6501 - accuracy: 0.8505 - val_loss: 0.6629 - val_accuracy: 0.8556\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6281 - accuracy: 0.8667 - val_loss: 0.6441 - val_accuracy: 0.8133\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6127 - accuracy: 0.8495 - val_loss: 0.6248 - val_accuracy: 0.8356\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5932 - accuracy: 0.8657 - val_loss: 0.6037 - val_accuracy: 0.8556\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5764 - accuracy: 0.8638 - val_loss: 0.5854 - val_accuracy: 0.8511\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.8610 - val_loss: 0.5755 - val_accuracy: 0.8533\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5434 - accuracy: 0.8752 - val_loss: 0.5606 - val_accuracy: 0.8533\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5298 - accuracy: 0.8686 - val_loss: 0.5448 - val_accuracy: 0.8533\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5138 - accuracy: 0.8695 - val_loss: 0.5285 - val_accuracy: 0.8511\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5006 - accuracy: 0.8762 - val_loss: 0.5150 - val_accuracy: 0.8533\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8714 - val_loss: 0.5065 - val_accuracy: 0.8578\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4742 - accuracy: 0.8781 - val_loss: 0.4899 - val_accuracy: 0.8578\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.8762 - val_loss: 0.4876 - val_accuracy: 0.8511\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4567 - accuracy: 0.8724 - val_loss: 0.4707 - val_accuracy: 0.8578\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4441 - accuracy: 0.8714 - val_loss: 0.4600 - val_accuracy: 0.8556\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4338 - accuracy: 0.8724 - val_loss: 0.4516 - val_accuracy: 0.8600\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4359 - accuracy: 0.8686 - val_loss: 0.4454 - val_accuracy: 0.8533\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4136 - accuracy: 0.8781 - val_loss: 0.4331 - val_accuracy: 0.8600\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8762 - val_loss: 0.4317 - val_accuracy: 0.8600\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3970 - accuracy: 0.8819 - val_loss: 0.4182 - val_accuracy: 0.8600\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3945 - accuracy: 0.8714 - val_loss: 0.4109 - val_accuracy: 0.8578\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3830 - accuracy: 0.8800 - val_loss: 0.4116 - val_accuracy: 0.8667\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3801 - accuracy: 0.8829 - val_loss: 0.4078 - val_accuracy: 0.8556\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3709 - accuracy: 0.8867 - val_loss: 0.4005 - val_accuracy: 0.8556\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3686 - accuracy: 0.8867 - val_loss: 0.4062 - val_accuracy: 0.8578\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3571 - accuracy: 0.8800 - val_loss: 0.3856 - val_accuracy: 0.8622\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3543 - accuracy: 0.8800 - val_loss: 0.3754 - val_accuracy: 0.8622\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3489 - accuracy: 0.8838 - val_loss: 0.3673 - val_accuracy: 0.8644\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3449 - accuracy: 0.8914 - val_loss: 0.3796 - val_accuracy: 0.8644\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8895 - val_loss: 0.3604 - val_accuracy: 0.8622\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3264 - accuracy: 0.8905 - val_loss: 0.3563 - val_accuracy: 0.8711\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3253 - accuracy: 0.8943 - val_loss: 0.3459 - val_accuracy: 0.8711\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3202 - accuracy: 0.8905 - val_loss: 0.3415 - val_accuracy: 0.8733\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3150 - accuracy: 0.8952 - val_loss: 0.3499 - val_accuracy: 0.8711\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3142 - accuracy: 0.8876 - val_loss: 0.3450 - val_accuracy: 0.8689\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3071 - accuracy: 0.8952 - val_loss: 0.3373 - val_accuracy: 0.8733\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8914 - val_loss: 0.3275 - val_accuracy: 0.8711\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3028 - accuracy: 0.8914 - val_loss: 0.3238 - val_accuracy: 0.8733\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2983 - accuracy: 0.8971 - val_loss: 0.3248 - val_accuracy: 0.8778\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2939 - accuracy: 0.8971 - val_loss: 0.3174 - val_accuracy: 0.8756\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.8914 - val_loss: 0.3196 - val_accuracy: 0.8689\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2941 - accuracy: 0.8914 - val_loss: 0.3188 - val_accuracy: 0.8644\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8981 - val_loss: 0.3100 - val_accuracy: 0.8689\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2855 - accuracy: 0.8962 - val_loss: 0.3126 - val_accuracy: 0.8756\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2804 - accuracy: 0.8990 - val_loss: 0.3049 - val_accuracy: 0.8733\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2757 - accuracy: 0.8990 - val_loss: 0.3016 - val_accuracy: 0.8733\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2748 - accuracy: 0.9019 - val_loss: 0.3080 - val_accuracy: 0.8756\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.9029 - val_loss: 0.2961 - val_accuracy: 0.8733\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2702 - accuracy: 0.9038 - val_loss: 0.2998 - val_accuracy: 0.8778\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2694 - accuracy: 0.8990 - val_loss: 0.2936 - val_accuracy: 0.8733\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2679 - accuracy: 0.8990 - val_loss: 0.2979 - val_accuracy: 0.8689\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2651 - accuracy: 0.8971 - val_loss: 0.2877 - val_accuracy: 0.8756\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2603 - accuracy: 0.9057 - val_loss: 0.2842 - val_accuracy: 0.8733\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2623 - accuracy: 0.9105 - val_loss: 0.2959 - val_accuracy: 0.8822\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.9010 - val_loss: 0.2864 - val_accuracy: 0.8800\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2563 - accuracy: 0.9105 - val_loss: 0.2780 - val_accuracy: 0.8778\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[144   2   8]\n",
            " [  0 130  15]\n",
            " [  9  21 121]]\n",
            "\n",
            "P-Score: 0.877, R-Score: 0.878, F-Score: 0.877\n",
            "[0.8777777777777778, 0.8770424836601306, 0.8776470541713747, 0.876977651237675, 0.9523297648297648, 0.9105709440361787, 0.8622007131940908, 0.9083671406866781]\n",
            "Model: \"sequential_49\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_101 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 12ms/step - loss: 1.0961 - accuracy: 0.3667 - val_loss: 1.0907 - val_accuracy: 0.4867\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0886 - accuracy: 0.3667 - val_loss: 1.0868 - val_accuracy: 0.4978\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0844 - accuracy: 0.4600 - val_loss: 1.0822 - val_accuracy: 0.6044\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0803 - accuracy: 0.4076 - val_loss: 1.0779 - val_accuracy: 0.4022\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0739 - accuracy: 0.4724 - val_loss: 1.0734 - val_accuracy: 0.3844\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0681 - accuracy: 0.5267 - val_loss: 1.0668 - val_accuracy: 0.6600\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0633 - accuracy: 0.5305 - val_loss: 1.0602 - val_accuracy: 0.6644\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0553 - accuracy: 0.4895 - val_loss: 1.0548 - val_accuracy: 0.4911\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0468 - accuracy: 0.7067 - val_loss: 1.0464 - val_accuracy: 0.5467\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0385 - accuracy: 0.6733 - val_loss: 1.0371 - val_accuracy: 0.7067\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0276 - accuracy: 0.6276 - val_loss: 1.0263 - val_accuracy: 0.7667\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0120 - accuracy: 0.6590 - val_loss: 1.0082 - val_accuracy: 0.6378\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9902 - accuracy: 0.6200 - val_loss: 0.9849 - val_accuracy: 0.5333\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9673 - accuracy: 0.7371 - val_loss: 0.9651 - val_accuracy: 0.7756\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9489 - accuracy: 0.7657 - val_loss: 0.9472 - val_accuracy: 0.7511\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9303 - accuracy: 0.6571 - val_loss: 0.9304 - val_accuracy: 0.8333\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9119 - accuracy: 0.6562 - val_loss: 0.9127 - val_accuracy: 0.5711\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8917 - accuracy: 0.6705 - val_loss: 0.9052 - val_accuracy: 0.8200\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8763 - accuracy: 0.7324 - val_loss: 0.8781 - val_accuracy: 0.7422\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8559 - accuracy: 0.7924 - val_loss: 0.8614 - val_accuracy: 0.8289\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8412 - accuracy: 0.8324 - val_loss: 0.8496 - val_accuracy: 0.8311\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8295 - accuracy: 0.7352 - val_loss: 0.8372 - val_accuracy: 0.6911\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8155 - accuracy: 0.7181 - val_loss: 0.8303 - val_accuracy: 0.7511\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8037 - accuracy: 0.6819 - val_loss: 0.8116 - val_accuracy: 0.7556\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7925 - accuracy: 0.7610 - val_loss: 0.8034 - val_accuracy: 0.8311\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7811 - accuracy: 0.8200 - val_loss: 0.7925 - val_accuracy: 0.8067\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.7467 - val_loss: 0.7857 - val_accuracy: 0.8289\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7633 - accuracy: 0.8295 - val_loss: 0.7794 - val_accuracy: 0.8067\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7588 - accuracy: 0.8029 - val_loss: 0.7686 - val_accuracy: 0.8200\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.7076 - val_loss: 0.7722 - val_accuracy: 0.6511\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7412 - accuracy: 0.7076 - val_loss: 0.7585 - val_accuracy: 0.7222\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7341 - accuracy: 0.8124 - val_loss: 0.7530 - val_accuracy: 0.8267\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7303 - accuracy: 0.8143 - val_loss: 0.7451 - val_accuracy: 0.8089\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7232 - accuracy: 0.8152 - val_loss: 0.7399 - val_accuracy: 0.8200\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7156 - accuracy: 0.8324 - val_loss: 0.7331 - val_accuracy: 0.8222\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7135 - accuracy: 0.8295 - val_loss: 0.7292 - val_accuracy: 0.8000\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7110 - accuracy: 0.8152 - val_loss: 0.7265 - val_accuracy: 0.8156\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7014 - accuracy: 0.8181 - val_loss: 0.7193 - val_accuracy: 0.8267\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.8352 - val_loss: 0.7140 - val_accuracy: 0.8067\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6886 - accuracy: 0.8238 - val_loss: 0.7178 - val_accuracy: 0.8400\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.8276 - val_loss: 0.7076 - val_accuracy: 0.8178\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6806 - accuracy: 0.8238 - val_loss: 0.6974 - val_accuracy: 0.8311\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6796 - accuracy: 0.8095 - val_loss: 0.6928 - val_accuracy: 0.8333\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6742 - accuracy: 0.8067 - val_loss: 0.6955 - val_accuracy: 0.8356\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.8000 - val_loss: 0.6845 - val_accuracy: 0.8444\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6565 - accuracy: 0.8400 - val_loss: 0.6813 - val_accuracy: 0.7778\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6542 - accuracy: 0.8314 - val_loss: 0.6710 - val_accuracy: 0.8067\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6452 - accuracy: 0.8419 - val_loss: 0.6655 - val_accuracy: 0.8089\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.8257 - val_loss: 0.6591 - val_accuracy: 0.8133\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6320 - accuracy: 0.8371 - val_loss: 0.6695 - val_accuracy: 0.8267\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6293 - accuracy: 0.8371 - val_loss: 0.6509 - val_accuracy: 0.8444\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6174 - accuracy: 0.8457 - val_loss: 0.6374 - val_accuracy: 0.8356\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6105 - accuracy: 0.8448 - val_loss: 0.6399 - val_accuracy: 0.8267\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.8400 - val_loss: 0.6244 - val_accuracy: 0.8244\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5987 - accuracy: 0.8381 - val_loss: 0.6187 - val_accuracy: 0.8356\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.8286 - val_loss: 0.6152 - val_accuracy: 0.8044\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5860 - accuracy: 0.8410 - val_loss: 0.6022 - val_accuracy: 0.8422\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5787 - accuracy: 0.8505 - val_loss: 0.5943 - val_accuracy: 0.8378\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5722 - accuracy: 0.8505 - val_loss: 0.5893 - val_accuracy: 0.8244\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5631 - accuracy: 0.8486 - val_loss: 0.5824 - val_accuracy: 0.8378\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5589 - accuracy: 0.8552 - val_loss: 0.5742 - val_accuracy: 0.8356\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5579 - accuracy: 0.8267 - val_loss: 0.5776 - val_accuracy: 0.7933\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5413 - accuracy: 0.8467 - val_loss: 0.5614 - val_accuracy: 0.8311\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5321 - accuracy: 0.8467 - val_loss: 0.5618 - val_accuracy: 0.8067\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5243 - accuracy: 0.8533 - val_loss: 0.5451 - val_accuracy: 0.8356\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5260 - accuracy: 0.8514 - val_loss: 0.5404 - val_accuracy: 0.8267\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5112 - accuracy: 0.8543 - val_loss: 0.5303 - val_accuracy: 0.8444\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4994 - accuracy: 0.8571 - val_loss: 0.5315 - val_accuracy: 0.8533\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4951 - accuracy: 0.8552 - val_loss: 0.5174 - val_accuracy: 0.8422\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4877 - accuracy: 0.8629 - val_loss: 0.5061 - val_accuracy: 0.8378\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8533 - val_loss: 0.5030 - val_accuracy: 0.8511\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4711 - accuracy: 0.8590 - val_loss: 0.4969 - val_accuracy: 0.8467\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4673 - accuracy: 0.8600 - val_loss: 0.4973 - val_accuracy: 0.8489\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.8648 - val_loss: 0.4910 - val_accuracy: 0.8489\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8571 - val_loss: 0.4778 - val_accuracy: 0.8578\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8638 - val_loss: 0.4738 - val_accuracy: 0.8600\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4400 - accuracy: 0.8638 - val_loss: 0.4612 - val_accuracy: 0.8489\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8724 - val_loss: 0.4718 - val_accuracy: 0.8378\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8590 - val_loss: 0.4493 - val_accuracy: 0.8511\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.8714 - val_loss: 0.4440 - val_accuracy: 0.8511\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[136   8  10]\n",
            " [  0 128  17]\n",
            " [ 14  18 119]]\n",
            "\n",
            "P-Score: 0.851, R-Score: 0.851, F-Score: 0.851\n",
            "[0.8511111111111112, 0.8509679969953942, 0.8513183246684045, 0.8507569781406548, 0.9179097929097928, 0.8987563595251554, 0.8488892334270971, 0.8885184619540151]\n",
            "Model: \"sequential_50\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_104 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1281 - accuracy: 0.2657 - val_loss: 1.1182 - val_accuracy: 0.0867\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1166 - accuracy: 0.1543 - val_loss: 1.1142 - val_accuracy: 0.3222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1116 - accuracy: 0.3343 - val_loss: 1.1092 - val_accuracy: 0.1911\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1082 - accuracy: 0.1352 - val_loss: 1.1044 - val_accuracy: 0.1422\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1017 - accuracy: 0.2143 - val_loss: 1.1007 - val_accuracy: 0.1378\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0970 - accuracy: 0.3067 - val_loss: 1.0956 - val_accuracy: 0.2844\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.2190 - val_loss: 1.0883 - val_accuracy: 0.2533\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0830 - accuracy: 0.3676 - val_loss: 1.0815 - val_accuracy: 0.4133\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.4248 - val_loss: 1.0740 - val_accuracy: 0.3311\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0653 - accuracy: 0.4590 - val_loss: 1.0647 - val_accuracy: 0.4444\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0557 - accuracy: 0.5162 - val_loss: 1.0550 - val_accuracy: 0.4222\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0450 - accuracy: 0.4648 - val_loss: 1.0457 - val_accuracy: 0.5267\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0330 - accuracy: 0.4886 - val_loss: 1.0336 - val_accuracy: 0.4333\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0211 - accuracy: 0.4771 - val_loss: 1.0226 - val_accuracy: 0.4844\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0086 - accuracy: 0.5105 - val_loss: 1.0120 - val_accuracy: 0.4333\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9953 - accuracy: 0.5000 - val_loss: 0.9996 - val_accuracy: 0.4911\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9814 - accuracy: 0.5476 - val_loss: 0.9877 - val_accuracy: 0.5289\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9685 - accuracy: 0.5714 - val_loss: 0.9728 - val_accuracy: 0.5600\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9542 - accuracy: 0.5543 - val_loss: 0.9646 - val_accuracy: 0.5178\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9376 - accuracy: 0.5733 - val_loss: 0.9451 - val_accuracy: 0.5422\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9228 - accuracy: 0.5924 - val_loss: 0.9307 - val_accuracy: 0.5311\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9066 - accuracy: 0.5771 - val_loss: 0.9155 - val_accuracy: 0.5800\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8893 - accuracy: 0.6467 - val_loss: 0.9018 - val_accuracy: 0.5378\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8760 - accuracy: 0.5743 - val_loss: 0.8891 - val_accuracy: 0.5422\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8610 - accuracy: 0.5848 - val_loss: 0.8745 - val_accuracy: 0.7244\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8462 - accuracy: 0.6438 - val_loss: 0.8618 - val_accuracy: 0.5400\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8302 - accuracy: 0.6010 - val_loss: 0.8511 - val_accuracy: 0.7333\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8200 - accuracy: 0.6657 - val_loss: 0.8389 - val_accuracy: 0.6289\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8069 - accuracy: 0.6419 - val_loss: 0.8315 - val_accuracy: 0.7222\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7992 - accuracy: 0.6933 - val_loss: 0.8167 - val_accuracy: 0.7222\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7890 - accuracy: 0.6657 - val_loss: 0.8077 - val_accuracy: 0.7000\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7798 - accuracy: 0.6914 - val_loss: 0.8029 - val_accuracy: 0.6289\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7736 - accuracy: 0.6857 - val_loss: 0.7999 - val_accuracy: 0.6333\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7658 - accuracy: 0.6857 - val_loss: 0.7891 - val_accuracy: 0.7022\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7647 - accuracy: 0.6848 - val_loss: 0.7899 - val_accuracy: 0.6800\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7614 - accuracy: 0.6905 - val_loss: 0.7796 - val_accuracy: 0.7067\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7529 - accuracy: 0.6952 - val_loss: 0.7773 - val_accuracy: 0.6689\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7457 - accuracy: 0.6924 - val_loss: 0.7695 - val_accuracy: 0.7156\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7421 - accuracy: 0.6914 - val_loss: 0.7751 - val_accuracy: 0.7022\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.6876 - val_loss: 0.7616 - val_accuracy: 0.7089\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7356 - accuracy: 0.7019 - val_loss: 0.7564 - val_accuracy: 0.7200\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7314 - accuracy: 0.6952 - val_loss: 0.7517 - val_accuracy: 0.7133\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.7124 - val_loss: 0.7571 - val_accuracy: 0.7044\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.6990 - val_loss: 0.7473 - val_accuracy: 0.7133\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7227 - accuracy: 0.7067 - val_loss: 0.7559 - val_accuracy: 0.6756\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7142 - accuracy: 0.6943 - val_loss: 0.7481 - val_accuracy: 0.7200\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7109 - accuracy: 0.7238 - val_loss: 0.7449 - val_accuracy: 0.6556\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7161 - accuracy: 0.6800 - val_loss: 0.7474 - val_accuracy: 0.6622\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7055 - accuracy: 0.7162 - val_loss: 0.7271 - val_accuracy: 0.7511\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7024 - accuracy: 0.7133 - val_loss: 0.7217 - val_accuracy: 0.7267\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7012 - accuracy: 0.7390 - val_loss: 0.7215 - val_accuracy: 0.7200\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6940 - accuracy: 0.7314 - val_loss: 0.7134 - val_accuracy: 0.7556\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6881 - accuracy: 0.7495 - val_loss: 0.7078 - val_accuracy: 0.7644\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6831 - accuracy: 0.7552 - val_loss: 0.7111 - val_accuracy: 0.7444\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6801 - accuracy: 0.7562 - val_loss: 0.7068 - val_accuracy: 0.7200\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6755 - accuracy: 0.7543 - val_loss: 0.6969 - val_accuracy: 0.7844\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6710 - accuracy: 0.7467 - val_loss: 0.6917 - val_accuracy: 0.7867\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.7810 - val_loss: 0.6854 - val_accuracy: 0.7933\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6604 - accuracy: 0.7781 - val_loss: 0.6816 - val_accuracy: 0.7933\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.7914 - val_loss: 0.6790 - val_accuracy: 0.7933\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6494 - accuracy: 0.7981 - val_loss: 0.6706 - val_accuracy: 0.7956\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6436 - accuracy: 0.7867 - val_loss: 0.6741 - val_accuracy: 0.8089\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.8086 - val_loss: 0.6614 - val_accuracy: 0.8044\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6332 - accuracy: 0.8029 - val_loss: 0.6644 - val_accuracy: 0.8200\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6280 - accuracy: 0.8200 - val_loss: 0.6496 - val_accuracy: 0.8156\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.8295 - val_loss: 0.6504 - val_accuracy: 0.8044\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6166 - accuracy: 0.8067 - val_loss: 0.6442 - val_accuracy: 0.8244\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.8162 - val_loss: 0.6387 - val_accuracy: 0.8200\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6075 - accuracy: 0.8343 - val_loss: 0.6347 - val_accuracy: 0.8111\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.8295 - val_loss: 0.6225 - val_accuracy: 0.8422\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5941 - accuracy: 0.8238 - val_loss: 0.6161 - val_accuracy: 0.8467\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5887 - accuracy: 0.8362 - val_loss: 0.6125 - val_accuracy: 0.8222\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5919 - accuracy: 0.8105 - val_loss: 0.6187 - val_accuracy: 0.8400\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5786 - accuracy: 0.8257 - val_loss: 0.5972 - val_accuracy: 0.8356\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.8390 - val_loss: 0.5934 - val_accuracy: 0.8533\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5677 - accuracy: 0.8371 - val_loss: 0.6093 - val_accuracy: 0.8200\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5626 - accuracy: 0.8438 - val_loss: 0.5882 - val_accuracy: 0.8511\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5557 - accuracy: 0.8514 - val_loss: 0.5777 - val_accuracy: 0.8333\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5441 - accuracy: 0.8533 - val_loss: 0.5696 - val_accuracy: 0.8356\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5400 - accuracy: 0.8448 - val_loss: 0.5756 - val_accuracy: 0.8533\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[144   4   6]\n",
            " [  0 131  14]\n",
            " [ 23  19 109]]\n",
            "\n",
            "P-Score: 0.853, R-Score: 0.853, F-Score: 0.851\n",
            "[0.8533333333333334, 0.8526286800204081, 0.8534558385209219, 0.8506739569518927, 0.928681116181116, 0.9140192198982476, 0.8274823362643691, 0.8900608907812443]\n",
            "Model: \"sequential_51\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_107 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.0962 - accuracy: 0.3362 - val_loss: 1.0875 - val_accuracy: 0.4178\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0795 - accuracy: 0.4467 - val_loss: 1.0773 - val_accuracy: 0.3511\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0697 - accuracy: 0.4333 - val_loss: 1.0664 - val_accuracy: 0.4933\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0582 - accuracy: 0.5257 - val_loss: 1.0539 - val_accuracy: 0.5400\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0399 - accuracy: 0.6943 - val_loss: 1.0315 - val_accuracy: 0.7911\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0182 - accuracy: 0.7324 - val_loss: 1.0133 - val_accuracy: 0.6756\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9999 - accuracy: 0.6171 - val_loss: 0.9946 - val_accuracy: 0.7422\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9783 - accuracy: 0.6867 - val_loss: 0.9754 - val_accuracy: 0.7044\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9586 - accuracy: 0.6410 - val_loss: 0.9587 - val_accuracy: 0.6133\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9363 - accuracy: 0.7248 - val_loss: 0.9341 - val_accuracy: 0.7156\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9182 - accuracy: 0.6790 - val_loss: 0.9122 - val_accuracy: 0.7089\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8977 - accuracy: 0.6695 - val_loss: 0.8909 - val_accuracy: 0.7267\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8658 - accuracy: 0.7133 - val_loss: 0.8652 - val_accuracy: 0.7489\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8414 - accuracy: 0.7390 - val_loss: 0.8435 - val_accuracy: 0.7400\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8219 - accuracy: 0.7210 - val_loss: 0.8478 - val_accuracy: 0.6178\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7998 - accuracy: 0.7333 - val_loss: 0.8055 - val_accuracy: 0.7578\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7791 - accuracy: 0.7667 - val_loss: 0.7883 - val_accuracy: 0.7556\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7601 - accuracy: 0.7552 - val_loss: 0.7688 - val_accuracy: 0.7844\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7424 - accuracy: 0.7848 - val_loss: 0.7528 - val_accuracy: 0.7622\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7260 - accuracy: 0.7810 - val_loss: 0.7341 - val_accuracy: 0.7911\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7101 - accuracy: 0.7800 - val_loss: 0.7200 - val_accuracy: 0.7822\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6935 - accuracy: 0.7876 - val_loss: 0.7039 - val_accuracy: 0.8000\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6780 - accuracy: 0.7838 - val_loss: 0.6956 - val_accuracy: 0.7800\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6639 - accuracy: 0.8048 - val_loss: 0.6803 - val_accuracy: 0.8089\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6514 - accuracy: 0.7971 - val_loss: 0.6664 - val_accuracy: 0.8022\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6380 - accuracy: 0.8171 - val_loss: 0.6581 - val_accuracy: 0.8067\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6233 - accuracy: 0.8133 - val_loss: 0.6376 - val_accuracy: 0.8111\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6118 - accuracy: 0.8181 - val_loss: 0.6211 - val_accuracy: 0.8200\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5987 - accuracy: 0.8305 - val_loss: 0.6062 - val_accuracy: 0.8333\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.8352 - val_loss: 0.6177 - val_accuracy: 0.8111\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.8438 - val_loss: 0.5836 - val_accuracy: 0.8311\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5562 - accuracy: 0.8486 - val_loss: 0.5673 - val_accuracy: 0.8467\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5394 - accuracy: 0.8543 - val_loss: 0.5542 - val_accuracy: 0.8400\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5297 - accuracy: 0.8552 - val_loss: 0.5429 - val_accuracy: 0.8444\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5201 - accuracy: 0.8562 - val_loss: 0.5287 - val_accuracy: 0.8578\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5020 - accuracy: 0.8648 - val_loss: 0.5147 - val_accuracy: 0.8578\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.8657 - val_loss: 0.5042 - val_accuracy: 0.8533\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4754 - accuracy: 0.8667 - val_loss: 0.5028 - val_accuracy: 0.8600\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4690 - accuracy: 0.8705 - val_loss: 0.4804 - val_accuracy: 0.8578\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4561 - accuracy: 0.8771 - val_loss: 0.4781 - val_accuracy: 0.8533\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4456 - accuracy: 0.8743 - val_loss: 0.4644 - val_accuracy: 0.8756\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8790 - val_loss: 0.4533 - val_accuracy: 0.8711\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8705 - val_loss: 0.4477 - val_accuracy: 0.8711\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4161 - accuracy: 0.8762 - val_loss: 0.4323 - val_accuracy: 0.8756\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4108 - accuracy: 0.8810 - val_loss: 0.4282 - val_accuracy: 0.8711\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3966 - accuracy: 0.8819 - val_loss: 0.4129 - val_accuracy: 0.8711\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3881 - accuracy: 0.8819 - val_loss: 0.4066 - val_accuracy: 0.8778\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3823 - accuracy: 0.8848 - val_loss: 0.4034 - val_accuracy: 0.8622\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3729 - accuracy: 0.8886 - val_loss: 0.3921 - val_accuracy: 0.8667\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3661 - accuracy: 0.8962 - val_loss: 0.3823 - val_accuracy: 0.8822\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3579 - accuracy: 0.8895 - val_loss: 0.3914 - val_accuracy: 0.8733\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3551 - accuracy: 0.8829 - val_loss: 0.3715 - val_accuracy: 0.8800\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3492 - accuracy: 0.8971 - val_loss: 0.3879 - val_accuracy: 0.8711\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3432 - accuracy: 0.8857 - val_loss: 0.3632 - val_accuracy: 0.8822\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3366 - accuracy: 0.8933 - val_loss: 0.3568 - val_accuracy: 0.8756\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3313 - accuracy: 0.8990 - val_loss: 0.3531 - val_accuracy: 0.8733\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3298 - accuracy: 0.8914 - val_loss: 0.3446 - val_accuracy: 0.8756\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3173 - accuracy: 0.8962 - val_loss: 0.3397 - val_accuracy: 0.8844\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3139 - accuracy: 0.9000 - val_loss: 0.3345 - val_accuracy: 0.8778\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3112 - accuracy: 0.8981 - val_loss: 0.3297 - val_accuracy: 0.8778\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3079 - accuracy: 0.8981 - val_loss: 0.3283 - val_accuracy: 0.8800\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3059 - accuracy: 0.8990 - val_loss: 0.3227 - val_accuracy: 0.8800\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2994 - accuracy: 0.8971 - val_loss: 0.3340 - val_accuracy: 0.8867\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2958 - accuracy: 0.9010 - val_loss: 0.3211 - val_accuracy: 0.8822\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2960 - accuracy: 0.9000 - val_loss: 0.3110 - val_accuracy: 0.8822\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.9019 - val_loss: 0.3197 - val_accuracy: 0.8756\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2905 - accuracy: 0.8990 - val_loss: 0.3119 - val_accuracy: 0.8756\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.9095 - val_loss: 0.3032 - val_accuracy: 0.8867\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.9133 - val_loss: 0.3010 - val_accuracy: 0.8800\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.9019 - val_loss: 0.2955 - val_accuracy: 0.8822\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2742 - accuracy: 0.9048 - val_loss: 0.2935 - val_accuracy: 0.8889\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2764 - accuracy: 0.8981 - val_loss: 0.2899 - val_accuracy: 0.8867\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2673 - accuracy: 0.9010 - val_loss: 0.2932 - val_accuracy: 0.8956\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2685 - accuracy: 0.9076 - val_loss: 0.2901 - val_accuracy: 0.8778\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2693 - accuracy: 0.9057 - val_loss: 0.3002 - val_accuracy: 0.8844\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2636 - accuracy: 0.9057 - val_loss: 0.2821 - val_accuracy: 0.8822\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.9057 - val_loss: 0.2821 - val_accuracy: 0.8889\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.9076 - val_loss: 0.2783 - val_accuracy: 0.8933\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2559 - accuracy: 0.9067 - val_loss: 0.2865 - val_accuracy: 0.8911\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2621 - accuracy: 0.9095 - val_loss: 0.2867 - val_accuracy: 0.8956\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[146   4   4]\n",
            " [  0 138   7]\n",
            " [  4  28 119]]\n",
            "\n",
            "P-Score: 0.900, R-Score: 0.896, F-Score: 0.895\n",
            "[0.8955555555555555, 0.9001608848667672, 0.8959518520605526, 0.8945639603159737, 0.9672692172692172, 0.9234030525720747, 0.8756450862699064, 0.9221057853703994]\n",
            "Model: \"sequential_52\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_110 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1181 - accuracy: 0.3562 - val_loss: 1.0953 - val_accuracy: 0.3822\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0907 - accuracy: 0.3733 - val_loss: 1.0873 - val_accuracy: 0.4178\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0851 - accuracy: 0.4238 - val_loss: 1.0822 - val_accuracy: 0.4489\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0805 - accuracy: 0.4000 - val_loss: 1.0782 - val_accuracy: 0.4556\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0750 - accuracy: 0.4505 - val_loss: 1.0729 - val_accuracy: 0.4867\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0699 - accuracy: 0.4371 - val_loss: 1.0659 - val_accuracy: 0.4822\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0607 - accuracy: 0.4705 - val_loss: 1.0581 - val_accuracy: 0.4200\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0511 - accuracy: 0.5219 - val_loss: 1.0479 - val_accuracy: 0.5756\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0386 - accuracy: 0.5029 - val_loss: 1.0338 - val_accuracy: 0.4533\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0243 - accuracy: 0.5305 - val_loss: 1.0272 - val_accuracy: 0.4400\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0103 - accuracy: 0.6752 - val_loss: 1.0043 - val_accuracy: 0.6644\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9910 - accuracy: 0.7133 - val_loss: 0.9885 - val_accuracy: 0.7267\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9769 - accuracy: 0.7000 - val_loss: 0.9732 - val_accuracy: 0.7356\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9608 - accuracy: 0.6876 - val_loss: 0.9632 - val_accuracy: 0.6200\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9425 - accuracy: 0.6838 - val_loss: 0.9383 - val_accuracy: 0.7156\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9227 - accuracy: 0.7010 - val_loss: 0.9185 - val_accuracy: 0.7200\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9021 - accuracy: 0.7467 - val_loss: 0.9021 - val_accuracy: 0.7222\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8857 - accuracy: 0.7400 - val_loss: 0.8805 - val_accuracy: 0.7556\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8626 - accuracy: 0.7790 - val_loss: 0.8625 - val_accuracy: 0.7778\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8390 - accuracy: 0.7657 - val_loss: 0.8465 - val_accuracy: 0.7711\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8183 - accuracy: 0.7790 - val_loss: 0.8221 - val_accuracy: 0.7911\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7979 - accuracy: 0.8010 - val_loss: 0.8010 - val_accuracy: 0.7822\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7790 - accuracy: 0.7790 - val_loss: 0.7897 - val_accuracy: 0.7622\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7626 - accuracy: 0.7867 - val_loss: 0.7633 - val_accuracy: 0.8111\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7354 - accuracy: 0.8362 - val_loss: 0.7393 - val_accuracy: 0.8244\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7125 - accuracy: 0.8419 - val_loss: 0.7272 - val_accuracy: 0.7089\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6891 - accuracy: 0.8400 - val_loss: 0.6894 - val_accuracy: 0.8378\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6603 - accuracy: 0.8438 - val_loss: 0.6637 - val_accuracy: 0.8311\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6425 - accuracy: 0.8562 - val_loss: 0.6425 - val_accuracy: 0.8400\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6205 - accuracy: 0.8457 - val_loss: 0.6269 - val_accuracy: 0.8400\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5965 - accuracy: 0.8600 - val_loss: 0.6058 - val_accuracy: 0.8444\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.8590 - val_loss: 0.5898 - val_accuracy: 0.8578\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5701 - accuracy: 0.8562 - val_loss: 0.5748 - val_accuracy: 0.8400\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.8524 - val_loss: 0.5941 - val_accuracy: 0.8400\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5406 - accuracy: 0.8619 - val_loss: 0.5444 - val_accuracy: 0.8467\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.8600 - val_loss: 0.5296 - val_accuracy: 0.8600\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8610 - val_loss: 0.5305 - val_accuracy: 0.8378\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4983 - accuracy: 0.8686 - val_loss: 0.5148 - val_accuracy: 0.8444\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.8619 - val_loss: 0.4964 - val_accuracy: 0.8489\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4724 - accuracy: 0.8657 - val_loss: 0.4904 - val_accuracy: 0.8600\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4572 - accuracy: 0.8676 - val_loss: 0.4751 - val_accuracy: 0.8644\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.8590 - val_loss: 0.4701 - val_accuracy: 0.8600\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8552 - val_loss: 0.4552 - val_accuracy: 0.8667\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8733 - val_loss: 0.4500 - val_accuracy: 0.8644\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8733 - val_loss: 0.4449 - val_accuracy: 0.8578\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4150 - accuracy: 0.8733 - val_loss: 0.4308 - val_accuracy: 0.8644\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4049 - accuracy: 0.8695 - val_loss: 0.4334 - val_accuracy: 0.8556\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4000 - accuracy: 0.8771 - val_loss: 0.4155 - val_accuracy: 0.8667\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3914 - accuracy: 0.8743 - val_loss: 0.4069 - val_accuracy: 0.8733\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3893 - accuracy: 0.8781 - val_loss: 0.4192 - val_accuracy: 0.8533\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3802 - accuracy: 0.8838 - val_loss: 0.4152 - val_accuracy: 0.8667\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.8800 - val_loss: 0.3921 - val_accuracy: 0.8689\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3647 - accuracy: 0.8800 - val_loss: 0.3805 - val_accuracy: 0.8733\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3604 - accuracy: 0.8790 - val_loss: 0.3766 - val_accuracy: 0.8756\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3537 - accuracy: 0.8895 - val_loss: 0.3765 - val_accuracy: 0.8667\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3483 - accuracy: 0.8838 - val_loss: 0.3641 - val_accuracy: 0.8756\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3447 - accuracy: 0.8810 - val_loss: 0.3693 - val_accuracy: 0.8711\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8857 - val_loss: 0.3591 - val_accuracy: 0.8800\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3356 - accuracy: 0.8867 - val_loss: 0.3559 - val_accuracy: 0.8778\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3273 - accuracy: 0.8876 - val_loss: 0.3551 - val_accuracy: 0.8667\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3230 - accuracy: 0.8876 - val_loss: 0.3473 - val_accuracy: 0.8822\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3215 - accuracy: 0.8962 - val_loss: 0.3387 - val_accuracy: 0.8800\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3242 - accuracy: 0.8867 - val_loss: 0.3412 - val_accuracy: 0.8778\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3159 - accuracy: 0.8886 - val_loss: 0.3299 - val_accuracy: 0.8800\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3100 - accuracy: 0.8905 - val_loss: 0.3260 - val_accuracy: 0.8800\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3051 - accuracy: 0.8914 - val_loss: 0.3216 - val_accuracy: 0.8822\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3021 - accuracy: 0.8933 - val_loss: 0.3177 - val_accuracy: 0.8800\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3008 - accuracy: 0.9000 - val_loss: 0.3151 - val_accuracy: 0.8800\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2983 - accuracy: 0.8895 - val_loss: 0.3117 - val_accuracy: 0.8867\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2916 - accuracy: 0.8971 - val_loss: 0.3181 - val_accuracy: 0.8756\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2885 - accuracy: 0.9010 - val_loss: 0.3052 - val_accuracy: 0.8800\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2846 - accuracy: 0.8990 - val_loss: 0.3060 - val_accuracy: 0.8800\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2826 - accuracy: 0.9038 - val_loss: 0.2997 - val_accuracy: 0.8844\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2785 - accuracy: 0.9048 - val_loss: 0.2997 - val_accuracy: 0.8800\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2768 - accuracy: 0.9038 - val_loss: 0.2942 - val_accuracy: 0.8822\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2770 - accuracy: 0.9019 - val_loss: 0.2923 - val_accuracy: 0.8844\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2729 - accuracy: 0.9067 - val_loss: 0.2986 - val_accuracy: 0.8933\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.9067 - val_loss: 0.2943 - val_accuracy: 0.8800\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2763 - accuracy: 0.9010 - val_loss: 0.2843 - val_accuracy: 0.8867\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2731 - accuracy: 0.9019 - val_loss: 0.2843 - val_accuracy: 0.8844\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[144   3   7]\n",
            " [  0 130  15]\n",
            " [  4  23 124]]\n",
            "\n",
            "P-Score: 0.885, R-Score: 0.884, F-Score: 0.884\n",
            "[0.8844444444444445, 0.8852071249331522, 0.8842695707276661, 0.8841488648460257, 0.9607757107757107, 0.9056529112492934, 0.8738067288312034, 0.9134117836187358]\n",
            "Model: \"sequential_53\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_113 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1533 - accuracy: 0.3381 - val_loss: 1.1228 - val_accuracy: 0.3222\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0982 - accuracy: 0.3419 - val_loss: 1.0901 - val_accuracy: 0.3311\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0780 - accuracy: 0.3705 - val_loss: 1.0746 - val_accuracy: 0.4911\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0632 - accuracy: 0.5162 - val_loss: 1.0614 - val_accuracy: 0.4133\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0474 - accuracy: 0.4886 - val_loss: 1.0462 - val_accuracy: 0.5400\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0323 - accuracy: 0.5390 - val_loss: 1.0319 - val_accuracy: 0.5311\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0166 - accuracy: 0.4876 - val_loss: 1.0156 - val_accuracy: 0.4556\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9997 - accuracy: 0.4638 - val_loss: 1.0003 - val_accuracy: 0.4156\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9842 - accuracy: 0.5152 - val_loss: 0.9909 - val_accuracy: 0.4311\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9711 - accuracy: 0.4990 - val_loss: 0.9710 - val_accuracy: 0.4333\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9489 - accuracy: 0.5514 - val_loss: 0.9516 - val_accuracy: 0.5644\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9314 - accuracy: 0.5324 - val_loss: 0.9361 - val_accuracy: 0.5600\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9159 - accuracy: 0.5381 - val_loss: 0.9202 - val_accuracy: 0.5711\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8989 - accuracy: 0.5581 - val_loss: 0.9086 - val_accuracy: 0.5333\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8846 - accuracy: 0.5467 - val_loss: 0.8993 - val_accuracy: 0.4711\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8750 - accuracy: 0.5771 - val_loss: 0.8805 - val_accuracy: 0.5756\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8597 - accuracy: 0.5467 - val_loss: 0.8790 - val_accuracy: 0.5778\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8484 - accuracy: 0.5771 - val_loss: 0.8590 - val_accuracy: 0.5844\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8358 - accuracy: 0.5800 - val_loss: 0.8534 - val_accuracy: 0.6089\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8287 - accuracy: 0.5743 - val_loss: 0.8412 - val_accuracy: 0.6044\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8194 - accuracy: 0.5943 - val_loss: 0.8381 - val_accuracy: 0.6111\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8127 - accuracy: 0.5810 - val_loss: 0.8272 - val_accuracy: 0.6200\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8059 - accuracy: 0.6038 - val_loss: 0.8212 - val_accuracy: 0.6400\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7986 - accuracy: 0.6352 - val_loss: 0.8178 - val_accuracy: 0.6333\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7935 - accuracy: 0.6505 - val_loss: 0.8316 - val_accuracy: 0.6533\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7943 - accuracy: 0.6200 - val_loss: 0.8158 - val_accuracy: 0.6111\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7829 - accuracy: 0.6467 - val_loss: 0.8049 - val_accuracy: 0.6667\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7807 - accuracy: 0.6448 - val_loss: 0.8180 - val_accuracy: 0.6689\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7732 - accuracy: 0.6800 - val_loss: 0.8013 - val_accuracy: 0.6711\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7759 - accuracy: 0.6210 - val_loss: 0.7961 - val_accuracy: 0.5733\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7697 - accuracy: 0.6581 - val_loss: 0.7899 - val_accuracy: 0.6689\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7668 - accuracy: 0.6190 - val_loss: 0.7876 - val_accuracy: 0.6089\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7627 - accuracy: 0.6724 - val_loss: 0.7872 - val_accuracy: 0.6600\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7602 - accuracy: 0.6733 - val_loss: 0.7924 - val_accuracy: 0.6333\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7571 - accuracy: 0.6324 - val_loss: 0.7799 - val_accuracy: 0.6822\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7577 - accuracy: 0.6800 - val_loss: 0.7794 - val_accuracy: 0.6933\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7529 - accuracy: 0.7029 - val_loss: 0.7784 - val_accuracy: 0.6733\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7524 - accuracy: 0.6295 - val_loss: 0.7732 - val_accuracy: 0.7022\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7488 - accuracy: 0.6962 - val_loss: 0.7729 - val_accuracy: 0.6956\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7453 - accuracy: 0.6876 - val_loss: 0.7730 - val_accuracy: 0.6733\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7438 - accuracy: 0.6724 - val_loss: 0.7664 - val_accuracy: 0.7333\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7452 - accuracy: 0.7095 - val_loss: 0.7918 - val_accuracy: 0.6756\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.6724 - val_loss: 0.7618 - val_accuracy: 0.7289\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7382 - accuracy: 0.7105 - val_loss: 0.7599 - val_accuracy: 0.6978\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7332 - accuracy: 0.7010 - val_loss: 0.7574 - val_accuracy: 0.7333\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7350 - accuracy: 0.7067 - val_loss: 0.7601 - val_accuracy: 0.7222\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7286 - accuracy: 0.7038 - val_loss: 0.7533 - val_accuracy: 0.6711\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7310 - accuracy: 0.7133 - val_loss: 0.7504 - val_accuracy: 0.7511\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.7162 - val_loss: 0.7519 - val_accuracy: 0.7467\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7188 - accuracy: 0.7276 - val_loss: 0.7547 - val_accuracy: 0.7000\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7165 - accuracy: 0.7086 - val_loss: 0.7452 - val_accuracy: 0.7556\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7142 - accuracy: 0.7362 - val_loss: 0.7328 - val_accuracy: 0.7578\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7105 - accuracy: 0.7505 - val_loss: 0.7367 - val_accuracy: 0.7622\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6994 - accuracy: 0.7486 - val_loss: 0.7237 - val_accuracy: 0.7733\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6985 - accuracy: 0.7410 - val_loss: 0.7272 - val_accuracy: 0.6756\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6962 - accuracy: 0.7371 - val_loss: 0.7156 - val_accuracy: 0.7711\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6863 - accuracy: 0.7676 - val_loss: 0.7163 - val_accuracy: 0.7556\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6804 - accuracy: 0.7752 - val_loss: 0.7070 - val_accuracy: 0.7711\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6750 - accuracy: 0.7676 - val_loss: 0.6987 - val_accuracy: 0.7756\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6714 - accuracy: 0.7638 - val_loss: 0.6913 - val_accuracy: 0.7800\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6639 - accuracy: 0.7886 - val_loss: 0.6855 - val_accuracy: 0.7800\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6602 - accuracy: 0.7629 - val_loss: 0.6787 - val_accuracy: 0.7911\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.7867 - val_loss: 0.6793 - val_accuracy: 0.7689\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6451 - accuracy: 0.7800 - val_loss: 0.6684 - val_accuracy: 0.7911\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6396 - accuracy: 0.8048 - val_loss: 0.6597 - val_accuracy: 0.8022\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6296 - accuracy: 0.7962 - val_loss: 0.6507 - val_accuracy: 0.7956\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6196 - accuracy: 0.8029 - val_loss: 0.6435 - val_accuracy: 0.7956\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6120 - accuracy: 0.8190 - val_loss: 0.6341 - val_accuracy: 0.8156\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6078 - accuracy: 0.8190 - val_loss: 0.6258 - val_accuracy: 0.8022\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5962 - accuracy: 0.8257 - val_loss: 0.6192 - val_accuracy: 0.8022\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5864 - accuracy: 0.8305 - val_loss: 0.6153 - val_accuracy: 0.8178\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5797 - accuracy: 0.8390 - val_loss: 0.6074 - val_accuracy: 0.8222\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5705 - accuracy: 0.8390 - val_loss: 0.5916 - val_accuracy: 0.8200\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5604 - accuracy: 0.8448 - val_loss: 0.5842 - val_accuracy: 0.8244\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5506 - accuracy: 0.8390 - val_loss: 0.5754 - val_accuracy: 0.8156\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5425 - accuracy: 0.8371 - val_loss: 0.5749 - val_accuracy: 0.8022\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5327 - accuracy: 0.8524 - val_loss: 0.5583 - val_accuracy: 0.8267\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5231 - accuracy: 0.8514 - val_loss: 0.5554 - val_accuracy: 0.8333\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.8514 - val_loss: 0.5408 - val_accuracy: 0.8222\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5073 - accuracy: 0.8552 - val_loss: 0.5279 - val_accuracy: 0.8400\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[136   7  11]\n",
            " [  1 124  20]\n",
            " [ 15  18 118]]\n",
            "\n",
            "P-Score: 0.840, R-Score: 0.840, F-Score: 0.840\n",
            "[0.84, 0.839632638643589, 0.8399154168507902, 0.839697656840514, 0.9145314145314145, 0.8866026003391747, 0.8388890119382488, 0.880007675602946]\n",
            "Model: \"sequential_54\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_116 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0676 - accuracy: 0.3800 - val_loss: 1.0637 - val_accuracy: 0.4000\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0544 - accuracy: 0.4914 - val_loss: 1.0533 - val_accuracy: 0.5600\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0470 - accuracy: 0.5095 - val_loss: 1.0440 - val_accuracy: 0.6044\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0338 - accuracy: 0.5543 - val_loss: 1.0331 - val_accuracy: 0.5933\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0212 - accuracy: 0.5895 - val_loss: 1.0207 - val_accuracy: 0.6222\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0069 - accuracy: 0.6076 - val_loss: 1.0080 - val_accuracy: 0.5822\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.5971 - val_loss: 0.9911 - val_accuracy: 0.5867\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9714 - accuracy: 0.6133 - val_loss: 0.9697 - val_accuracy: 0.6422\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9504 - accuracy: 0.6143 - val_loss: 0.9512 - val_accuracy: 0.5911\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9281 - accuracy: 0.6076 - val_loss: 0.9296 - val_accuracy: 0.5956\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9069 - accuracy: 0.6057 - val_loss: 0.9091 - val_accuracy: 0.6378\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8866 - accuracy: 0.5962 - val_loss: 0.8890 - val_accuracy: 0.6244\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8680 - accuracy: 0.6010 - val_loss: 0.8777 - val_accuracy: 0.5644\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8490 - accuracy: 0.6133 - val_loss: 0.8668 - val_accuracy: 0.5511\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8365 - accuracy: 0.6105 - val_loss: 0.8421 - val_accuracy: 0.6133\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8204 - accuracy: 0.6114 - val_loss: 0.8323 - val_accuracy: 0.5733\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8026 - accuracy: 0.6076 - val_loss: 0.8175 - val_accuracy: 0.6378\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7979 - accuracy: 0.6076 - val_loss: 0.8165 - val_accuracy: 0.5689\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7840 - accuracy: 0.5981 - val_loss: 0.7981 - val_accuracy: 0.6333\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7768 - accuracy: 0.6267 - val_loss: 0.7935 - val_accuracy: 0.6444\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7688 - accuracy: 0.6143 - val_loss: 0.7840 - val_accuracy: 0.6422\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7635 - accuracy: 0.6229 - val_loss: 0.7785 - val_accuracy: 0.6444\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7590 - accuracy: 0.6229 - val_loss: 0.7798 - val_accuracy: 0.6044\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7566 - accuracy: 0.6171 - val_loss: 0.7709 - val_accuracy: 0.6444\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7509 - accuracy: 0.6267 - val_loss: 0.7678 - val_accuracy: 0.6467\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7516 - accuracy: 0.6143 - val_loss: 0.7636 - val_accuracy: 0.6622\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7436 - accuracy: 0.6276 - val_loss: 0.7600 - val_accuracy: 0.6511\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7383 - accuracy: 0.6390 - val_loss: 0.7614 - val_accuracy: 0.6467\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7361 - accuracy: 0.6371 - val_loss: 0.7654 - val_accuracy: 0.6333\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7362 - accuracy: 0.6257 - val_loss: 0.7567 - val_accuracy: 0.6444\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7385 - accuracy: 0.6314 - val_loss: 0.7562 - val_accuracy: 0.6733\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7289 - accuracy: 0.6476 - val_loss: 0.7495 - val_accuracy: 0.6600\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7310 - accuracy: 0.6467 - val_loss: 0.7453 - val_accuracy: 0.6778\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7243 - accuracy: 0.6486 - val_loss: 0.7481 - val_accuracy: 0.6578\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7238 - accuracy: 0.6486 - val_loss: 0.7421 - val_accuracy: 0.6733\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7223 - accuracy: 0.6524 - val_loss: 0.7397 - val_accuracy: 0.6778\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.6524 - val_loss: 0.7379 - val_accuracy: 0.6756\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7216 - accuracy: 0.6514 - val_loss: 0.7405 - val_accuracy: 0.6644\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7189 - accuracy: 0.6495 - val_loss: 0.7384 - val_accuracy: 0.6733\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7183 - accuracy: 0.6562 - val_loss: 0.7778 - val_accuracy: 0.6022\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7168 - accuracy: 0.6533 - val_loss: 0.7319 - val_accuracy: 0.6867\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7149 - accuracy: 0.6610 - val_loss: 0.7305 - val_accuracy: 0.7022\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7127 - accuracy: 0.6638 - val_loss: 0.7285 - val_accuracy: 0.6889\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7102 - accuracy: 0.6676 - val_loss: 0.7278 - val_accuracy: 0.6889\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7097 - accuracy: 0.6762 - val_loss: 0.7446 - val_accuracy: 0.6578\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7095 - accuracy: 0.6629 - val_loss: 0.7241 - val_accuracy: 0.6956\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7080 - accuracy: 0.6600 - val_loss: 0.7224 - val_accuracy: 0.7022\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7059 - accuracy: 0.6714 - val_loss: 0.7210 - val_accuracy: 0.7089\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.6743 - val_loss: 0.7454 - val_accuracy: 0.6467\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7050 - accuracy: 0.6724 - val_loss: 0.7200 - val_accuracy: 0.7044\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7023 - accuracy: 0.6762 - val_loss: 0.7177 - val_accuracy: 0.7089\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6998 - accuracy: 0.6838 - val_loss: 0.7178 - val_accuracy: 0.7133\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7007 - accuracy: 0.6771 - val_loss: 0.7159 - val_accuracy: 0.7111\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7003 - accuracy: 0.6771 - val_loss: 0.7212 - val_accuracy: 0.6778\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6950 - accuracy: 0.6714 - val_loss: 0.7171 - val_accuracy: 0.7133\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6964 - accuracy: 0.6867 - val_loss: 0.7089 - val_accuracy: 0.7022\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6928 - accuracy: 0.6810 - val_loss: 0.7082 - val_accuracy: 0.7089\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6883 - accuracy: 0.6810 - val_loss: 0.7202 - val_accuracy: 0.6689\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6889 - accuracy: 0.6886 - val_loss: 0.7082 - val_accuracy: 0.7133\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6872 - accuracy: 0.6895 - val_loss: 0.7037 - val_accuracy: 0.7222\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6862 - accuracy: 0.6886 - val_loss: 0.6997 - val_accuracy: 0.7222\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6839 - accuracy: 0.7038 - val_loss: 0.7070 - val_accuracy: 0.6911\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6838 - accuracy: 0.6800 - val_loss: 0.7266 - val_accuracy: 0.6756\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6926 - accuracy: 0.6781 - val_loss: 0.6967 - val_accuracy: 0.7200\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6824 - accuracy: 0.6952 - val_loss: 0.6946 - val_accuracy: 0.7267\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6799 - accuracy: 0.6867 - val_loss: 0.6931 - val_accuracy: 0.7356\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6754 - accuracy: 0.7048 - val_loss: 0.6974 - val_accuracy: 0.7156\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6720 - accuracy: 0.7010 - val_loss: 0.6918 - val_accuracy: 0.7311\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6792 - accuracy: 0.6943 - val_loss: 0.6902 - val_accuracy: 0.7244\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.7200 - val_loss: 0.6834 - val_accuracy: 0.7378\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6687 - accuracy: 0.7010 - val_loss: 0.6837 - val_accuracy: 0.7311\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6676 - accuracy: 0.7067 - val_loss: 0.6957 - val_accuracy: 0.7022\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6796 - accuracy: 0.6886 - val_loss: 0.6902 - val_accuracy: 0.7200\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6666 - accuracy: 0.7000 - val_loss: 0.6784 - val_accuracy: 0.7356\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6636 - accuracy: 0.7200 - val_loss: 0.6869 - val_accuracy: 0.7111\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6603 - accuracy: 0.7124 - val_loss: 0.6744 - val_accuracy: 0.7311\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.7181 - val_loss: 0.6715 - val_accuracy: 0.7400\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6569 - accuracy: 0.7219 - val_loss: 0.6654 - val_accuracy: 0.7533\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6558 - accuracy: 0.7200 - val_loss: 0.6756 - val_accuracy: 0.7244\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.7095 - val_loss: 0.6781 - val_accuracy: 0.7289\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[111  34   9]\n",
            " [ 28 110   7]\n",
            " [ 35   9 107]]\n",
            "\n",
            "P-Score: 0.742, R-Score: 0.729, F-Score: 0.732\n",
            "[0.7288888888888889, 0.7422679940119211, 0.7293363939858573, 0.7320353998866497, 0.7539706914706914, 0.8088185415488977, 0.82754878291878, 0.7967793386461229]\n",
            "Model: \"sequential_55\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_119 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_120 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1177 - accuracy: 0.3038 - val_loss: 1.1096 - val_accuracy: 0.1756\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1080 - accuracy: 0.2905 - val_loss: 1.1043 - val_accuracy: 0.3400\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1027 - accuracy: 0.3124 - val_loss: 1.1012 - val_accuracy: 0.2800\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0982 - accuracy: 0.2610 - val_loss: 1.0967 - val_accuracy: 0.2578\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0947 - accuracy: 0.3248 - val_loss: 1.0927 - val_accuracy: 0.3067\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0901 - accuracy: 0.3229 - val_loss: 1.0885 - val_accuracy: 0.3333\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0854 - accuracy: 0.3810 - val_loss: 1.0849 - val_accuracy: 0.3533\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0808 - accuracy: 0.3590 - val_loss: 1.0810 - val_accuracy: 0.3511\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0760 - accuracy: 0.4162 - val_loss: 1.0757 - val_accuracy: 0.4667\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0707 - accuracy: 0.5181 - val_loss: 1.0700 - val_accuracy: 0.6067\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0635 - accuracy: 0.5571 - val_loss: 1.0585 - val_accuracy: 0.7378\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0499 - accuracy: 0.6133 - val_loss: 1.0481 - val_accuracy: 0.7156\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0402 - accuracy: 0.5829 - val_loss: 1.0392 - val_accuracy: 0.6644\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0300 - accuracy: 0.6333 - val_loss: 1.0287 - val_accuracy: 0.7356\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0200 - accuracy: 0.6676 - val_loss: 1.0188 - val_accuracy: 0.6022\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0041 - accuracy: 0.6705 - val_loss: 1.0047 - val_accuracy: 0.7156\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9912 - accuracy: 0.6076 - val_loss: 0.9923 - val_accuracy: 0.6444\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9765 - accuracy: 0.7133 - val_loss: 0.9789 - val_accuracy: 0.6800\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9631 - accuracy: 0.6838 - val_loss: 0.9655 - val_accuracy: 0.6400\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9478 - accuracy: 0.7048 - val_loss: 0.9524 - val_accuracy: 0.6667\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9333 - accuracy: 0.6924 - val_loss: 0.9374 - val_accuracy: 0.7733\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9199 - accuracy: 0.7105 - val_loss: 0.9273 - val_accuracy: 0.5711\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9046 - accuracy: 0.6190 - val_loss: 0.9121 - val_accuracy: 0.6311\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8915 - accuracy: 0.7095 - val_loss: 0.8996 - val_accuracy: 0.7644\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8776 - accuracy: 0.7581 - val_loss: 0.8872 - val_accuracy: 0.6578\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8653 - accuracy: 0.6419 - val_loss: 0.8801 - val_accuracy: 0.7867\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8527 - accuracy: 0.7552 - val_loss: 0.8646 - val_accuracy: 0.6733\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8443 - accuracy: 0.7486 - val_loss: 0.8611 - val_accuracy: 0.7044\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8345 - accuracy: 0.6781 - val_loss: 0.8467 - val_accuracy: 0.7756\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8213 - accuracy: 0.7400 - val_loss: 0.8362 - val_accuracy: 0.6311\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8111 - accuracy: 0.7667 - val_loss: 0.8267 - val_accuracy: 0.7222\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8025 - accuracy: 0.7333 - val_loss: 0.8177 - val_accuracy: 0.8133\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7956 - accuracy: 0.7467 - val_loss: 0.8099 - val_accuracy: 0.7689\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7890 - accuracy: 0.7971 - val_loss: 0.8036 - val_accuracy: 0.7844\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7828 - accuracy: 0.7257 - val_loss: 0.8011 - val_accuracy: 0.7133\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7728 - accuracy: 0.7790 - val_loss: 0.7909 - val_accuracy: 0.6778\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7651 - accuracy: 0.7486 - val_loss: 0.7868 - val_accuracy: 0.8311\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7597 - accuracy: 0.8000 - val_loss: 0.7775 - val_accuracy: 0.7644\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7565 - accuracy: 0.7333 - val_loss: 0.7741 - val_accuracy: 0.7978\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7508 - accuracy: 0.7400 - val_loss: 0.7787 - val_accuracy: 0.6200\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7425 - accuracy: 0.7086 - val_loss: 0.7624 - val_accuracy: 0.8044\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7359 - accuracy: 0.8057 - val_loss: 0.7582 - val_accuracy: 0.7200\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7309 - accuracy: 0.6914 - val_loss: 0.7519 - val_accuracy: 0.8000\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7285 - accuracy: 0.7695 - val_loss: 0.7483 - val_accuracy: 0.7422\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7227 - accuracy: 0.7438 - val_loss: 0.7409 - val_accuracy: 0.8044\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7174 - accuracy: 0.7962 - val_loss: 0.7399 - val_accuracy: 0.7800\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7109 - accuracy: 0.7752 - val_loss: 0.7307 - val_accuracy: 0.8267\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7101 - accuracy: 0.7648 - val_loss: 0.7318 - val_accuracy: 0.7956\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7025 - accuracy: 0.8076 - val_loss: 0.7256 - val_accuracy: 0.7511\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6971 - accuracy: 0.8038 - val_loss: 0.7192 - val_accuracy: 0.7667\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6959 - accuracy: 0.8143 - val_loss: 0.7142 - val_accuracy: 0.8022\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6907 - accuracy: 0.7857 - val_loss: 0.7079 - val_accuracy: 0.8133\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6852 - accuracy: 0.8048 - val_loss: 0.7104 - val_accuracy: 0.7267\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6785 - accuracy: 0.8190 - val_loss: 0.6995 - val_accuracy: 0.8422\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6731 - accuracy: 0.8267 - val_loss: 0.6959 - val_accuracy: 0.8089\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6752 - accuracy: 0.8267 - val_loss: 0.6945 - val_accuracy: 0.8089\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6664 - accuracy: 0.8219 - val_loss: 0.6897 - val_accuracy: 0.8067\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6616 - accuracy: 0.8105 - val_loss: 0.6814 - val_accuracy: 0.8533\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6577 - accuracy: 0.8286 - val_loss: 0.6772 - val_accuracy: 0.8578\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6490 - accuracy: 0.8448 - val_loss: 0.6701 - val_accuracy: 0.8378\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6447 - accuracy: 0.8314 - val_loss: 0.6659 - val_accuracy: 0.8111\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6405 - accuracy: 0.8276 - val_loss: 0.6677 - val_accuracy: 0.8289\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6374 - accuracy: 0.8295 - val_loss: 0.6543 - val_accuracy: 0.8356\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6288 - accuracy: 0.8476 - val_loss: 0.6488 - val_accuracy: 0.8289\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6260 - accuracy: 0.8362 - val_loss: 0.6493 - val_accuracy: 0.7867\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6181 - accuracy: 0.8438 - val_loss: 0.6506 - val_accuracy: 0.7756\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6092 - accuracy: 0.8305 - val_loss: 0.6383 - val_accuracy: 0.8556\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6115 - accuracy: 0.8419 - val_loss: 0.6336 - val_accuracy: 0.8600\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6005 - accuracy: 0.8429 - val_loss: 0.6227 - val_accuracy: 0.8489\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5961 - accuracy: 0.8524 - val_loss: 0.6246 - val_accuracy: 0.8156\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5923 - accuracy: 0.8467 - val_loss: 0.6104 - val_accuracy: 0.8289\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5848 - accuracy: 0.8448 - val_loss: 0.6046 - val_accuracy: 0.8311\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5808 - accuracy: 0.8610 - val_loss: 0.5994 - val_accuracy: 0.8311\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5781 - accuracy: 0.8400 - val_loss: 0.5931 - val_accuracy: 0.8333\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5672 - accuracy: 0.8476 - val_loss: 0.6009 - val_accuracy: 0.8400\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5613 - accuracy: 0.8438 - val_loss: 0.5826 - val_accuracy: 0.8556\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.8610 - val_loss: 0.5785 - val_accuracy: 0.8600\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5499 - accuracy: 0.8552 - val_loss: 0.5735 - val_accuracy: 0.8578\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5453 - accuracy: 0.8562 - val_loss: 0.5659 - val_accuracy: 0.8511\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.8600 - val_loss: 0.5632 - val_accuracy: 0.8533\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[136  10   8]\n",
            " [  0 131  14]\n",
            " [ 10  24 117]]\n",
            "\n",
            "P-Score: 0.856, R-Score: 0.854, F-Score: 0.853\n",
            "[0.8533333333333334, 0.8557242873198327, 0.8537998653550151, 0.8529081695711284, 0.9246665496665496, 0.8959864330130017, 0.8506279208841835, 0.8904269678545783]\n",
            "Model: \"sequential_56\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_122 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_124 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.1577 - accuracy: 0.2276 - val_loss: 1.1287 - val_accuracy: 0.1289\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1215 - accuracy: 0.1314 - val_loss: 1.1145 - val_accuracy: 0.1444\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1098 - accuracy: 0.1200 - val_loss: 1.1037 - val_accuracy: 0.1400\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1018 - accuracy: 0.2629 - val_loss: 1.0970 - val_accuracy: 0.4978\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0935 - accuracy: 0.4276 - val_loss: 1.0856 - val_accuracy: 0.3489\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0818 - accuracy: 0.5314 - val_loss: 1.0767 - val_accuracy: 0.6378\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0716 - accuracy: 0.6095 - val_loss: 1.0640 - val_accuracy: 0.7000\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0572 - accuracy: 0.7962 - val_loss: 1.0523 - val_accuracy: 0.7044\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0428 - accuracy: 0.7276 - val_loss: 1.0365 - val_accuracy: 0.8422\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0281 - accuracy: 0.7143 - val_loss: 1.0161 - val_accuracy: 0.8533\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0037 - accuracy: 0.7790 - val_loss: 0.9984 - val_accuracy: 0.8222\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9815 - accuracy: 0.8495 - val_loss: 0.9768 - val_accuracy: 0.8267\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9579 - accuracy: 0.8600 - val_loss: 0.9579 - val_accuracy: 0.8222\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9358 - accuracy: 0.8410 - val_loss: 0.9337 - val_accuracy: 0.8333\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9153 - accuracy: 0.7667 - val_loss: 0.9082 - val_accuracy: 0.8133\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8830 - accuracy: 0.8457 - val_loss: 0.8824 - val_accuracy: 0.8489\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8616 - accuracy: 0.8067 - val_loss: 0.8630 - val_accuracy: 0.8156\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8352 - accuracy: 0.8438 - val_loss: 0.8358 - val_accuracy: 0.8467\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8106 - accuracy: 0.8371 - val_loss: 0.8146 - val_accuracy: 0.8200\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7877 - accuracy: 0.8467 - val_loss: 0.7941 - val_accuracy: 0.8267\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7679 - accuracy: 0.8362 - val_loss: 0.7724 - val_accuracy: 0.8400\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7492 - accuracy: 0.8305 - val_loss: 0.7584 - val_accuracy: 0.8289\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7320 - accuracy: 0.8314 - val_loss: 0.7406 - val_accuracy: 0.8467\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7170 - accuracy: 0.8352 - val_loss: 0.7406 - val_accuracy: 0.8311\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7055 - accuracy: 0.8305 - val_loss: 0.7181 - val_accuracy: 0.8289\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6866 - accuracy: 0.8229 - val_loss: 0.6938 - val_accuracy: 0.8422\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6698 - accuracy: 0.8467 - val_loss: 0.6812 - val_accuracy: 0.8400\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6585 - accuracy: 0.8419 - val_loss: 0.6674 - val_accuracy: 0.8378\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6441 - accuracy: 0.8457 - val_loss: 0.6710 - val_accuracy: 0.8044\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6333 - accuracy: 0.8400 - val_loss: 0.6488 - val_accuracy: 0.8222\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6197 - accuracy: 0.8476 - val_loss: 0.6329 - val_accuracy: 0.8356\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.8524 - val_loss: 0.6186 - val_accuracy: 0.8467\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5980 - accuracy: 0.8514 - val_loss: 0.6077 - val_accuracy: 0.8533\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5870 - accuracy: 0.8533 - val_loss: 0.5954 - val_accuracy: 0.8533\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5726 - accuracy: 0.8552 - val_loss: 0.5945 - val_accuracy: 0.8333\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5594 - accuracy: 0.8638 - val_loss: 0.5773 - val_accuracy: 0.8467\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5499 - accuracy: 0.8552 - val_loss: 0.5733 - val_accuracy: 0.8444\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5378 - accuracy: 0.8667 - val_loss: 0.5550 - val_accuracy: 0.8489\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5242 - accuracy: 0.8638 - val_loss: 0.5558 - val_accuracy: 0.8556\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5149 - accuracy: 0.8629 - val_loss: 0.5321 - val_accuracy: 0.8600\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5079 - accuracy: 0.8600 - val_loss: 0.5219 - val_accuracy: 0.8689\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4987 - accuracy: 0.8695 - val_loss: 0.5124 - val_accuracy: 0.8578\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4821 - accuracy: 0.8705 - val_loss: 0.5048 - val_accuracy: 0.8667\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.8771 - val_loss: 0.4894 - val_accuracy: 0.8578\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4645 - accuracy: 0.8733 - val_loss: 0.4827 - val_accuracy: 0.8578\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4548 - accuracy: 0.8733 - val_loss: 0.4715 - val_accuracy: 0.8689\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.8819 - val_loss: 0.4613 - val_accuracy: 0.8644\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4380 - accuracy: 0.8790 - val_loss: 0.4587 - val_accuracy: 0.8622\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4291 - accuracy: 0.8867 - val_loss: 0.4463 - val_accuracy: 0.8689\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8819 - val_loss: 0.4372 - val_accuracy: 0.8689\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8790 - val_loss: 0.4315 - val_accuracy: 0.8756\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4014 - accuracy: 0.8848 - val_loss: 0.4249 - val_accuracy: 0.8600\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3975 - accuracy: 0.8848 - val_loss: 0.4165 - val_accuracy: 0.8689\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3903 - accuracy: 0.8857 - val_loss: 0.4072 - val_accuracy: 0.8689\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3821 - accuracy: 0.8876 - val_loss: 0.4013 - val_accuracy: 0.8689\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3761 - accuracy: 0.8886 - val_loss: 0.4011 - val_accuracy: 0.8644\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3724 - accuracy: 0.8848 - val_loss: 0.3926 - val_accuracy: 0.8733\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3643 - accuracy: 0.8876 - val_loss: 0.3883 - val_accuracy: 0.8756\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.8943 - val_loss: 0.3764 - val_accuracy: 0.8711\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3527 - accuracy: 0.8886 - val_loss: 0.3727 - val_accuracy: 0.8689\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8914 - val_loss: 0.3736 - val_accuracy: 0.8733\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3454 - accuracy: 0.8876 - val_loss: 0.3806 - val_accuracy: 0.8733\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.3277 - accuracy: 0.8952 - val_loss: 0.3432 - val_accuracy: 0.8733\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3078 - accuracy: 0.8990 - val_loss: 0.3226 - val_accuracy: 0.8822\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2990 - accuracy: 0.9067 - val_loss: 0.3162 - val_accuracy: 0.8756\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2967 - accuracy: 0.9019 - val_loss: 0.3095 - val_accuracy: 0.8778\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2879 - accuracy: 0.9067 - val_loss: 0.3061 - val_accuracy: 0.8822\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2824 - accuracy: 0.9038 - val_loss: 0.3047 - val_accuracy: 0.8822\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2807 - accuracy: 0.9086 - val_loss: 0.3062 - val_accuracy: 0.8867\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2776 - accuracy: 0.9095 - val_loss: 0.3222 - val_accuracy: 0.8822\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2748 - accuracy: 0.9067 - val_loss: 0.3030 - val_accuracy: 0.8733\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.9124 - val_loss: 0.2926 - val_accuracy: 0.8867\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2691 - accuracy: 0.9095 - val_loss: 0.3014 - val_accuracy: 0.8867\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2676 - accuracy: 0.9105 - val_loss: 0.2896 - val_accuracy: 0.8889\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2634 - accuracy: 0.9095 - val_loss: 0.2860 - val_accuracy: 0.8867\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2606 - accuracy: 0.9038 - val_loss: 0.2940 - val_accuracy: 0.8889\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.2592 - accuracy: 0.9076 - val_loss: 0.2874 - val_accuracy: 0.8867\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.2592 - accuracy: 0.9124 - val_loss: 0.2765 - val_accuracy: 0.8956\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.2515 - accuracy: 0.9133 - val_loss: 0.2711 - val_accuracy: 0.8822\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.2526 - accuracy: 0.9095 - val_loss: 0.2708 - val_accuracy: 0.8889\n",
            "15/15 [==============================] - 0s 3ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[142   2  10]\n",
            " [  0 129  16]\n",
            " [  5  17 129]]\n",
            "\n",
            "P-Score: 0.890, R-Score: 0.889, F-Score: 0.889\n",
            "[0.8888888888888888, 0.8899553602318578, 0.8886792434177683, 0.88906830822389, 0.9525930150930151, 0.9136800452232899, 0.8836740570112296, 0.9166490391091782]\n",
            "Model: \"sequential_57\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_125 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 12ms/step - loss: 1.1239 - accuracy: 0.1448 - val_loss: 1.1127 - val_accuracy: 0.0644\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.1107 - accuracy: 0.0667 - val_loss: 1.1081 - val_accuracy: 0.1667\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.1069 - accuracy: 0.2305 - val_loss: 1.1046 - val_accuracy: 0.2067\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.1040 - accuracy: 0.1895 - val_loss: 1.1026 - val_accuracy: 0.2200\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.1012 - accuracy: 0.2400 - val_loss: 1.0992 - val_accuracy: 0.1222\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0975 - accuracy: 0.1305 - val_loss: 1.0973 - val_accuracy: 0.2689\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0951 - accuracy: 0.2229 - val_loss: 1.0939 - val_accuracy: 0.2022\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0914 - accuracy: 0.2143 - val_loss: 1.0907 - val_accuracy: 0.1578\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0883 - accuracy: 0.2724 - val_loss: 1.0874 - val_accuracy: 0.2489\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0823 - accuracy: 0.2819 - val_loss: 1.0801 - val_accuracy: 0.3956\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0752 - accuracy: 0.4238 - val_loss: 1.0734 - val_accuracy: 0.5044\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0670 - accuracy: 0.4486 - val_loss: 1.0639 - val_accuracy: 0.4133\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0561 - accuracy: 0.5000 - val_loss: 1.0532 - val_accuracy: 0.4911\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0434 - accuracy: 0.5238 - val_loss: 1.0386 - val_accuracy: 0.4422\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0234 - accuracy: 0.5095 - val_loss: 1.0214 - val_accuracy: 0.4667\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0008 - accuracy: 0.5505 - val_loss: 1.0007 - val_accuracy: 0.5156\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9763 - accuracy: 0.5705 - val_loss: 0.9737 - val_accuracy: 0.5333\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9534 - accuracy: 0.5943 - val_loss: 0.9556 - val_accuracy: 0.5289\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9296 - accuracy: 0.6238 - val_loss: 0.9411 - val_accuracy: 0.5222\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9114 - accuracy: 0.5905 - val_loss: 0.9099 - val_accuracy: 0.5644\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8853 - accuracy: 0.6019 - val_loss: 0.8895 - val_accuracy: 0.5822\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8654 - accuracy: 0.6524 - val_loss: 0.8693 - val_accuracy: 0.6222\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8509 - accuracy: 0.6000 - val_loss: 0.8541 - val_accuracy: 0.5933\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8314 - accuracy: 0.6210 - val_loss: 0.8395 - val_accuracy: 0.7089\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8177 - accuracy: 0.6562 - val_loss: 0.8274 - val_accuracy: 0.6844\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8061 - accuracy: 0.6429 - val_loss: 0.8160 - val_accuracy: 0.7222\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7952 - accuracy: 0.7143 - val_loss: 0.8084 - val_accuracy: 0.7089\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7845 - accuracy: 0.6210 - val_loss: 0.8018 - val_accuracy: 0.6178\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7823 - accuracy: 0.6600 - val_loss: 0.7952 - val_accuracy: 0.6333\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7707 - accuracy: 0.6371 - val_loss: 0.7860 - val_accuracy: 0.7000\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7637 - accuracy: 0.7114 - val_loss: 0.7824 - val_accuracy: 0.7556\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7600 - accuracy: 0.7848 - val_loss: 0.7757 - val_accuracy: 0.7489\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7577 - accuracy: 0.6733 - val_loss: 0.7721 - val_accuracy: 0.7933\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7480 - accuracy: 0.7933 - val_loss: 0.7781 - val_accuracy: 0.6689\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7483 - accuracy: 0.7295 - val_loss: 0.7635 - val_accuracy: 0.7867\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7399 - accuracy: 0.7467 - val_loss: 0.7623 - val_accuracy: 0.7667\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7384 - accuracy: 0.7457 - val_loss: 0.7636 - val_accuracy: 0.7889\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7334 - accuracy: 0.7486 - val_loss: 0.7573 - val_accuracy: 0.6933\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7334 - accuracy: 0.7638 - val_loss: 0.7548 - val_accuracy: 0.8378\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7288 - accuracy: 0.8390 - val_loss: 0.7500 - val_accuracy: 0.8022\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7228 - accuracy: 0.8114 - val_loss: 0.7431 - val_accuracy: 0.8222\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7184 - accuracy: 0.8324 - val_loss: 0.7413 - val_accuracy: 0.7444\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7211 - accuracy: 0.7181 - val_loss: 0.7377 - val_accuracy: 0.8378\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7136 - accuracy: 0.8200 - val_loss: 0.7503 - val_accuracy: 0.6244\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7117 - accuracy: 0.7571 - val_loss: 0.7291 - val_accuracy: 0.8400\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7027 - accuracy: 0.8181 - val_loss: 0.7314 - val_accuracy: 0.8067\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7076 - accuracy: 0.8248 - val_loss: 0.7249 - val_accuracy: 0.7200\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6980 - accuracy: 0.8000 - val_loss: 0.7179 - val_accuracy: 0.8378\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6918 - accuracy: 0.8057 - val_loss: 0.7121 - val_accuracy: 0.8356\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6843 - accuracy: 0.8419 - val_loss: 0.7093 - val_accuracy: 0.7800\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6844 - accuracy: 0.8210 - val_loss: 0.7033 - val_accuracy: 0.8244\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6753 - accuracy: 0.8457 - val_loss: 0.7048 - val_accuracy: 0.8111\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.6707 - accuracy: 0.8200 - val_loss: 0.6935 - val_accuracy: 0.7689\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6661 - accuracy: 0.7867 - val_loss: 0.6949 - val_accuracy: 0.8467\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6616 - accuracy: 0.8257 - val_loss: 0.6786 - val_accuracy: 0.8333\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6545 - accuracy: 0.8267 - val_loss: 0.6735 - val_accuracy: 0.8178\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6443 - accuracy: 0.8352 - val_loss: 0.6686 - val_accuracy: 0.8489\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6356 - accuracy: 0.8267 - val_loss: 0.6595 - val_accuracy: 0.8400\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6285 - accuracy: 0.8562 - val_loss: 0.6529 - val_accuracy: 0.8000\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6236 - accuracy: 0.8181 - val_loss: 0.6463 - val_accuracy: 0.7778\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6133 - accuracy: 0.8429 - val_loss: 0.6360 - val_accuracy: 0.8333\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6042 - accuracy: 0.8429 - val_loss: 0.6234 - val_accuracy: 0.8467\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5947 - accuracy: 0.8495 - val_loss: 0.6195 - val_accuracy: 0.8489\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.8362 - val_loss: 0.6233 - val_accuracy: 0.7800\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5769 - accuracy: 0.8400 - val_loss: 0.5957 - val_accuracy: 0.8422\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.8467 - val_loss: 0.5887 - val_accuracy: 0.8378\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.5582 - accuracy: 0.8476 - val_loss: 0.5819 - val_accuracy: 0.8422\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5481 - accuracy: 0.8619 - val_loss: 0.5691 - val_accuracy: 0.8400\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5391 - accuracy: 0.8552 - val_loss: 0.5567 - val_accuracy: 0.8444\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.8610 - val_loss: 0.5489 - val_accuracy: 0.8511\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5206 - accuracy: 0.8619 - val_loss: 0.5436 - val_accuracy: 0.8333\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5056 - accuracy: 0.8600 - val_loss: 0.5277 - val_accuracy: 0.8533\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4962 - accuracy: 0.8676 - val_loss: 0.5447 - val_accuracy: 0.8156\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.5005 - accuracy: 0.8543 - val_loss: 0.5115 - val_accuracy: 0.8444\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4822 - accuracy: 0.8581 - val_loss: 0.5049 - val_accuracy: 0.8644\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4731 - accuracy: 0.8600 - val_loss: 0.4918 - val_accuracy: 0.8622\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.8657 - val_loss: 0.4851 - val_accuracy: 0.8644\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.4535 - accuracy: 0.8667 - val_loss: 0.4844 - val_accuracy: 0.8467\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8743 - val_loss: 0.4640 - val_accuracy: 0.8556\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.4372 - accuracy: 0.8686 - val_loss: 0.4710 - val_accuracy: 0.8644\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[145   3   6]\n",
            " [  0 134  11]\n",
            " [ 15  26 110]]\n",
            "\n",
            "P-Score: 0.865, R-Score: 0.865, F-Score: 0.862\n",
            "[0.8644444444444445, 0.8648258739513389, 0.8647243979283257, 0.861687885195194, 0.945441382941383, 0.914527981910684, 0.8358103169505415, 0.8985932272675362]\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.877778   0.877042  0.877647  0.876978  0.952330  0.910571  0.862201   \n",
            "1  0.851111   0.850968  0.851318  0.850757  0.917910  0.898756  0.848889   \n",
            "2  0.853333   0.852629  0.853456  0.850674  0.928681  0.914019  0.827482   \n",
            "3  0.895556   0.900161  0.895952  0.894564  0.967269  0.923403  0.875645   \n",
            "4  0.884444   0.885207  0.884270  0.884149  0.960776  0.905653  0.873807   \n",
            "5  0.840000   0.839633  0.839915  0.839698  0.914531  0.886603  0.838889   \n",
            "6  0.728889   0.742268  0.729336  0.732035  0.753971  0.808819  0.827549   \n",
            "7  0.853333   0.855724  0.853800  0.852908  0.924667  0.895986  0.850628   \n",
            "8  0.888889   0.889955  0.888679  0.889068  0.952593  0.913680  0.883674   \n",
            "9  0.864444   0.864826  0.864724  0.861688  0.945441  0.914528  0.835810   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.908367  \n",
            "1       0.888518  \n",
            "2       0.890061  \n",
            "3       0.922106  \n",
            "4       0.913412  \n",
            "5       0.880008  \n",
            "6       0.796779  \n",
            "7       0.890427  \n",
            "8       0.916649  \n",
            "9       0.898593  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00064463 0.00045863 0.09889675]\n",
            " [0.02019877 0.06752565 0.01227557]\n",
            " [0.0157502  0.08320622 0.00104358]\n",
            " ...\n",
            " [0.02076931 0.07781978 0.00141092]\n",
            " [0.03426459 0.04214225 0.02359315]\n",
            " [0.02681999 0.07237139 0.00080862]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_name = 'MLP_SGD'\n",
        "NAME = 'Landsat8_DATA'\n",
        "optimiser_type = 'sgd'\n",
        "experimental_runs = 10\n",
        "\n",
        "best_model, best_history, avg_y_pred, df = MLP_model(optimiser_type, experimental_runs, train_x, train_y, test_x, test_y)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "best_model.save('Best_model_{}_{}'.format(NAME, Model_name))\n",
        "plot_metric(best_history, \"loss\")\n",
        "print(\"\")\n",
        "plot_metric(best_history, \"accuracy\")\n",
        "# plot_AUC_ROC(best_model, test_x, test_y, 3, label_names)\n",
        "# print(\"\")\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "print(avg_y_pred)\n",
        "test_y_dummies = test_y.argmax(axis = 1)\n",
        "plot_avg_AUC_ROC(avg_y_pred, test_y_dummies, 3, label_names)\n",
        "print(\"\")\n",
        "avg_y_pred = avg_y_pred.argmax(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tFQ5lUcy6m9H",
        "outputId": "3d56001c-3b4f-4632-d818-6a985621e3b2"
      },
      "id": "tFQ5lUcy6m9H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_59\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_128 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_129 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_130 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 8ms/step - loss: 1.0861 - accuracy: 0.4571 - val_loss: 1.0832 - val_accuracy: 0.4178\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0801 - accuracy: 0.3819 - val_loss: 1.0787 - val_accuracy: 0.3689\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.3876 - val_loss: 1.0781 - val_accuracy: 0.3289\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0722 - accuracy: 0.3829 - val_loss: 1.0712 - val_accuracy: 0.3711\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0686 - accuracy: 0.3714 - val_loss: 1.0682 - val_accuracy: 0.3556\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0643 - accuracy: 0.3819 - val_loss: 1.0635 - val_accuracy: 0.3956\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0599 - accuracy: 0.4048 - val_loss: 1.0610 - val_accuracy: 0.3400\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0552 - accuracy: 0.4295 - val_loss: 1.0559 - val_accuracy: 0.4400\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0512 - accuracy: 0.3981 - val_loss: 1.0558 - val_accuracy: 0.3422\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0464 - accuracy: 0.4971 - val_loss: 1.0475 - val_accuracy: 0.4022\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0409 - accuracy: 0.4648 - val_loss: 1.0423 - val_accuracy: 0.5156\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0357 - accuracy: 0.5876 - val_loss: 1.0374 - val_accuracy: 0.5533\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0305 - accuracy: 0.5876 - val_loss: 1.0346 - val_accuracy: 0.4911\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0260 - accuracy: 0.5952 - val_loss: 1.0287 - val_accuracy: 0.5200\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0204 - accuracy: 0.6114 - val_loss: 1.0271 - val_accuracy: 0.4889\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0157 - accuracy: 0.5838 - val_loss: 1.0179 - val_accuracy: 0.5778\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0098 - accuracy: 0.6019 - val_loss: 1.0129 - val_accuracy: 0.5778\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0046 - accuracy: 0.6190 - val_loss: 1.0159 - val_accuracy: 0.5178\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9995 - accuracy: 0.6076 - val_loss: 1.0026 - val_accuracy: 0.5844\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9931 - accuracy: 0.6190 - val_loss: 0.9978 - val_accuracy: 0.6533\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9890 - accuracy: 0.6210 - val_loss: 0.9962 - val_accuracy: 0.5489\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9832 - accuracy: 0.6010 - val_loss: 0.9870 - val_accuracy: 0.5956\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9785 - accuracy: 0.6171 - val_loss: 0.9816 - val_accuracy: 0.5978\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9717 - accuracy: 0.6229 - val_loss: 0.9760 - val_accuracy: 0.5956\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9650 - accuracy: 0.6105 - val_loss: 0.9774 - val_accuracy: 0.5378\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9595 - accuracy: 0.6038 - val_loss: 0.9666 - val_accuracy: 0.5644\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9538 - accuracy: 0.6210 - val_loss: 0.9613 - val_accuracy: 0.6444\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9473 - accuracy: 0.6048 - val_loss: 0.9533 - val_accuracy: 0.6444\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9408 - accuracy: 0.6200 - val_loss: 0.9466 - val_accuracy: 0.6067\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9335 - accuracy: 0.6219 - val_loss: 0.9412 - val_accuracy: 0.5911\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9278 - accuracy: 0.6190 - val_loss: 0.9340 - val_accuracy: 0.6178\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9210 - accuracy: 0.6314 - val_loss: 0.9294 - val_accuracy: 0.5933\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9141 - accuracy: 0.6171 - val_loss: 0.9215 - val_accuracy: 0.6089\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9070 - accuracy: 0.6162 - val_loss: 0.9151 - val_accuracy: 0.6400\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8995 - accuracy: 0.6238 - val_loss: 0.9086 - val_accuracy: 0.6067\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8938 - accuracy: 0.6219 - val_loss: 0.9097 - val_accuracy: 0.5511\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8858 - accuracy: 0.6295 - val_loss: 0.8954 - val_accuracy: 0.6089\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8788 - accuracy: 0.6295 - val_loss: 0.8920 - val_accuracy: 0.5956\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8737 - accuracy: 0.6229 - val_loss: 0.8832 - val_accuracy: 0.6044\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8665 - accuracy: 0.6267 - val_loss: 0.8765 - val_accuracy: 0.6333\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8595 - accuracy: 0.6171 - val_loss: 0.8727 - val_accuracy: 0.6022\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8544 - accuracy: 0.6295 - val_loss: 0.8647 - val_accuracy: 0.6156\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8466 - accuracy: 0.6257 - val_loss: 0.8588 - val_accuracy: 0.6467\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8421 - accuracy: 0.6314 - val_loss: 0.8529 - val_accuracy: 0.6267\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8356 - accuracy: 0.6229 - val_loss: 0.8475 - val_accuracy: 0.6111\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8311 - accuracy: 0.6219 - val_loss: 0.8421 - val_accuracy: 0.6533\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8235 - accuracy: 0.6133 - val_loss: 0.8471 - val_accuracy: 0.6800\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8193 - accuracy: 0.6324 - val_loss: 0.8354 - val_accuracy: 0.6044\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8108 - accuracy: 0.6343 - val_loss: 0.8264 - val_accuracy: 0.6689\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8065 - accuracy: 0.6381 - val_loss: 0.8228 - val_accuracy: 0.6244\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8012 - accuracy: 0.6457 - val_loss: 0.8207 - val_accuracy: 0.6844\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7954 - accuracy: 0.6352 - val_loss: 0.8142 - val_accuracy: 0.6778\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7928 - accuracy: 0.6438 - val_loss: 0.8067 - val_accuracy: 0.6756\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7893 - accuracy: 0.6476 - val_loss: 0.8026 - val_accuracy: 0.6556\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7815 - accuracy: 0.6533 - val_loss: 0.8026 - val_accuracy: 0.6111\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7779 - accuracy: 0.6524 - val_loss: 0.7962 - val_accuracy: 0.6867\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7740 - accuracy: 0.6562 - val_loss: 0.7916 - val_accuracy: 0.6556\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7702 - accuracy: 0.6533 - val_loss: 0.8021 - val_accuracy: 0.5956\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7675 - accuracy: 0.6457 - val_loss: 0.7838 - val_accuracy: 0.6844\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7660 - accuracy: 0.6667 - val_loss: 0.7835 - val_accuracy: 0.6911\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7648 - accuracy: 0.6448 - val_loss: 0.7788 - val_accuracy: 0.6600\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7570 - accuracy: 0.6638 - val_loss: 0.7750 - val_accuracy: 0.6689\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7529 - accuracy: 0.6638 - val_loss: 0.7735 - val_accuracy: 0.6600\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7499 - accuracy: 0.6648 - val_loss: 0.7697 - val_accuracy: 0.6689\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7491 - accuracy: 0.6600 - val_loss: 0.7683 - val_accuracy: 0.7222\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7433 - accuracy: 0.6762 - val_loss: 0.7634 - val_accuracy: 0.7111\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7418 - accuracy: 0.6876 - val_loss: 0.7608 - val_accuracy: 0.7022\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.6705 - val_loss: 0.7642 - val_accuracy: 0.6489\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7349 - accuracy: 0.6857 - val_loss: 0.7594 - val_accuracy: 0.6644\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7370 - accuracy: 0.6886 - val_loss: 0.7507 - val_accuracy: 0.7178\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7301 - accuracy: 0.6914 - val_loss: 0.7473 - val_accuracy: 0.7356\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7255 - accuracy: 0.6895 - val_loss: 0.7464 - val_accuracy: 0.7422\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7258 - accuracy: 0.6876 - val_loss: 0.7429 - val_accuracy: 0.7422\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7200 - accuracy: 0.6933 - val_loss: 0.7521 - val_accuracy: 0.7156\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7207 - accuracy: 0.7048 - val_loss: 0.7375 - val_accuracy: 0.7422\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7165 - accuracy: 0.7057 - val_loss: 0.7329 - val_accuracy: 0.7311\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7131 - accuracy: 0.7057 - val_loss: 0.7506 - val_accuracy: 0.7089\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7149 - accuracy: 0.7057 - val_loss: 0.7305 - val_accuracy: 0.7467\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7091 - accuracy: 0.7105 - val_loss: 0.7262 - val_accuracy: 0.7356\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7035 - accuracy: 0.7143 - val_loss: 0.7276 - val_accuracy: 0.7067\n",
            "15/15 [==============================] - 0s 1ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[ 96  41  17]\n",
            " [ 21 114  10]\n",
            " [ 31  12 108]]\n",
            "\n",
            "P-Score: 0.710, R-Score: 0.708, F-Score: 0.707\n",
            "[0.7066666666666667, 0.7104277930625237, 0.7082717693359393, 0.70725852513932, 0.7238504738504739, 0.8062182023742226, 0.8124653923674945, 0.7808446895307304]\n",
            "Model: \"sequential_60\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_131 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_132 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_133 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1179 - accuracy: 0.3086 - val_loss: 1.1150 - val_accuracy: 0.3000\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1126 - accuracy: 0.3152 - val_loss: 1.1105 - val_accuracy: 0.3222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1095 - accuracy: 0.3324 - val_loss: 1.1075 - val_accuracy: 0.3222\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1064 - accuracy: 0.3362 - val_loss: 1.1047 - val_accuracy: 0.3222\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1041 - accuracy: 0.3343 - val_loss: 1.1023 - val_accuracy: 0.3222\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1013 - accuracy: 0.3381 - val_loss: 1.1002 - val_accuracy: 0.3222\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.3381 - val_loss: 1.0978 - val_accuracy: 0.3222\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0965 - accuracy: 0.3533 - val_loss: 1.0960 - val_accuracy: 0.3222\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0942 - accuracy: 0.3486 - val_loss: 1.0935 - val_accuracy: 0.3222\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0917 - accuracy: 0.3400 - val_loss: 1.0910 - val_accuracy: 0.4133\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0892 - accuracy: 0.4143 - val_loss: 1.0888 - val_accuracy: 0.3733\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0868 - accuracy: 0.4190 - val_loss: 1.0863 - val_accuracy: 0.3978\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0839 - accuracy: 0.4257 - val_loss: 1.0840 - val_accuracy: 0.4311\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0816 - accuracy: 0.4400 - val_loss: 1.0815 - val_accuracy: 0.5000\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0789 - accuracy: 0.5343 - val_loss: 1.0794 - val_accuracy: 0.4311\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0760 - accuracy: 0.4743 - val_loss: 1.0767 - val_accuracy: 0.5311\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0734 - accuracy: 0.5629 - val_loss: 1.0743 - val_accuracy: 0.4711\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0705 - accuracy: 0.5133 - val_loss: 1.0714 - val_accuracy: 0.5289\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0676 - accuracy: 0.5486 - val_loss: 1.0686 - val_accuracy: 0.5244\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0641 - accuracy: 0.5457 - val_loss: 1.0656 - val_accuracy: 0.5333\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0610 - accuracy: 0.5743 - val_loss: 1.0628 - val_accuracy: 0.5311\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0573 - accuracy: 0.5790 - val_loss: 1.0599 - val_accuracy: 0.5178\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0539 - accuracy: 0.5657 - val_loss: 1.0559 - val_accuracy: 0.5311\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0501 - accuracy: 0.5686 - val_loss: 1.0524 - val_accuracy: 0.5400\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0459 - accuracy: 0.5790 - val_loss: 1.0476 - val_accuracy: 0.5733\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0395 - accuracy: 0.5829 - val_loss: 1.0389 - val_accuracy: 0.6044\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0304 - accuracy: 0.5200 - val_loss: 1.0315 - val_accuracy: 0.5867\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0232 - accuracy: 0.5676 - val_loss: 1.0246 - val_accuracy: 0.5978\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0169 - accuracy: 0.5819 - val_loss: 1.0183 - val_accuracy: 0.6200\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0096 - accuracy: 0.6133 - val_loss: 1.0120 - val_accuracy: 0.6067\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0018 - accuracy: 0.6333 - val_loss: 1.0104 - val_accuracy: 0.4822\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9963 - accuracy: 0.6219 - val_loss: 0.9987 - val_accuracy: 0.6711\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9886 - accuracy: 0.6381 - val_loss: 0.9931 - val_accuracy: 0.6533\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9811 - accuracy: 0.6219 - val_loss: 0.9852 - val_accuracy: 0.6311\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9750 - accuracy: 0.6743 - val_loss: 0.9786 - val_accuracy: 0.6778\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9673 - accuracy: 0.6257 - val_loss: 0.9728 - val_accuracy: 0.6711\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9596 - accuracy: 0.6343 - val_loss: 0.9650 - val_accuracy: 0.6867\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9522 - accuracy: 0.6562 - val_loss: 0.9586 - val_accuracy: 0.6422\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9445 - accuracy: 0.6267 - val_loss: 0.9548 - val_accuracy: 0.6489\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9379 - accuracy: 0.6619 - val_loss: 0.9447 - val_accuracy: 0.6844\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9305 - accuracy: 0.6305 - val_loss: 0.9377 - val_accuracy: 0.6844\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9235 - accuracy: 0.6419 - val_loss: 0.9311 - val_accuracy: 0.7000\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9153 - accuracy: 0.6600 - val_loss: 0.9248 - val_accuracy: 0.6756\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9086 - accuracy: 0.6343 - val_loss: 0.9175 - val_accuracy: 0.6867\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9003 - accuracy: 0.6590 - val_loss: 0.9130 - val_accuracy: 0.5978\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8942 - accuracy: 0.6429 - val_loss: 0.9108 - val_accuracy: 0.6044\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8866 - accuracy: 0.6410 - val_loss: 0.8980 - val_accuracy: 0.6689\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8803 - accuracy: 0.6514 - val_loss: 0.8927 - val_accuracy: 0.6556\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8734 - accuracy: 0.6571 - val_loss: 0.8852 - val_accuracy: 0.6800\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8652 - accuracy: 0.6476 - val_loss: 0.8790 - val_accuracy: 0.7067\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8600 - accuracy: 0.6533 - val_loss: 0.8749 - val_accuracy: 0.6533\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8541 - accuracy: 0.6695 - val_loss: 0.8681 - val_accuracy: 0.6356\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8480 - accuracy: 0.6524 - val_loss: 0.8737 - val_accuracy: 0.5822\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8434 - accuracy: 0.6543 - val_loss: 0.8576 - val_accuracy: 0.6578\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8366 - accuracy: 0.6571 - val_loss: 0.8518 - val_accuracy: 0.6978\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8324 - accuracy: 0.6524 - val_loss: 0.8474 - val_accuracy: 0.6733\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.6590 - val_loss: 0.8423 - val_accuracy: 0.7000\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8220 - accuracy: 0.6543 - val_loss: 0.8402 - val_accuracy: 0.6978\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8175 - accuracy: 0.6629 - val_loss: 0.8342 - val_accuracy: 0.6644\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8138 - accuracy: 0.6686 - val_loss: 0.8293 - val_accuracy: 0.7022\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8059 - accuracy: 0.6810 - val_loss: 0.8319 - val_accuracy: 0.6933\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7984 - accuracy: 0.6857 - val_loss: 0.8215 - val_accuracy: 0.7044\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7984 - accuracy: 0.6771 - val_loss: 0.8160 - val_accuracy: 0.7089\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7938 - accuracy: 0.6733 - val_loss: 0.8128 - val_accuracy: 0.7000\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7904 - accuracy: 0.6619 - val_loss: 0.8095 - val_accuracy: 0.7022\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7867 - accuracy: 0.6962 - val_loss: 0.8115 - val_accuracy: 0.6311\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7852 - accuracy: 0.6610 - val_loss: 0.8040 - val_accuracy: 0.7156\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7807 - accuracy: 0.6648 - val_loss: 0.8023 - val_accuracy: 0.7178\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7783 - accuracy: 0.6876 - val_loss: 0.8001 - val_accuracy: 0.6889\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7744 - accuracy: 0.6886 - val_loss: 0.7979 - val_accuracy: 0.7000\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7746 - accuracy: 0.6705 - val_loss: 0.7958 - val_accuracy: 0.7044\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7710 - accuracy: 0.6790 - val_loss: 0.7962 - val_accuracy: 0.6733\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.6857 - val_loss: 0.7941 - val_accuracy: 0.6578\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7664 - accuracy: 0.6943 - val_loss: 0.7935 - val_accuracy: 0.7133\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.6800 - val_loss: 0.7878 - val_accuracy: 0.6556\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7615 - accuracy: 0.6733 - val_loss: 0.8000 - val_accuracy: 0.6511\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7621 - accuracy: 0.6800 - val_loss: 0.7831 - val_accuracy: 0.7178\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7600 - accuracy: 0.6886 - val_loss: 0.8040 - val_accuracy: 0.6378\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7567 - accuracy: 0.6971 - val_loss: 0.7817 - val_accuracy: 0.7333\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7535 - accuracy: 0.7029 - val_loss: 0.7805 - val_accuracy: 0.7356\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[113  21  20]\n",
            " [ 23  96  26]\n",
            " [ 21   8 122]]\n",
            "\n",
            "P-Score: 0.738, R-Score: 0.735, F-Score: 0.734\n",
            "[0.7355555555555555, 0.7379785663734708, 0.7345940730503416, 0.7342298320455544, 0.7925587925587925, 0.7834934991520632, 0.8270504330106979, 0.8010342415738512]\n",
            "Model: \"sequential_61\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_134 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_135 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_136 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.3163 - accuracy: 0.3324 - val_loss: 1.1924 - val_accuracy: 0.3356\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1681 - accuracy: 0.3038 - val_loss: 1.1480 - val_accuracy: 0.2289\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1461 - accuracy: 0.1714 - val_loss: 1.1366 - val_accuracy: 0.1444\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1369 - accuracy: 0.1276 - val_loss: 1.1299 - val_accuracy: 0.1244\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1305 - accuracy: 0.1629 - val_loss: 1.1240 - val_accuracy: 0.1378\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1252 - accuracy: 0.2286 - val_loss: 1.1195 - val_accuracy: 0.1444\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1203 - accuracy: 0.1886 - val_loss: 1.1157 - val_accuracy: 0.3267\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1143 - accuracy: 0.3543 - val_loss: 1.1079 - val_accuracy: 0.3956\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1083 - accuracy: 0.4133 - val_loss: 1.1055 - val_accuracy: 0.3444\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1046 - accuracy: 0.3943 - val_loss: 1.1043 - val_accuracy: 0.3267\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1024 - accuracy: 0.3733 - val_loss: 1.0999 - val_accuracy: 0.3667\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0997 - accuracy: 0.3867 - val_loss: 1.0974 - val_accuracy: 0.3622\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0969 - accuracy: 0.3867 - val_loss: 1.0945 - val_accuracy: 0.3956\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0945 - accuracy: 0.4067 - val_loss: 1.0920 - val_accuracy: 0.4000\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0918 - accuracy: 0.4133 - val_loss: 1.0895 - val_accuracy: 0.4156\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0894 - accuracy: 0.4200 - val_loss: 1.0874 - val_accuracy: 0.3933\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0866 - accuracy: 0.4171 - val_loss: 1.0848 - val_accuracy: 0.4267\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0834 - accuracy: 0.4152 - val_loss: 1.0829 - val_accuracy: 0.4778\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0817 - accuracy: 0.4495 - val_loss: 1.0800 - val_accuracy: 0.4289\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0782 - accuracy: 0.4505 - val_loss: 1.0800 - val_accuracy: 0.3556\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0765 - accuracy: 0.4019 - val_loss: 1.0751 - val_accuracy: 0.4600\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0746 - accuracy: 0.4143 - val_loss: 1.0727 - val_accuracy: 0.4889\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0717 - accuracy: 0.4419 - val_loss: 1.0703 - val_accuracy: 0.4644\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0698 - accuracy: 0.4352 - val_loss: 1.0690 - val_accuracy: 0.3978\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0664 - accuracy: 0.4419 - val_loss: 1.0655 - val_accuracy: 0.4467\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0638 - accuracy: 0.4352 - val_loss: 1.0629 - val_accuracy: 0.5267\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0613 - accuracy: 0.4629 - val_loss: 1.0618 - val_accuracy: 0.3978\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0583 - accuracy: 0.4600 - val_loss: 1.0581 - val_accuracy: 0.4356\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0555 - accuracy: 0.4638 - val_loss: 1.0559 - val_accuracy: 0.4267\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0518 - accuracy: 0.4524 - val_loss: 1.0526 - val_accuracy: 0.4556\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0495 - accuracy: 0.4676 - val_loss: 1.0504 - val_accuracy: 0.4356\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0467 - accuracy: 0.4505 - val_loss: 1.0469 - val_accuracy: 0.4689\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0439 - accuracy: 0.4505 - val_loss: 1.0438 - val_accuracy: 0.4956\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0404 - accuracy: 0.4800 - val_loss: 1.0459 - val_accuracy: 0.3800\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0374 - accuracy: 0.4543 - val_loss: 1.0370 - val_accuracy: 0.4356\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0318 - accuracy: 0.4514 - val_loss: 1.0319 - val_accuracy: 0.4844\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0273 - accuracy: 0.4619 - val_loss: 1.0274 - val_accuracy: 0.4444\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0222 - accuracy: 0.4495 - val_loss: 1.0221 - val_accuracy: 0.4578\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0158 - accuracy: 0.4848 - val_loss: 1.0179 - val_accuracy: 0.5200\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0126 - accuracy: 0.5000 - val_loss: 1.0145 - val_accuracy: 0.4756\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.5638 - val_loss: 1.0099 - val_accuracy: 0.4933\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0037 - accuracy: 0.5610 - val_loss: 1.0048 - val_accuracy: 0.5333\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9992 - accuracy: 0.6076 - val_loss: 1.0002 - val_accuracy: 0.5867\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9936 - accuracy: 0.6067 - val_loss: 0.9957 - val_accuracy: 0.6556\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9891 - accuracy: 0.5933 - val_loss: 0.9922 - val_accuracy: 0.6444\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9828 - accuracy: 0.6733 - val_loss: 0.9879 - val_accuracy: 0.7378\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9802 - accuracy: 0.6486 - val_loss: 0.9819 - val_accuracy: 0.6689\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9743 - accuracy: 0.7010 - val_loss: 0.9819 - val_accuracy: 0.6067\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9700 - accuracy: 0.6781 - val_loss: 0.9725 - val_accuracy: 0.6578\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9654 - accuracy: 0.7010 - val_loss: 0.9692 - val_accuracy: 0.6422\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9583 - accuracy: 0.6905 - val_loss: 0.9624 - val_accuracy: 0.7267\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9530 - accuracy: 0.6886 - val_loss: 0.9567 - val_accuracy: 0.7111\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9484 - accuracy: 0.6981 - val_loss: 0.9522 - val_accuracy: 0.7400\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9437 - accuracy: 0.6876 - val_loss: 0.9463 - val_accuracy: 0.6889\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9369 - accuracy: 0.6981 - val_loss: 0.9413 - val_accuracy: 0.7311\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9327 - accuracy: 0.7029 - val_loss: 0.9429 - val_accuracy: 0.6222\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9270 - accuracy: 0.7029 - val_loss: 0.9314 - val_accuracy: 0.6578\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9204 - accuracy: 0.7010 - val_loss: 0.9254 - val_accuracy: 0.6667\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9142 - accuracy: 0.6962 - val_loss: 0.9192 - val_accuracy: 0.7378\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9089 - accuracy: 0.7143 - val_loss: 0.9151 - val_accuracy: 0.6756\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9029 - accuracy: 0.6971 - val_loss: 0.9088 - val_accuracy: 0.6778\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8979 - accuracy: 0.6981 - val_loss: 0.9057 - val_accuracy: 0.6533\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8913 - accuracy: 0.6962 - val_loss: 0.8961 - val_accuracy: 0.7267\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8833 - accuracy: 0.7086 - val_loss: 0.8952 - val_accuracy: 0.6578\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8798 - accuracy: 0.7038 - val_loss: 0.8846 - val_accuracy: 0.7333\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8736 - accuracy: 0.7076 - val_loss: 0.8891 - val_accuracy: 0.6378\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8658 - accuracy: 0.7086 - val_loss: 0.8730 - val_accuracy: 0.7267\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8613 - accuracy: 0.7105 - val_loss: 0.8856 - val_accuracy: 0.6178\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8561 - accuracy: 0.7000 - val_loss: 0.8626 - val_accuracy: 0.7178\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8479 - accuracy: 0.7105 - val_loss: 0.8629 - val_accuracy: 0.7400\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8440 - accuracy: 0.7105 - val_loss: 0.8503 - val_accuracy: 0.7267\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8364 - accuracy: 0.7190 - val_loss: 0.8444 - val_accuracy: 0.7311\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8317 - accuracy: 0.7171 - val_loss: 0.8441 - val_accuracy: 0.6756\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8270 - accuracy: 0.7162 - val_loss: 0.8408 - val_accuracy: 0.7422\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8202 - accuracy: 0.7229 - val_loss: 0.8284 - val_accuracy: 0.7289\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8143 - accuracy: 0.7171 - val_loss: 0.8234 - val_accuracy: 0.7200\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8088 - accuracy: 0.7171 - val_loss: 0.8227 - val_accuracy: 0.6822\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8020 - accuracy: 0.7190 - val_loss: 0.8138 - val_accuracy: 0.7578\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7974 - accuracy: 0.7248 - val_loss: 0.8060 - val_accuracy: 0.7378\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7894 - accuracy: 0.7286 - val_loss: 0.8012 - val_accuracy: 0.7400\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[101  34  19]\n",
            " [ 13 118  14]\n",
            " [ 22  15 114]]\n",
            "\n",
            "P-Score: 0.742, R-Score: 0.742, F-Score: 0.739\n",
            "[0.74, 0.7415813630841558, 0.7415347155698834, 0.7393542172297091, 0.7688004563004565, 0.8265686828716788, 0.8222994972203148, 0.80588954546415]\n",
            "Model: \"sequential_62\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_137 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_138 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_139 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1369 - accuracy: 0.3438 - val_loss: 1.1045 - val_accuracy: 0.3400\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1044 - accuracy: 0.2933 - val_loss: 1.1002 - val_accuracy: 0.3133\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1013 - accuracy: 0.2762 - val_loss: 1.0980 - val_accuracy: 0.2667\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0976 - accuracy: 0.2676 - val_loss: 1.0940 - val_accuracy: 0.2800\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0941 - accuracy: 0.3086 - val_loss: 1.0912 - val_accuracy: 0.3422\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0906 - accuracy: 0.3314 - val_loss: 1.0904 - val_accuracy: 0.3178\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0880 - accuracy: 0.3257 - val_loss: 1.0847 - val_accuracy: 0.4422\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0846 - accuracy: 0.4210 - val_loss: 1.0830 - val_accuracy: 0.3244\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0809 - accuracy: 0.3533 - val_loss: 1.0798 - val_accuracy: 0.3933\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0767 - accuracy: 0.4124 - val_loss: 1.0790 - val_accuracy: 0.3956\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0733 - accuracy: 0.4476 - val_loss: 1.0721 - val_accuracy: 0.4089\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0697 - accuracy: 0.4762 - val_loss: 1.0692 - val_accuracy: 0.3578\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0668 - accuracy: 0.4695 - val_loss: 1.0643 - val_accuracy: 0.4511\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0608 - accuracy: 0.4705 - val_loss: 1.0601 - val_accuracy: 0.5289\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0571 - accuracy: 0.5229 - val_loss: 1.0557 - val_accuracy: 0.5356\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0507 - accuracy: 0.5048 - val_loss: 1.0509 - val_accuracy: 0.5778\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0479 - accuracy: 0.5486 - val_loss: 1.0469 - val_accuracy: 0.5511\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0425 - accuracy: 0.5552 - val_loss: 1.0419 - val_accuracy: 0.5533\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0362 - accuracy: 0.5724 - val_loss: 1.0396 - val_accuracy: 0.5267\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0307 - accuracy: 0.5667 - val_loss: 1.0314 - val_accuracy: 0.5778\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0256 - accuracy: 0.5733 - val_loss: 1.0259 - val_accuracy: 0.6044\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0191 - accuracy: 0.5781 - val_loss: 1.0223 - val_accuracy: 0.5311\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0133 - accuracy: 0.5848 - val_loss: 1.0142 - val_accuracy: 0.5689\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0068 - accuracy: 0.5933 - val_loss: 1.0090 - val_accuracy: 0.5889\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0009 - accuracy: 0.6000 - val_loss: 1.0051 - val_accuracy: 0.5533\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9939 - accuracy: 0.5981 - val_loss: 0.9976 - val_accuracy: 0.5778\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9870 - accuracy: 0.5952 - val_loss: 0.9902 - val_accuracy: 0.6111\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9811 - accuracy: 0.6086 - val_loss: 0.9854 - val_accuracy: 0.5733\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9731 - accuracy: 0.6048 - val_loss: 0.9766 - val_accuracy: 0.6111\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9658 - accuracy: 0.6000 - val_loss: 0.9709 - val_accuracy: 0.6067\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9587 - accuracy: 0.6057 - val_loss: 0.9635 - val_accuracy: 0.6178\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9511 - accuracy: 0.6086 - val_loss: 0.9581 - val_accuracy: 0.6133\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9426 - accuracy: 0.6295 - val_loss: 0.9507 - val_accuracy: 0.5956\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9355 - accuracy: 0.6105 - val_loss: 0.9414 - val_accuracy: 0.6244\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9271 - accuracy: 0.6267 - val_loss: 0.9336 - val_accuracy: 0.6089\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9206 - accuracy: 0.6257 - val_loss: 0.9302 - val_accuracy: 0.6333\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9118 - accuracy: 0.6114 - val_loss: 0.9243 - val_accuracy: 0.6267\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9047 - accuracy: 0.6162 - val_loss: 0.9135 - val_accuracy: 0.6133\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8960 - accuracy: 0.6533 - val_loss: 0.9058 - val_accuracy: 0.6289\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8904 - accuracy: 0.6210 - val_loss: 0.8992 - val_accuracy: 0.6267\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8811 - accuracy: 0.6352 - val_loss: 0.8971 - val_accuracy: 0.6111\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8737 - accuracy: 0.6390 - val_loss: 0.8868 - val_accuracy: 0.5711\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8672 - accuracy: 0.6171 - val_loss: 0.8789 - val_accuracy: 0.6200\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8610 - accuracy: 0.6352 - val_loss: 0.8714 - val_accuracy: 0.6022\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8514 - accuracy: 0.6381 - val_loss: 0.8662 - val_accuracy: 0.6289\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8464 - accuracy: 0.6248 - val_loss: 0.8573 - val_accuracy: 0.6200\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8374 - accuracy: 0.6343 - val_loss: 0.8505 - val_accuracy: 0.6022\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8297 - accuracy: 0.6295 - val_loss: 0.8563 - val_accuracy: 0.5733\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8260 - accuracy: 0.6343 - val_loss: 0.8404 - val_accuracy: 0.6422\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8198 - accuracy: 0.6429 - val_loss: 0.8361 - val_accuracy: 0.6311\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8148 - accuracy: 0.6562 - val_loss: 0.8270 - val_accuracy: 0.6267\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8072 - accuracy: 0.6514 - val_loss: 0.8263 - val_accuracy: 0.6511\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8022 - accuracy: 0.6410 - val_loss: 0.8224 - val_accuracy: 0.6178\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7978 - accuracy: 0.6381 - val_loss: 0.8124 - val_accuracy: 0.6333\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7909 - accuracy: 0.6324 - val_loss: 0.8119 - val_accuracy: 0.6000\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7918 - accuracy: 0.6533 - val_loss: 0.8047 - val_accuracy: 0.6511\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7850 - accuracy: 0.6610 - val_loss: 0.8084 - val_accuracy: 0.6422\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7837 - accuracy: 0.6495 - val_loss: 0.8005 - val_accuracy: 0.6622\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.6438 - val_loss: 0.7961 - val_accuracy: 0.6267\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7748 - accuracy: 0.6457 - val_loss: 0.7996 - val_accuracy: 0.6000\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7702 - accuracy: 0.6419 - val_loss: 0.7921 - val_accuracy: 0.6556\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7686 - accuracy: 0.6448 - val_loss: 0.7881 - val_accuracy: 0.6489\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7656 - accuracy: 0.6467 - val_loss: 0.7846 - val_accuracy: 0.6467\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7629 - accuracy: 0.6686 - val_loss: 0.7832 - val_accuracy: 0.6489\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7571 - accuracy: 0.6371 - val_loss: 0.7783 - val_accuracy: 0.6733\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7599 - accuracy: 0.6638 - val_loss: 0.7751 - val_accuracy: 0.6444\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7554 - accuracy: 0.6629 - val_loss: 0.7747 - val_accuracy: 0.6756\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7527 - accuracy: 0.6743 - val_loss: 0.7713 - val_accuracy: 0.6511\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7511 - accuracy: 0.6705 - val_loss: 0.7718 - val_accuracy: 0.6444\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7484 - accuracy: 0.6610 - val_loss: 0.7702 - val_accuracy: 0.6556\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7489 - accuracy: 0.6524 - val_loss: 0.7698 - val_accuracy: 0.6356\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7464 - accuracy: 0.6838 - val_loss: 0.7634 - val_accuracy: 0.6556\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7415 - accuracy: 0.6781 - val_loss: 0.7625 - val_accuracy: 0.6533\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7399 - accuracy: 0.6924 - val_loss: 0.7934 - val_accuracy: 0.6378\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7412 - accuracy: 0.6762 - val_loss: 0.7640 - val_accuracy: 0.6733\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7380 - accuracy: 0.6676 - val_loss: 0.7594 - val_accuracy: 0.6667\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7346 - accuracy: 0.6857 - val_loss: 0.7559 - val_accuracy: 0.6667\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7336 - accuracy: 0.6848 - val_loss: 0.7594 - val_accuracy: 0.6644\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7267 - accuracy: 0.6952 - val_loss: 0.7537 - val_accuracy: 0.6822\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7314 - accuracy: 0.7000 - val_loss: 0.7511 - val_accuracy: 0.6933\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[103  37  14]\n",
            " [ 32  82  31]\n",
            " [  7  17 127]]\n",
            "\n",
            "P-Score: 0.689, R-Score: 0.692, F-Score: 0.689\n",
            "[0.6933333333333334, 0.6888884607233002, 0.691802670953162, 0.6886511827209029, 0.768537206037206, 0.6942340305257207, 0.845278965204102, 0.7693500672556762]\n",
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_140 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_141 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_142 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1986 - accuracy: 0.2981 - val_loss: 1.1187 - val_accuracy: 0.3422\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1191 - accuracy: 0.3286 - val_loss: 1.1071 - val_accuracy: 0.3422\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1076 - accuracy: 0.3238 - val_loss: 1.1009 - val_accuracy: 0.3422\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1013 - accuracy: 0.3371 - val_loss: 1.0960 - val_accuracy: 0.3422\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0958 - accuracy: 0.3400 - val_loss: 1.0919 - val_accuracy: 0.3689\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0908 - accuracy: 0.4448 - val_loss: 1.0876 - val_accuracy: 0.4844\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0857 - accuracy: 0.5571 - val_loss: 1.0826 - val_accuracy: 0.6778\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0804 - accuracy: 0.6295 - val_loss: 1.0783 - val_accuracy: 0.6222\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0755 - accuracy: 0.6448 - val_loss: 1.0744 - val_accuracy: 0.6511\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0709 - accuracy: 0.6762 - val_loss: 1.0702 - val_accuracy: 0.6356\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0663 - accuracy: 0.6543 - val_loss: 1.0663 - val_accuracy: 0.6244\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0616 - accuracy: 0.6143 - val_loss: 1.0620 - val_accuracy: 0.7556\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0571 - accuracy: 0.6733 - val_loss: 1.0573 - val_accuracy: 0.7867\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0518 - accuracy: 0.7352 - val_loss: 1.0521 - val_accuracy: 0.6489\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0465 - accuracy: 0.7086 - val_loss: 1.0471 - val_accuracy: 0.6844\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0415 - accuracy: 0.7571 - val_loss: 1.0419 - val_accuracy: 0.6200\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0356 - accuracy: 0.6790 - val_loss: 1.0363 - val_accuracy: 0.7333\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0300 - accuracy: 0.7533 - val_loss: 1.0306 - val_accuracy: 0.6978\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0220 - accuracy: 0.7143 - val_loss: 1.0191 - val_accuracy: 0.6222\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0067 - accuracy: 0.6476 - val_loss: 1.0052 - val_accuracy: 0.5556\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9873 - accuracy: 0.7067 - val_loss: 0.9944 - val_accuracy: 0.5422\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9765 - accuracy: 0.6895 - val_loss: 0.9780 - val_accuracy: 0.6711\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9673 - accuracy: 0.6762 - val_loss: 0.9691 - val_accuracy: 0.6733\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9572 - accuracy: 0.6905 - val_loss: 0.9612 - val_accuracy: 0.6556\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9483 - accuracy: 0.7086 - val_loss: 0.9522 - val_accuracy: 0.6778\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9378 - accuracy: 0.6981 - val_loss: 0.9450 - val_accuracy: 0.8044\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9291 - accuracy: 0.7390 - val_loss: 0.9348 - val_accuracy: 0.6733\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9177 - accuracy: 0.7067 - val_loss: 0.9255 - val_accuracy: 0.7200\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9102 - accuracy: 0.7829 - val_loss: 0.9174 - val_accuracy: 0.6400\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9027 - accuracy: 0.7076 - val_loss: 0.9092 - val_accuracy: 0.6711\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8931 - accuracy: 0.7143 - val_loss: 0.9016 - val_accuracy: 0.7689\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8857 - accuracy: 0.7343 - val_loss: 0.8965 - val_accuracy: 0.6511\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8764 - accuracy: 0.7429 - val_loss: 0.8873 - val_accuracy: 0.6667\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8684 - accuracy: 0.7352 - val_loss: 0.8774 - val_accuracy: 0.7222\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8598 - accuracy: 0.7343 - val_loss: 0.8878 - val_accuracy: 0.5978\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8537 - accuracy: 0.7381 - val_loss: 0.8630 - val_accuracy: 0.6911\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8448 - accuracy: 0.7267 - val_loss: 0.8592 - val_accuracy: 0.7467\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8378 - accuracy: 0.7038 - val_loss: 0.8512 - val_accuracy: 0.7467\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8312 - accuracy: 0.7495 - val_loss: 0.8445 - val_accuracy: 0.7200\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8250 - accuracy: 0.7438 - val_loss: 0.8398 - val_accuracy: 0.7222\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8174 - accuracy: 0.7533 - val_loss: 0.8475 - val_accuracy: 0.6778\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8168 - accuracy: 0.7467 - val_loss: 0.8288 - val_accuracy: 0.7267\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8057 - accuracy: 0.7314 - val_loss: 0.8259 - val_accuracy: 0.7333\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8023 - accuracy: 0.7514 - val_loss: 0.8207 - val_accuracy: 0.7333\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7969 - accuracy: 0.7495 - val_loss: 0.8163 - val_accuracy: 0.7244\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7947 - accuracy: 0.7486 - val_loss: 0.8146 - val_accuracy: 0.6956\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7893 - accuracy: 0.7476 - val_loss: 0.8058 - val_accuracy: 0.7289\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7836 - accuracy: 0.7314 - val_loss: 0.8036 - val_accuracy: 0.7400\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7791 - accuracy: 0.7457 - val_loss: 0.7991 - val_accuracy: 0.7444\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7782 - accuracy: 0.7305 - val_loss: 0.7985 - val_accuracy: 0.7622\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7711 - accuracy: 0.7257 - val_loss: 0.7928 - val_accuracy: 0.6867\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7651 - accuracy: 0.7371 - val_loss: 0.7853 - val_accuracy: 0.7089\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7592 - accuracy: 0.7752 - val_loss: 0.7820 - val_accuracy: 0.7067\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7573 - accuracy: 0.7895 - val_loss: 0.7893 - val_accuracy: 0.8244\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7552 - accuracy: 0.7781 - val_loss: 0.7779 - val_accuracy: 0.7822\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7528 - accuracy: 0.7743 - val_loss: 0.7732 - val_accuracy: 0.7533\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7487 - accuracy: 0.8000 - val_loss: 0.7915 - val_accuracy: 0.6689\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7496 - accuracy: 0.7819 - val_loss: 0.7679 - val_accuracy: 0.7867\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7416 - accuracy: 0.8095 - val_loss: 0.7674 - val_accuracy: 0.7711\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7404 - accuracy: 0.8124 - val_loss: 0.7636 - val_accuracy: 0.6956\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7384 - accuracy: 0.8019 - val_loss: 0.7608 - val_accuracy: 0.8244\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7356 - accuracy: 0.8152 - val_loss: 0.7558 - val_accuracy: 0.8244\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7354 - accuracy: 0.8048 - val_loss: 0.7578 - val_accuracy: 0.8267\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7296 - accuracy: 0.8038 - val_loss: 0.7582 - val_accuracy: 0.7711\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7282 - accuracy: 0.8124 - val_loss: 0.7578 - val_accuracy: 0.8267\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7272 - accuracy: 0.8143 - val_loss: 0.7466 - val_accuracy: 0.8311\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7233 - accuracy: 0.8143 - val_loss: 0.7452 - val_accuracy: 0.8333\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7206 - accuracy: 0.8381 - val_loss: 0.7455 - val_accuracy: 0.6822\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7183 - accuracy: 0.8095 - val_loss: 0.7448 - val_accuracy: 0.7444\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7167 - accuracy: 0.8238 - val_loss: 0.7443 - val_accuracy: 0.8356\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7136 - accuracy: 0.8095 - val_loss: 0.7440 - val_accuracy: 0.7911\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7104 - accuracy: 0.8305 - val_loss: 0.7377 - val_accuracy: 0.8244\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7078 - accuracy: 0.8305 - val_loss: 0.7319 - val_accuracy: 0.8000\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7062 - accuracy: 0.8143 - val_loss: 0.7396 - val_accuracy: 0.7356\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7061 - accuracy: 0.8010 - val_loss: 0.7282 - val_accuracy: 0.7956\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7052 - accuracy: 0.8210 - val_loss: 0.7255 - val_accuracy: 0.8356\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7002 - accuracy: 0.8152 - val_loss: 0.7268 - val_accuracy: 0.7867\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6977 - accuracy: 0.8371 - val_loss: 0.7199 - val_accuracy: 0.8422\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6960 - accuracy: 0.8343 - val_loss: 0.7205 - val_accuracy: 0.8133\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6878 - accuracy: 0.8248 - val_loss: 0.7350 - val_accuracy: 0.6911\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[148   0   6]\n",
            " [ 77  56  12]\n",
            " [ 28  16 107]]\n",
            "\n",
            "P-Score: 0.740, R-Score: 0.685, F-Score: 0.673\n",
            "[0.6911111111111111, 0.7395860049773093, 0.6852850430379546, 0.6729213594571238, 0.8031546156546157, 0.6668739400791407, 0.8242043013134288, 0.764744285682395]\n",
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_143 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_144 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_145 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.1318 - accuracy: 0.2581 - val_loss: 1.1219 - val_accuracy: 0.3000\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1135 - accuracy: 0.3371 - val_loss: 1.1114 - val_accuracy: 0.3222\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1071 - accuracy: 0.3381 - val_loss: 1.1069 - val_accuracy: 0.3222\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.1039 - accuracy: 0.3381 - val_loss: 1.1037 - val_accuracy: 0.3222\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1017 - accuracy: 0.3381 - val_loss: 1.1015 - val_accuracy: 0.3222\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0999 - accuracy: 0.3381 - val_loss: 1.0997 - val_accuracy: 0.3222\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0981 - accuracy: 0.3381 - val_loss: 1.0981 - val_accuracy: 0.3222\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0963 - accuracy: 0.3419 - val_loss: 1.0964 - val_accuracy: 0.3222\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0947 - accuracy: 0.3419 - val_loss: 1.0947 - val_accuracy: 0.3222\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0928 - accuracy: 0.3419 - val_loss: 1.0931 - val_accuracy: 0.3356\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0913 - accuracy: 0.3600 - val_loss: 1.0916 - val_accuracy: 0.3333\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0895 - accuracy: 0.3552 - val_loss: 1.0900 - val_accuracy: 0.3467\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0878 - accuracy: 0.3571 - val_loss: 1.0884 - val_accuracy: 0.3711\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0861 - accuracy: 0.4000 - val_loss: 1.0869 - val_accuracy: 0.3711\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0843 - accuracy: 0.4152 - val_loss: 1.0852 - val_accuracy: 0.3689\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0825 - accuracy: 0.4019 - val_loss: 1.0834 - val_accuracy: 0.3822\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0805 - accuracy: 0.4324 - val_loss: 1.0816 - val_accuracy: 0.3911\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0785 - accuracy: 0.4476 - val_loss: 1.0797 - val_accuracy: 0.3978\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0761 - accuracy: 0.4390 - val_loss: 1.0776 - val_accuracy: 0.4244\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0743 - accuracy: 0.4648 - val_loss: 1.0754 - val_accuracy: 0.4267\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0711 - accuracy: 0.4010 - val_loss: 1.0735 - val_accuracy: 0.5067\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0689 - accuracy: 0.5381 - val_loss: 1.0710 - val_accuracy: 0.4422\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0664 - accuracy: 0.4743 - val_loss: 1.0684 - val_accuracy: 0.4711\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0637 - accuracy: 0.5124 - val_loss: 1.0658 - val_accuracy: 0.4711\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0610 - accuracy: 0.5171 - val_loss: 1.0632 - val_accuracy: 0.4756\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0577 - accuracy: 0.5219 - val_loss: 1.0602 - val_accuracy: 0.5044\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0541 - accuracy: 0.5505 - val_loss: 1.0579 - val_accuracy: 0.4400\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0515 - accuracy: 0.4971 - val_loss: 1.0541 - val_accuracy: 0.5067\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0476 - accuracy: 0.5352 - val_loss: 1.0505 - val_accuracy: 0.5244\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0440 - accuracy: 0.5410 - val_loss: 1.0470 - val_accuracy: 0.5289\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0403 - accuracy: 0.5543 - val_loss: 1.0433 - val_accuracy: 0.5333\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0366 - accuracy: 0.5571 - val_loss: 1.0395 - val_accuracy: 0.5422\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0321 - accuracy: 0.5581 - val_loss: 1.0356 - val_accuracy: 0.5444\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0275 - accuracy: 0.5552 - val_loss: 1.0321 - val_accuracy: 0.5333\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0234 - accuracy: 0.5667 - val_loss: 1.0272 - val_accuracy: 0.5356\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0179 - accuracy: 0.5667 - val_loss: 1.0226 - val_accuracy: 0.5378\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0130 - accuracy: 0.5705 - val_loss: 1.0181 - val_accuracy: 0.5311\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0080 - accuracy: 0.5714 - val_loss: 1.0129 - val_accuracy: 0.5378\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0024 - accuracy: 0.5857 - val_loss: 1.0079 - val_accuracy: 0.5378\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9970 - accuracy: 0.5933 - val_loss: 1.0030 - val_accuracy: 0.5378\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9913 - accuracy: 0.5657 - val_loss: 0.9973 - val_accuracy: 0.5422\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9859 - accuracy: 0.5771 - val_loss: 0.9924 - val_accuracy: 0.5378\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9798 - accuracy: 0.5800 - val_loss: 0.9867 - val_accuracy: 0.5489\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9745 - accuracy: 0.5724 - val_loss: 0.9809 - val_accuracy: 0.5467\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9687 - accuracy: 0.5762 - val_loss: 0.9753 - val_accuracy: 0.5533\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9613 - accuracy: 0.5790 - val_loss: 0.9720 - val_accuracy: 0.5711\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9560 - accuracy: 0.5743 - val_loss: 0.9659 - val_accuracy: 0.5800\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9499 - accuracy: 0.5924 - val_loss: 0.9578 - val_accuracy: 0.5800\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9431 - accuracy: 0.6029 - val_loss: 0.9517 - val_accuracy: 0.5711\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9358 - accuracy: 0.6010 - val_loss: 0.9455 - val_accuracy: 0.5578\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9294 - accuracy: 0.5705 - val_loss: 0.9393 - val_accuracy: 0.5778\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9233 - accuracy: 0.6343 - val_loss: 0.9352 - val_accuracy: 0.5644\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9171 - accuracy: 0.6000 - val_loss: 0.9269 - val_accuracy: 0.5578\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9097 - accuracy: 0.6067 - val_loss: 0.9208 - val_accuracy: 0.5600\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9043 - accuracy: 0.5800 - val_loss: 0.9146 - val_accuracy: 0.5933\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8952 - accuracy: 0.6295 - val_loss: 0.9130 - val_accuracy: 0.5867\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8902 - accuracy: 0.6019 - val_loss: 0.9022 - val_accuracy: 0.6133\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8846 - accuracy: 0.6248 - val_loss: 0.8970 - val_accuracy: 0.5956\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8769 - accuracy: 0.6295 - val_loss: 0.8914 - val_accuracy: 0.6089\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8696 - accuracy: 0.6095 - val_loss: 0.8919 - val_accuracy: 0.6156\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8661 - accuracy: 0.6419 - val_loss: 0.8810 - val_accuracy: 0.6222\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8599 - accuracy: 0.6314 - val_loss: 0.8739 - val_accuracy: 0.6333\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8538 - accuracy: 0.6524 - val_loss: 0.8682 - val_accuracy: 0.6267\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8477 - accuracy: 0.6552 - val_loss: 0.8632 - val_accuracy: 0.6089\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8429 - accuracy: 0.6562 - val_loss: 0.8611 - val_accuracy: 0.6067\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8379 - accuracy: 0.6448 - val_loss: 0.8567 - val_accuracy: 0.6200\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8327 - accuracy: 0.6324 - val_loss: 0.8482 - val_accuracy: 0.6378\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8268 - accuracy: 0.6610 - val_loss: 0.8444 - val_accuracy: 0.6422\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8221 - accuracy: 0.6362 - val_loss: 0.8444 - val_accuracy: 0.6444\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8169 - accuracy: 0.6590 - val_loss: 0.8370 - val_accuracy: 0.6422\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8131 - accuracy: 0.6505 - val_loss: 0.8336 - val_accuracy: 0.6422\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8085 - accuracy: 0.6543 - val_loss: 0.8267 - val_accuracy: 0.6489\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8055 - accuracy: 0.6581 - val_loss: 0.8225 - val_accuracy: 0.6489\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8013 - accuracy: 0.6390 - val_loss: 0.8181 - val_accuracy: 0.6733\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7964 - accuracy: 0.6724 - val_loss: 0.8155 - val_accuracy: 0.6622\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7917 - accuracy: 0.6790 - val_loss: 0.8127 - val_accuracy: 0.6622\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.6762 - val_loss: 0.8165 - val_accuracy: 0.6511\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7866 - accuracy: 0.6657 - val_loss: 0.8055 - val_accuracy: 0.6644\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7813 - accuracy: 0.6695 - val_loss: 0.8028 - val_accuracy: 0.6644\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7800 - accuracy: 0.6752 - val_loss: 0.7996 - val_accuracy: 0.6756\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[ 72  65  17]\n",
            " [ 12 113  20]\n",
            " [ 15  17 119]]\n",
            "\n",
            "P-Score: 0.690, R-Score: 0.678, F-Score: 0.670\n",
            "[0.6755555555555556, 0.6898601398601398, 0.6783074275195764, 0.6697067141671722, 0.6881581256581256, 0.7552289429055964, 0.8321668254003411, 0.7585179646546877]\n",
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_146 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_147 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_148 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 9ms/step - loss: 1.0991 - accuracy: 0.3219 - val_loss: 1.0959 - val_accuracy: 0.2044\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0932 - accuracy: 0.2990 - val_loss: 1.0945 - val_accuracy: 0.3044\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0911 - accuracy: 0.2410 - val_loss: 1.0901 - val_accuracy: 0.2133\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0868 - accuracy: 0.2886 - val_loss: 1.0853 - val_accuracy: 0.2778\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0812 - accuracy: 0.2610 - val_loss: 1.0812 - val_accuracy: 0.3311\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0778 - accuracy: 0.2990 - val_loss: 1.0768 - val_accuracy: 0.3311\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0730 - accuracy: 0.3010 - val_loss: 1.0729 - val_accuracy: 0.3111\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0687 - accuracy: 0.3486 - val_loss: 1.0693 - val_accuracy: 0.3422\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0649 - accuracy: 0.3857 - val_loss: 1.0655 - val_accuracy: 0.3733\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0608 - accuracy: 0.4086 - val_loss: 1.0619 - val_accuracy: 0.4089\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0569 - accuracy: 0.4295 - val_loss: 1.0580 - val_accuracy: 0.4822\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0520 - accuracy: 0.5086 - val_loss: 1.0529 - val_accuracy: 0.4667\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0469 - accuracy: 0.4990 - val_loss: 1.0477 - val_accuracy: 0.5267\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0422 - accuracy: 0.5200 - val_loss: 1.0432 - val_accuracy: 0.5378\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0365 - accuracy: 0.5495 - val_loss: 1.0387 - val_accuracy: 0.5067\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0304 - accuracy: 0.5543 - val_loss: 1.0334 - val_accuracy: 0.5489\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0252 - accuracy: 0.5667 - val_loss: 1.0272 - val_accuracy: 0.5444\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0195 - accuracy: 0.5676 - val_loss: 1.0215 - val_accuracy: 0.5600\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0138 - accuracy: 0.5724 - val_loss: 1.0159 - val_accuracy: 0.5511\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0063 - accuracy: 0.5629 - val_loss: 1.0097 - val_accuracy: 0.5711\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0002 - accuracy: 0.5638 - val_loss: 1.0047 - val_accuracy: 0.5511\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9933 - accuracy: 0.5762 - val_loss: 0.9981 - val_accuracy: 0.5667\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9872 - accuracy: 0.5752 - val_loss: 0.9905 - val_accuracy: 0.5689\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9791 - accuracy: 0.5695 - val_loss: 0.9846 - val_accuracy: 0.5400\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9719 - accuracy: 0.5714 - val_loss: 0.9769 - val_accuracy: 0.5600\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9645 - accuracy: 0.5895 - val_loss: 0.9701 - val_accuracy: 0.5733\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9567 - accuracy: 0.5838 - val_loss: 0.9628 - val_accuracy: 0.5733\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9488 - accuracy: 0.5867 - val_loss: 0.9559 - val_accuracy: 0.5467\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9422 - accuracy: 0.5676 - val_loss: 0.9495 - val_accuracy: 0.5822\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9356 - accuracy: 0.5886 - val_loss: 0.9439 - val_accuracy: 0.5800\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9259 - accuracy: 0.5905 - val_loss: 0.9333 - val_accuracy: 0.5578\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9183 - accuracy: 0.5848 - val_loss: 0.9279 - val_accuracy: 0.5622\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9107 - accuracy: 0.5790 - val_loss: 0.9184 - val_accuracy: 0.5733\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9024 - accuracy: 0.5829 - val_loss: 0.9114 - val_accuracy: 0.5533\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8942 - accuracy: 0.5905 - val_loss: 0.9039 - val_accuracy: 0.5644\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8879 - accuracy: 0.5867 - val_loss: 0.8974 - val_accuracy: 0.5600\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8798 - accuracy: 0.5829 - val_loss: 0.8902 - val_accuracy: 0.5556\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8735 - accuracy: 0.5800 - val_loss: 0.8838 - val_accuracy: 0.5778\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8676 - accuracy: 0.5800 - val_loss: 0.8782 - val_accuracy: 0.5778\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8604 - accuracy: 0.5981 - val_loss: 0.8716 - val_accuracy: 0.5756\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8519 - accuracy: 0.5943 - val_loss: 0.8657 - val_accuracy: 0.5844\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8463 - accuracy: 0.5990 - val_loss: 0.8630 - val_accuracy: 0.5844\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8399 - accuracy: 0.5981 - val_loss: 0.8563 - val_accuracy: 0.5911\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8348 - accuracy: 0.6038 - val_loss: 0.8484 - val_accuracy: 0.5800\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8314 - accuracy: 0.6000 - val_loss: 0.8433 - val_accuracy: 0.5733\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8233 - accuracy: 0.6076 - val_loss: 0.8397 - val_accuracy: 0.5822\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8181 - accuracy: 0.5952 - val_loss: 0.8351 - val_accuracy: 0.5844\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8130 - accuracy: 0.6181 - val_loss: 0.8302 - val_accuracy: 0.5867\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8079 - accuracy: 0.6105 - val_loss: 0.8440 - val_accuracy: 0.5889\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8053 - accuracy: 0.6124 - val_loss: 0.8219 - val_accuracy: 0.6222\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8034 - accuracy: 0.6171 - val_loss: 0.8175 - val_accuracy: 0.5933\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7977 - accuracy: 0.6219 - val_loss: 0.8137 - val_accuracy: 0.5956\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7922 - accuracy: 0.6171 - val_loss: 0.8125 - val_accuracy: 0.5978\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7890 - accuracy: 0.6152 - val_loss: 0.8101 - val_accuracy: 0.5978\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7855 - accuracy: 0.6295 - val_loss: 0.8040 - val_accuracy: 0.6044\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7816 - accuracy: 0.6410 - val_loss: 0.8172 - val_accuracy: 0.6000\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7791 - accuracy: 0.6371 - val_loss: 0.7999 - val_accuracy: 0.6356\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7775 - accuracy: 0.6419 - val_loss: 0.7983 - val_accuracy: 0.6289\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7732 - accuracy: 0.6410 - val_loss: 0.7946 - val_accuracy: 0.6289\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7701 - accuracy: 0.6505 - val_loss: 0.7928 - val_accuracy: 0.6289\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7672 - accuracy: 0.6590 - val_loss: 0.7919 - val_accuracy: 0.6111\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7677 - accuracy: 0.6476 - val_loss: 0.7869 - val_accuracy: 0.6289\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7639 - accuracy: 0.6438 - val_loss: 0.7863 - val_accuracy: 0.6511\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7618 - accuracy: 0.6495 - val_loss: 0.7868 - val_accuracy: 0.6556\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7585 - accuracy: 0.6610 - val_loss: 0.7807 - val_accuracy: 0.6467\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7577 - accuracy: 0.6638 - val_loss: 0.7811 - val_accuracy: 0.6533\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7553 - accuracy: 0.6743 - val_loss: 0.7775 - val_accuracy: 0.6489\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.6743 - val_loss: 0.7813 - val_accuracy: 0.6533\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7528 - accuracy: 0.6619 - val_loss: 0.7754 - val_accuracy: 0.6711\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7505 - accuracy: 0.6819 - val_loss: 0.7735 - val_accuracy: 0.6556\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7487 - accuracy: 0.6905 - val_loss: 0.7716 - val_accuracy: 0.6644\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7469 - accuracy: 0.6810 - val_loss: 0.7713 - val_accuracy: 0.6800\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7453 - accuracy: 0.7019 - val_loss: 0.7713 - val_accuracy: 0.6867\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7461 - accuracy: 0.6886 - val_loss: 0.7718 - val_accuracy: 0.6889\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7444 - accuracy: 0.6933 - val_loss: 0.7662 - val_accuracy: 0.6756\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7428 - accuracy: 0.7076 - val_loss: 0.7689 - val_accuracy: 0.6956\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7400 - accuracy: 0.6952 - val_loss: 0.7642 - val_accuracy: 0.6844\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7390 - accuracy: 0.7048 - val_loss: 0.7669 - val_accuracy: 0.7000\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7374 - accuracy: 0.7152 - val_loss: 0.7711 - val_accuracy: 0.6956\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7379 - accuracy: 0.7105 - val_loss: 0.7606 - val_accuracy: 0.6889\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[ 94  45  15]\n",
            " [ 22  98  25]\n",
            " [  2  31 118]]\n",
            "\n",
            "P-Score: 0.702, R-Score: 0.689, F-Score: 0.690\n",
            "[0.6888888888888889, 0.7022213344446993, 0.6892362109991707, 0.6897835261972011, 0.7646542646542647, 0.7133408705483324, 0.8238388447141687, 0.7672779933055885]\n",
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_149 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_150 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_151 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.1078 - accuracy: 0.2886 - val_loss: 1.0986 - val_accuracy: 0.3067\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.1011 - accuracy: 0.3076 - val_loss: 1.0955 - val_accuracy: 0.3489\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0973 - accuracy: 0.3219 - val_loss: 1.0931 - val_accuracy: 0.4089\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0948 - accuracy: 0.3571 - val_loss: 1.0922 - val_accuracy: 0.3556\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0931 - accuracy: 0.3914 - val_loss: 1.0905 - val_accuracy: 0.5133\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0905 - accuracy: 0.5143 - val_loss: 1.0877 - val_accuracy: 0.7178\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0874 - accuracy: 0.4581 - val_loss: 1.0864 - val_accuracy: 0.5778\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0858 - accuracy: 0.4952 - val_loss: 1.0868 - val_accuracy: 0.3222\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0849 - accuracy: 0.4143 - val_loss: 1.0847 - val_accuracy: 0.3222\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0833 - accuracy: 0.5162 - val_loss: 1.0829 - val_accuracy: 0.3956\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0819 - accuracy: 0.4638 - val_loss: 1.0810 - val_accuracy: 0.6600\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0805 - accuracy: 0.4667 - val_loss: 1.0795 - val_accuracy: 0.3533\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0790 - accuracy: 0.5162 - val_loss: 1.0781 - val_accuracy: 0.4622\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0777 - accuracy: 0.5457 - val_loss: 1.0770 - val_accuracy: 0.6556\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0759 - accuracy: 0.4924 - val_loss: 1.0768 - val_accuracy: 0.3378\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0741 - accuracy: 0.4990 - val_loss: 1.0753 - val_accuracy: 0.3578\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0727 - accuracy: 0.4590 - val_loss: 1.0741 - val_accuracy: 0.3711\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0711 - accuracy: 0.4895 - val_loss: 1.0709 - val_accuracy: 0.6822\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0688 - accuracy: 0.5600 - val_loss: 1.0707 - val_accuracy: 0.4178\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0672 - accuracy: 0.5362 - val_loss: 1.0681 - val_accuracy: 0.6178\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0662 - accuracy: 0.5457 - val_loss: 1.0668 - val_accuracy: 0.5089\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0640 - accuracy: 0.5771 - val_loss: 1.0640 - val_accuracy: 0.5378\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0617 - accuracy: 0.6076 - val_loss: 1.0621 - val_accuracy: 0.6000\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0593 - accuracy: 0.5552 - val_loss: 1.0619 - val_accuracy: 0.5378\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0580 - accuracy: 0.6448 - val_loss: 1.0586 - val_accuracy: 0.6867\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0551 - accuracy: 0.5714 - val_loss: 1.0568 - val_accuracy: 0.6667\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0527 - accuracy: 0.6686 - val_loss: 1.0545 - val_accuracy: 0.6711\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0500 - accuracy: 0.6952 - val_loss: 1.0509 - val_accuracy: 0.7267\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 1.0463 - accuracy: 0.6971 - val_loss: 1.0476 - val_accuracy: 0.6689\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0434 - accuracy: 0.6457 - val_loss: 1.0453 - val_accuracy: 0.7222\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0401 - accuracy: 0.6876 - val_loss: 1.0431 - val_accuracy: 0.6822\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0374 - accuracy: 0.6676 - val_loss: 1.0402 - val_accuracy: 0.6956\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0339 - accuracy: 0.6714 - val_loss: 1.0358 - val_accuracy: 0.7044\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0301 - accuracy: 0.6952 - val_loss: 1.0324 - val_accuracy: 0.7022\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0266 - accuracy: 0.6724 - val_loss: 1.0284 - val_accuracy: 0.6533\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0219 - accuracy: 0.6962 - val_loss: 1.0245 - val_accuracy: 0.6644\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0174 - accuracy: 0.6762 - val_loss: 1.0203 - val_accuracy: 0.6756\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0112 - accuracy: 0.7000 - val_loss: 1.0149 - val_accuracy: 0.6622\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0056 - accuracy: 0.6895 - val_loss: 1.0100 - val_accuracy: 0.6289\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9989 - accuracy: 0.6829 - val_loss: 1.0032 - val_accuracy: 0.6356\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9915 - accuracy: 0.6600 - val_loss: 0.9947 - val_accuracy: 0.6822\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9822 - accuracy: 0.6762 - val_loss: 0.9892 - val_accuracy: 0.6156\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9759 - accuracy: 0.6686 - val_loss: 0.9808 - val_accuracy: 0.6800\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9688 - accuracy: 0.6886 - val_loss: 0.9731 - val_accuracy: 0.6778\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9612 - accuracy: 0.6724 - val_loss: 0.9661 - val_accuracy: 0.6844\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9532 - accuracy: 0.6943 - val_loss: 0.9600 - val_accuracy: 0.6711\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9466 - accuracy: 0.6762 - val_loss: 0.9536 - val_accuracy: 0.6800\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9393 - accuracy: 0.6905 - val_loss: 0.9471 - val_accuracy: 0.6089\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9326 - accuracy: 0.6629 - val_loss: 0.9403 - val_accuracy: 0.6733\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9253 - accuracy: 0.6562 - val_loss: 0.9389 - val_accuracy: 0.6356\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9174 - accuracy: 0.6733 - val_loss: 0.9264 - val_accuracy: 0.6244\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.9110 - accuracy: 0.6638 - val_loss: 0.9247 - val_accuracy: 0.5867\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9046 - accuracy: 0.6638 - val_loss: 0.9133 - val_accuracy: 0.6400\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8968 - accuracy: 0.6600 - val_loss: 0.9073 - val_accuracy: 0.6533\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8913 - accuracy: 0.6429 - val_loss: 0.9027 - val_accuracy: 0.6556\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8838 - accuracy: 0.6657 - val_loss: 0.8934 - val_accuracy: 0.6289\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8763 - accuracy: 0.6524 - val_loss: 0.8899 - val_accuracy: 0.6533\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8707 - accuracy: 0.6562 - val_loss: 0.8831 - val_accuracy: 0.6600\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8639 - accuracy: 0.6438 - val_loss: 0.8757 - val_accuracy: 0.6578\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8569 - accuracy: 0.6619 - val_loss: 0.8688 - val_accuracy: 0.6267\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.8509 - accuracy: 0.6533 - val_loss: 0.8628 - val_accuracy: 0.6356\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8436 - accuracy: 0.6524 - val_loss: 0.8745 - val_accuracy: 0.5867\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8398 - accuracy: 0.6514 - val_loss: 0.8513 - val_accuracy: 0.6289\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8306 - accuracy: 0.6467 - val_loss: 0.8465 - val_accuracy: 0.6444\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8262 - accuracy: 0.6629 - val_loss: 0.8470 - val_accuracy: 0.6711\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8200 - accuracy: 0.6657 - val_loss: 0.8384 - val_accuracy: 0.6400\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8174 - accuracy: 0.6752 - val_loss: 0.8338 - val_accuracy: 0.6156\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8104 - accuracy: 0.6638 - val_loss: 0.8370 - val_accuracy: 0.6022\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8081 - accuracy: 0.6571 - val_loss: 0.8229 - val_accuracy: 0.6756\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7999 - accuracy: 0.6810 - val_loss: 0.8226 - val_accuracy: 0.6089\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7962 - accuracy: 0.6743 - val_loss: 0.8147 - val_accuracy: 0.6067\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7899 - accuracy: 0.6562 - val_loss: 0.8110 - val_accuracy: 0.6800\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7856 - accuracy: 0.6962 - val_loss: 0.8040 - val_accuracy: 0.6356\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7803 - accuracy: 0.6695 - val_loss: 0.8014 - val_accuracy: 0.6844\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7784 - accuracy: 0.6848 - val_loss: 0.7982 - val_accuracy: 0.7044\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7745 - accuracy: 0.7000 - val_loss: 0.7934 - val_accuracy: 0.6933\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7697 - accuracy: 0.6952 - val_loss: 0.7943 - val_accuracy: 0.6867\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7654 - accuracy: 0.6971 - val_loss: 0.7864 - val_accuracy: 0.6933\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7591 - accuracy: 0.6971 - val_loss: 0.7881 - val_accuracy: 0.6978\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7581 - accuracy: 0.7276 - val_loss: 0.7791 - val_accuracy: 0.7000\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[124  15  15]\n",
            " [ 47  72  26]\n",
            " [ 11  21 119]]\n",
            "\n",
            "P-Score: 0.697, R-Score: 0.697, F-Score: 0.691\n",
            "[0.7, 0.697245115995116, 0.6966086665104706, 0.6908461701555509, 0.8046244296244296, 0.6892594686263426, 0.8254778621896388, 0.7731205868134703]\n",
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_152 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_153 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_154 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 10ms/step - loss: 1.0911 - accuracy: 0.3886 - val_loss: 1.0795 - val_accuracy: 0.3644\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0734 - accuracy: 0.4524 - val_loss: 1.0717 - val_accuracy: 0.5311\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0710 - accuracy: 0.5295 - val_loss: 1.0694 - val_accuracy: 0.4800\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0654 - accuracy: 0.5248 - val_loss: 1.0646 - val_accuracy: 0.6667\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0618 - accuracy: 0.5771 - val_loss: 1.0607 - val_accuracy: 0.6556\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0571 - accuracy: 0.5981 - val_loss: 1.0564 - val_accuracy: 0.6044\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0533 - accuracy: 0.5952 - val_loss: 1.0524 - val_accuracy: 0.5867\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0493 - accuracy: 0.6038 - val_loss: 1.0482 - val_accuracy: 0.6044\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0432 - accuracy: 0.6505 - val_loss: 1.0511 - val_accuracy: 0.4911\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0398 - accuracy: 0.5943 - val_loss: 1.0399 - val_accuracy: 0.5778\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0360 - accuracy: 0.6095 - val_loss: 1.0359 - val_accuracy: 0.5600\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0285 - accuracy: 0.6000 - val_loss: 1.0297 - val_accuracy: 0.6156\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0248 - accuracy: 0.6210 - val_loss: 1.0243 - val_accuracy: 0.6667\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0192 - accuracy: 0.6257 - val_loss: 1.0202 - val_accuracy: 0.7489\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0148 - accuracy: 0.6438 - val_loss: 1.0140 - val_accuracy: 0.6311\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0083 - accuracy: 0.6552 - val_loss: 1.0133 - val_accuracy: 0.5733\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0017 - accuracy: 0.6333 - val_loss: 1.0081 - val_accuracy: 0.5867\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9972 - accuracy: 0.6543 - val_loss: 0.9982 - val_accuracy: 0.6089\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9899 - accuracy: 0.6448 - val_loss: 0.9941 - val_accuracy: 0.6089\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9833 - accuracy: 0.6714 - val_loss: 0.9848 - val_accuracy: 0.6400\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9770 - accuracy: 0.6571 - val_loss: 0.9795 - val_accuracy: 0.6378\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9708 - accuracy: 0.6610 - val_loss: 0.9726 - val_accuracy: 0.7711\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9640 - accuracy: 0.6819 - val_loss: 0.9653 - val_accuracy: 0.6333\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9555 - accuracy: 0.6581 - val_loss: 0.9579 - val_accuracy: 0.7311\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9482 - accuracy: 0.6762 - val_loss: 0.9518 - val_accuracy: 0.7733\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9412 - accuracy: 0.7133 - val_loss: 0.9528 - val_accuracy: 0.5733\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9328 - accuracy: 0.6705 - val_loss: 0.9370 - val_accuracy: 0.7822\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9267 - accuracy: 0.6905 - val_loss: 0.9284 - val_accuracy: 0.7467\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9166 - accuracy: 0.7143 - val_loss: 0.9216 - val_accuracy: 0.6444\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9088 - accuracy: 0.6838 - val_loss: 0.9151 - val_accuracy: 0.6978\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8992 - accuracy: 0.7019 - val_loss: 0.9257 - val_accuracy: 0.5511\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8938 - accuracy: 0.6819 - val_loss: 0.9008 - val_accuracy: 0.6578\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8849 - accuracy: 0.6857 - val_loss: 0.8895 - val_accuracy: 0.7689\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8767 - accuracy: 0.7238 - val_loss: 0.8836 - val_accuracy: 0.6400\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8669 - accuracy: 0.7114 - val_loss: 0.8758 - val_accuracy: 0.7889\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8605 - accuracy: 0.7114 - val_loss: 0.8668 - val_accuracy: 0.7889\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8523 - accuracy: 0.7257 - val_loss: 0.8597 - val_accuracy: 0.6733\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8451 - accuracy: 0.7124 - val_loss: 0.8521 - val_accuracy: 0.8000\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8368 - accuracy: 0.7314 - val_loss: 0.8479 - val_accuracy: 0.7022\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8287 - accuracy: 0.7410 - val_loss: 0.8364 - val_accuracy: 0.7444\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8212 - accuracy: 0.7476 - val_loss: 0.8319 - val_accuracy: 0.8022\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8135 - accuracy: 0.7457 - val_loss: 0.8217 - val_accuracy: 0.8133\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8062 - accuracy: 0.7333 - val_loss: 0.8159 - val_accuracy: 0.8133\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7995 - accuracy: 0.7552 - val_loss: 0.8099 - val_accuracy: 0.7400\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7909 - accuracy: 0.7524 - val_loss: 0.8008 - val_accuracy: 0.8067\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7851 - accuracy: 0.7629 - val_loss: 0.7952 - val_accuracy: 0.7911\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7793 - accuracy: 0.7733 - val_loss: 0.7937 - val_accuracy: 0.6667\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7707 - accuracy: 0.7676 - val_loss: 0.7870 - val_accuracy: 0.8133\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7677 - accuracy: 0.7676 - val_loss: 0.7762 - val_accuracy: 0.8222\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7582 - accuracy: 0.7571 - val_loss: 0.7695 - val_accuracy: 0.8156\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7501 - accuracy: 0.7733 - val_loss: 0.7698 - val_accuracy: 0.8222\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7455 - accuracy: 0.8029 - val_loss: 0.7784 - val_accuracy: 0.6333\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7435 - accuracy: 0.7790 - val_loss: 0.7530 - val_accuracy: 0.7956\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7349 - accuracy: 0.7905 - val_loss: 0.7471 - val_accuracy: 0.8222\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7293 - accuracy: 0.7924 - val_loss: 0.7717 - val_accuracy: 0.6578\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7213 - accuracy: 0.7962 - val_loss: 0.7415 - val_accuracy: 0.7844\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7175 - accuracy: 0.7838 - val_loss: 0.7305 - val_accuracy: 0.8311\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7122 - accuracy: 0.7886 - val_loss: 0.7356 - val_accuracy: 0.8289\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7091 - accuracy: 0.8057 - val_loss: 0.7366 - val_accuracy: 0.6822\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7009 - accuracy: 0.8038 - val_loss: 0.7153 - val_accuracy: 0.7822\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6967 - accuracy: 0.8019 - val_loss: 0.7078 - val_accuracy: 0.8467\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6899 - accuracy: 0.8210 - val_loss: 0.7097 - val_accuracy: 0.8067\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6847 - accuracy: 0.7981 - val_loss: 0.7009 - val_accuracy: 0.8467\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6766 - accuracy: 0.8124 - val_loss: 0.6926 - val_accuracy: 0.8356\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6703 - accuracy: 0.8257 - val_loss: 0.6943 - val_accuracy: 0.8311\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6706 - accuracy: 0.8086 - val_loss: 0.6931 - val_accuracy: 0.7756\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6599 - accuracy: 0.8410 - val_loss: 0.6745 - val_accuracy: 0.8333\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6553 - accuracy: 0.8190 - val_loss: 0.6797 - val_accuracy: 0.7822\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6482 - accuracy: 0.8171 - val_loss: 0.6657 - val_accuracy: 0.8267\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.8238 - val_loss: 0.6627 - val_accuracy: 0.8200\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6363 - accuracy: 0.8295 - val_loss: 0.6688 - val_accuracy: 0.7911\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6392 - accuracy: 0.8257 - val_loss: 0.6752 - val_accuracy: 0.7844\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6268 - accuracy: 0.8429 - val_loss: 0.6458 - val_accuracy: 0.8378\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6212 - accuracy: 0.8429 - val_loss: 0.6482 - val_accuracy: 0.7844\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6134 - accuracy: 0.8343 - val_loss: 0.6362 - val_accuracy: 0.8311\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6139 - accuracy: 0.8343 - val_loss: 0.6333 - val_accuracy: 0.8378\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6074 - accuracy: 0.8343 - val_loss: 0.6642 - val_accuracy: 0.8244\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.6051 - accuracy: 0.8381 - val_loss: 0.6163 - val_accuracy: 0.8356\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5949 - accuracy: 0.8486 - val_loss: 0.6139 - val_accuracy: 0.8511\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.5907 - accuracy: 0.8419 - val_loss: 0.6076 - val_accuracy: 0.8400\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[133   6  15]\n",
            " [  0 116  29]\n",
            " [  5  17 129]]\n",
            "\n",
            "P-Score: 0.848, R-Score: 0.839, F-Score: 0.841\n",
            "[0.84, 0.8479884099757138, 0.8393136664659844, 0.8413855362855299, 0.9233722358722359, 0.8622950819672133, 0.853573722563069, 0.879747013467506]\n",
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_155 (Dense)           (None, 7)                 56        \n",
            "                                                                 \n",
            " dense_156 (Dense)           (None, 5)                 40        \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 3)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 114\n",
            "Trainable params: 114\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/80\n",
            "33/33 [==============================] - 1s 11ms/step - loss: 1.1985 - accuracy: 0.3381 - val_loss: 1.1004 - val_accuracy: 0.4733\n",
            "Epoch 2/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0988 - accuracy: 0.5352 - val_loss: 1.0918 - val_accuracy: 0.5511\n",
            "Epoch 3/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0913 - accuracy: 0.4343 - val_loss: 1.0898 - val_accuracy: 0.4156\n",
            "Epoch 4/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0891 - accuracy: 0.4219 - val_loss: 1.0885 - val_accuracy: 0.3822\n",
            "Epoch 5/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0871 - accuracy: 0.3562 - val_loss: 1.0871 - val_accuracy: 0.3822\n",
            "Epoch 6/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0855 - accuracy: 0.3829 - val_loss: 1.0856 - val_accuracy: 0.3867\n",
            "Epoch 7/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0837 - accuracy: 0.3838 - val_loss: 1.0841 - val_accuracy: 0.3889\n",
            "Epoch 8/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0820 - accuracy: 0.3771 - val_loss: 1.0823 - val_accuracy: 0.4111\n",
            "Epoch 9/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0804 - accuracy: 0.4086 - val_loss: 1.0811 - val_accuracy: 0.4156\n",
            "Epoch 10/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0790 - accuracy: 0.3943 - val_loss: 1.0796 - val_accuracy: 0.4311\n",
            "Epoch 11/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0770 - accuracy: 0.3762 - val_loss: 1.0777 - val_accuracy: 0.3711\n",
            "Epoch 12/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0763 - accuracy: 0.3810 - val_loss: 1.0763 - val_accuracy: 0.3911\n",
            "Epoch 13/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0743 - accuracy: 0.4429 - val_loss: 1.0752 - val_accuracy: 0.4556\n",
            "Epoch 14/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0728 - accuracy: 0.4133 - val_loss: 1.0738 - val_accuracy: 0.4489\n",
            "Epoch 15/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0704 - accuracy: 0.4410 - val_loss: 1.0718 - val_accuracy: 0.4178\n",
            "Epoch 16/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0688 - accuracy: 0.4629 - val_loss: 1.0712 - val_accuracy: 0.4089\n",
            "Epoch 17/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0676 - accuracy: 0.4533 - val_loss: 1.0700 - val_accuracy: 0.3800\n",
            "Epoch 18/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0654 - accuracy: 0.4190 - val_loss: 1.0670 - val_accuracy: 0.4578\n",
            "Epoch 19/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0635 - accuracy: 0.5019 - val_loss: 1.0659 - val_accuracy: 0.4822\n",
            "Epoch 20/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0613 - accuracy: 0.5171 - val_loss: 1.0647 - val_accuracy: 0.4467\n",
            "Epoch 21/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0596 - accuracy: 0.5419 - val_loss: 1.0619 - val_accuracy: 0.5489\n",
            "Epoch 22/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0576 - accuracy: 0.5333 - val_loss: 1.0605 - val_accuracy: 0.4867\n",
            "Epoch 23/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0553 - accuracy: 0.5400 - val_loss: 1.0577 - val_accuracy: 0.5911\n",
            "Epoch 24/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0529 - accuracy: 0.5971 - val_loss: 1.0560 - val_accuracy: 0.5556\n",
            "Epoch 25/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0510 - accuracy: 0.5448 - val_loss: 1.0531 - val_accuracy: 0.5578\n",
            "Epoch 26/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0479 - accuracy: 0.5467 - val_loss: 1.0525 - val_accuracy: 0.4711\n",
            "Epoch 27/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0457 - accuracy: 0.5876 - val_loss: 1.0493 - val_accuracy: 0.5378\n",
            "Epoch 28/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0422 - accuracy: 0.5648 - val_loss: 1.0458 - val_accuracy: 0.6667\n",
            "Epoch 29/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0400 - accuracy: 0.6448 - val_loss: 1.0429 - val_accuracy: 0.6667\n",
            "Epoch 30/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0361 - accuracy: 0.6486 - val_loss: 1.0401 - val_accuracy: 0.6556\n",
            "Epoch 31/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0325 - accuracy: 0.6276 - val_loss: 1.0363 - val_accuracy: 0.6556\n",
            "Epoch 32/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0290 - accuracy: 0.6448 - val_loss: 1.0337 - val_accuracy: 0.6222\n",
            "Epoch 33/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 1.0252 - accuracy: 0.6457 - val_loss: 1.0292 - val_accuracy: 0.6333\n",
            "Epoch 34/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0209 - accuracy: 0.6724 - val_loss: 1.0249 - val_accuracy: 0.6778\n",
            "Epoch 35/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0164 - accuracy: 0.6600 - val_loss: 1.0206 - val_accuracy: 0.6844\n",
            "Epoch 36/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 1.0101 - accuracy: 0.6219 - val_loss: 1.0142 - val_accuracy: 0.6600\n",
            "Epoch 37/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0036 - accuracy: 0.6867 - val_loss: 1.0070 - val_accuracy: 0.6956\n",
            "Epoch 38/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9935 - accuracy: 0.6552 - val_loss: 0.9972 - val_accuracy: 0.6778\n",
            "Epoch 39/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9830 - accuracy: 0.6733 - val_loss: 0.9875 - val_accuracy: 0.6844\n",
            "Epoch 40/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9733 - accuracy: 0.6733 - val_loss: 0.9796 - val_accuracy: 0.6800\n",
            "Epoch 41/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9656 - accuracy: 0.6505 - val_loss: 0.9723 - val_accuracy: 0.6778\n",
            "Epoch 42/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9580 - accuracy: 0.6848 - val_loss: 0.9647 - val_accuracy: 0.6578\n",
            "Epoch 43/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9498 - accuracy: 0.6790 - val_loss: 0.9575 - val_accuracy: 0.6578\n",
            "Epoch 44/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9436 - accuracy: 0.6790 - val_loss: 0.9507 - val_accuracy: 0.6733\n",
            "Epoch 45/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9359 - accuracy: 0.6790 - val_loss: 0.9435 - val_accuracy: 0.6511\n",
            "Epoch 46/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.9291 - accuracy: 0.6705 - val_loss: 0.9369 - val_accuracy: 0.6778\n",
            "Epoch 47/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9214 - accuracy: 0.6733 - val_loss: 0.9314 - val_accuracy: 0.6933\n",
            "Epoch 48/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9141 - accuracy: 0.7181 - val_loss: 0.9240 - val_accuracy: 0.7044\n",
            "Epoch 49/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.9075 - accuracy: 0.6924 - val_loss: 0.9178 - val_accuracy: 0.6933\n",
            "Epoch 50/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8994 - accuracy: 0.7010 - val_loss: 0.9102 - val_accuracy: 0.6067\n",
            "Epoch 51/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8945 - accuracy: 0.6495 - val_loss: 0.9050 - val_accuracy: 0.7222\n",
            "Epoch 52/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8859 - accuracy: 0.7305 - val_loss: 0.8987 - val_accuracy: 0.6800\n",
            "Epoch 53/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8793 - accuracy: 0.7181 - val_loss: 0.8919 - val_accuracy: 0.6778\n",
            "Epoch 54/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8736 - accuracy: 0.7171 - val_loss: 0.8865 - val_accuracy: 0.7333\n",
            "Epoch 55/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8658 - accuracy: 0.7476 - val_loss: 0.8805 - val_accuracy: 0.6889\n",
            "Epoch 56/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8613 - accuracy: 0.7257 - val_loss: 0.8756 - val_accuracy: 0.7378\n",
            "Epoch 57/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8530 - accuracy: 0.7400 - val_loss: 0.8691 - val_accuracy: 0.7356\n",
            "Epoch 58/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8489 - accuracy: 0.7152 - val_loss: 0.8664 - val_accuracy: 0.7333\n",
            "Epoch 59/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8428 - accuracy: 0.7324 - val_loss: 0.8592 - val_accuracy: 0.7533\n",
            "Epoch 60/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8365 - accuracy: 0.7571 - val_loss: 0.8601 - val_accuracy: 0.6733\n",
            "Epoch 61/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8326 - accuracy: 0.7486 - val_loss: 0.8506 - val_accuracy: 0.7311\n",
            "Epoch 62/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8262 - accuracy: 0.7371 - val_loss: 0.8503 - val_accuracy: 0.6489\n",
            "Epoch 63/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8214 - accuracy: 0.7248 - val_loss: 0.8412 - val_accuracy: 0.7756\n",
            "Epoch 64/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8190 - accuracy: 0.7467 - val_loss: 0.8364 - val_accuracy: 0.7867\n",
            "Epoch 65/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.8116 - accuracy: 0.7419 - val_loss: 0.8318 - val_accuracy: 0.7800\n",
            "Epoch 66/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8066 - accuracy: 0.8057 - val_loss: 0.8295 - val_accuracy: 0.7511\n",
            "Epoch 67/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.8040 - accuracy: 0.7638 - val_loss: 0.8298 - val_accuracy: 0.7844\n",
            "Epoch 68/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8003 - accuracy: 0.7876 - val_loss: 0.8204 - val_accuracy: 0.7822\n",
            "Epoch 69/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7974 - accuracy: 0.7781 - val_loss: 0.8180 - val_accuracy: 0.7444\n",
            "Epoch 70/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7925 - accuracy: 0.7390 - val_loss: 0.8140 - val_accuracy: 0.7711\n",
            "Epoch 71/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7886 - accuracy: 0.7914 - val_loss: 0.8143 - val_accuracy: 0.7889\n",
            "Epoch 72/80\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7858 - accuracy: 0.8143 - val_loss: 0.8096 - val_accuracy: 0.7089\n",
            "Epoch 73/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7829 - accuracy: 0.7438 - val_loss: 0.8078 - val_accuracy: 0.7356\n",
            "Epoch 74/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7787 - accuracy: 0.7781 - val_loss: 0.8027 - val_accuracy: 0.8044\n",
            "Epoch 75/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7774 - accuracy: 0.7819 - val_loss: 0.7995 - val_accuracy: 0.8089\n",
            "Epoch 76/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7737 - accuracy: 0.8067 - val_loss: 0.8003 - val_accuracy: 0.7733\n",
            "Epoch 77/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7695 - accuracy: 0.8029 - val_loss: 0.8004 - val_accuracy: 0.7644\n",
            "Epoch 78/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7679 - accuracy: 0.7838 - val_loss: 0.7914 - val_accuracy: 0.7956\n",
            "Epoch 79/80\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.7670 - accuracy: 0.8019 - val_loss: 0.7991 - val_accuracy: 0.7622\n",
            "Epoch 80/80\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.7616 - accuracy: 0.7590 - val_loss: 0.7893 - val_accuracy: 0.6956\n",
            "15/15 [==============================] - 0s 2ms/step\n",
            "8/8 [==============================] - 0s 3ms/step\n",
            "3\n",
            "Confusion matrix:\n",
            " [[ 72  63  19]\n",
            " [  0 119  26]\n",
            " [  5  24 122]]\n",
            "\n",
            "P-Score: 0.748, R-Score: 0.699, F-Score: 0.690\n",
            "[0.6955555555555556, 0.7477579200444149, 0.6987230475241436, 0.6895782996411928, 0.7253202878202878, 0.7677218767665348, 0.8287226738133735, 0.7739216128000654]\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.706667   0.710428  0.708272  0.707259  0.723850  0.806218  0.812465   \n",
            "1  0.735556   0.737979  0.734594  0.734230  0.792559  0.783493  0.827050   \n",
            "2  0.740000   0.741581  0.741535  0.739354  0.768800  0.826569  0.822299   \n",
            "3  0.693333   0.688888  0.691803  0.688651  0.768537  0.694234  0.845279   \n",
            "4  0.691111   0.739586  0.685285  0.672921  0.803155  0.666874  0.824204   \n",
            "5  0.675556   0.689860  0.678307  0.669707  0.688158  0.755229  0.832167   \n",
            "6  0.688889   0.702221  0.689236  0.689784  0.764654  0.713341  0.823839   \n",
            "7  0.700000   0.697245  0.696609  0.690846  0.804624  0.689259  0.825478   \n",
            "8  0.840000   0.847988  0.839314  0.841386  0.923372  0.862295  0.853574   \n",
            "9  0.695556   0.747758  0.698723  0.689578  0.725320  0.767722  0.828723   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.780845  \n",
            "1       0.801034  \n",
            "2       0.805890  \n",
            "3       0.769350  \n",
            "4       0.764744  \n",
            "5       0.758518  \n",
            "6       0.767278  \n",
            "7       0.773121  \n",
            "8       0.879747  \n",
            "9       0.773922  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00238795 0.00283325 0.0947788 ]\n",
            " [0.03357307 0.04113323 0.02529369]\n",
            " [0.04128735 0.05151635 0.00719631]\n",
            " ...\n",
            " [0.04107926 0.05086074 0.00805999]\n",
            " [0.02873113 0.03206037 0.0392085 ]\n",
            " [0.04410414 0.05136883 0.00452703]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed00cd6",
      "metadata": {
        "id": "eed00cd6"
      },
      "source": [
        "### Training the model using SVM"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import load\n",
        "train_x = load('train_x.npy')\n",
        "test_x = load('train_y.npy')\n",
        "train_y = load('test_x.npy')\n",
        "test_y = load('test_y.npy')"
      ],
      "metadata": {
        "id": "rPgTZrCZGVyj"
      },
      "id": "rPgTZrCZGVyj",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def roc(model, test_x, test_y, n_classes):\n",
        "  fpr = {}\n",
        "  tpr = {}\n",
        "  roc_auc = {}\n",
        "\n",
        "  y_pred = model.predict(test_x)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  prediction = pd.get_dummies(y_pred).values\n",
        "  print(n_classes)\n",
        "  for i in range(n_classes):\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "\n",
        "  return roc_auc"
      ],
      "metadata": {
        "id": "3QgPdOXIJPGx"
      },
      "id": "3QgPdOXIJPGx",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_avg_AUC_ROC(y_pred, test_y, n_classes, label_names, figsize=(6.4, 4.8), average=\"macro\"):\n",
        "  fpr = dict()\n",
        "  tpr = dict()\n",
        "  roc_auc = dict()\n",
        "\n",
        "  #y_pred = model.predict(test_x, batch_size=64, verbose=1)\n",
        "  y_test_dummies = pd.get_dummies(test_y, drop_first=False).values\n",
        "  \n",
        "  for i in range(n_classes):\n",
        "    #fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i], prediction[:, i])\n",
        "    fpr[i], tpr[i], _ = roc_curve(y_test_dummies[:, i].astype(int) ,y_pred[:, i])\n",
        "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "      # roc for each class\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  ax.plot([0, 1], [0, 1], 'k--')\n",
        "  ax.set_xlim([0.0, 1.0])\n",
        "  ax.set_ylim([0.0, 1.05])\n",
        "  ax.set_xlabel('False Positive Rate')\n",
        "  ax.set_ylabel('True Positive Rate')\n",
        "  ax.set_title('Receiver operating characteristic example')\n",
        "  for i in range(n_classes):\n",
        "      ax.plot(fpr[i], tpr[i], label='ROC curve (area = {}) for {}'.format('{0:.2f}'.format(roc_auc[i]), label_names[i]))\n",
        "  ax.legend(loc=\"best\")\n",
        "  ax.grid(alpha=.4)\n",
        "  sns.despine()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4qpdMzjkJRqs"
      },
      "id": "4qpdMzjkJRqs",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(train_x, train_y)\n",
        "\n",
        "# print best parameter after tuning\n",
        "print(grid.best_params_)\n",
        "  \n",
        "# print how our model looks after hyper-parameter tuning\n",
        "print(grid.best_estimator_)\n",
        "\n",
        "\n",
        "grid_predictions = grid.predict(test_x)\n",
        "  \n",
        "# print classification report\n",
        "print(classification_report(test_y, grid_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LdqpD-ZWGaxc",
        "outputId": "b166488e-9686-4f98-85ea-9fbcc35de7f0"
      },
      "id": "LdqpD-ZWGaxc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.557 total time=   0.2s\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.567 total time=   0.1s\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.571 total time=   0.1s\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.810 total time=   0.1s\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.800 total time=   0.1s\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.852 total time=   0.2s\n",
            "[CV 4/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.838 total time=   0.2s\n",
            "[CV 5/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.862 total time=   0.2s\n",
            "[CV 1/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 2/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 3/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 4/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.562 total time=   0.2s\n",
            "[CV 5/5] END ........C=1, gamma=0.1, kernel=rbf;, score=0.576 total time=   0.2s\n",
            "[CV 1/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 3/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END .......C=1, gamma=0.01, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 2/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 3/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 5/5] END ......C=1, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 2/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 3/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END .....C=1, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END .........C=10, gamma=1, kernel=rbf;, score=0.886 total time=   0.1s\n",
            "[CV 2/5] END .........C=10, gamma=1, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 3/5] END .........C=10, gamma=1, kernel=rbf;, score=0.929 total time=   0.1s\n",
            "[CV 4/5] END .........C=10, gamma=1, kernel=rbf;, score=0.914 total time=   0.1s\n",
            "[CV 5/5] END .........C=10, gamma=1, kernel=rbf;, score=0.938 total time=   0.1s\n",
            "[CV 1/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.814 total time=   0.1s\n",
            "[CV 2/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.800 total time=   0.1s\n",
            "[CV 3/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.857 total time=   0.1s\n",
            "[CV 4/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.848 total time=   0.2s\n",
            "[CV 5/5] END .......C=10, gamma=0.1, kernel=rbf;, score=0.862 total time=   0.2s\n",
            "[CV 1/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.562 total time=   0.3s\n",
            "[CV 2/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.557 total time=   0.3s\n",
            "[CV 3/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.567 total time=   0.2s\n",
            "[CV 4/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.562 total time=   0.2s\n",
            "[CV 5/5] END ......C=10, gamma=0.01, kernel=rbf;, score=0.581 total time=   0.2s\n",
            "[CV 1/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 3/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 4/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END .....C=10, gamma=0.001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 2/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 3/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 5/5] END ....C=10, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 1/5] END ........C=100, gamma=1, kernel=rbf;, score=0.938 total time=   0.1s\n",
            "[CV 2/5] END ........C=100, gamma=1, kernel=rbf;, score=0.929 total time=   0.0s\n",
            "[CV 3/5] END ........C=100, gamma=1, kernel=rbf;, score=0.948 total time=   0.1s\n",
            "[CV 4/5] END ........C=100, gamma=1, kernel=rbf;, score=0.943 total time=   0.0s\n",
            "[CV 5/5] END ........C=100, gamma=1, kernel=rbf;, score=0.952 total time=   0.0s\n",
            "[CV 1/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.886 total time=   0.1s\n",
            "[CV 2/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 3/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.929 total time=   0.1s\n",
            "[CV 4/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.910 total time=   0.1s\n",
            "[CV 5/5] END ......C=100, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.1s\n",
            "[CV 1/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.814 total time=   0.2s\n",
            "[CV 2/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.800 total time=   0.1s\n",
            "[CV 3/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.857 total time=   0.1s\n",
            "[CV 4/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.848 total time=   0.1s\n",
            "[CV 5/5] END .....C=100, gamma=0.01, kernel=rbf;, score=0.862 total time=   0.1s\n",
            "[CV 1/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.562 total time=   0.2s\n",
            "[CV 2/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.557 total time=   0.3s\n",
            "[CV 3/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.567 total time=   0.3s\n",
            "[CV 4/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.562 total time=   0.3s\n",
            "[CV 5/5] END ....C=100, gamma=0.001, kernel=rbf;, score=0.581 total time=   0.1s\n",
            "[CV 1/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.1s\n",
            "[CV 2/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.3s\n",
            "[CV 3/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 4/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 5/5] END ...C=100, gamma=0.0001, kernel=rbf;, score=0.338 total time=   0.2s\n",
            "[CV 1/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.943 total time=   0.0s\n",
            "[CV 2/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.943 total time=   0.0s\n",
            "[CV 3/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.948 total time=   0.0s\n",
            "[CV 4/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.957 total time=   0.0s\n",
            "[CV 5/5] END .......C=1000, gamma=1, kernel=rbf;, score=0.957 total time=   0.0s\n",
            "[CV 1/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.0s\n",
            "[CV 2/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.933 total time=   0.1s\n",
            "[CV 3/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.948 total time=   0.1s\n",
            "[CV 4/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.938 total time=   0.1s\n",
            "[CV 5/5] END .....C=1000, gamma=0.1, kernel=rbf;, score=0.957 total time=   0.0s\n",
            "[CV 1/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.886 total time=   0.0s\n",
            "[CV 2/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.900 total time=   0.1s\n",
            "[CV 3/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.929 total time=   0.1s\n",
            "[CV 4/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.910 total time=   0.1s\n",
            "[CV 5/5] END ....C=1000, gamma=0.01, kernel=rbf;, score=0.938 total time=   0.0s\n",
            "[CV 1/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.814 total time=   0.2s\n",
            "[CV 2/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.800 total time=   0.2s\n",
            "[CV 3/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.857 total time=   0.1s\n",
            "[CV 4/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.848 total time=   0.2s\n",
            "[CV 5/5] END ...C=1000, gamma=0.001, kernel=rbf;, score=0.862 total time=   0.2s\n",
            "[CV 1/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.562 total time=   0.2s\n",
            "[CV 2/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.557 total time=   0.1s\n",
            "[CV 3/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.567 total time=   0.1s\n",
            "[CV 4/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.562 total time=   0.1s\n",
            "[CV 5/5] END ..C=1000, gamma=0.0001, kernel=rbf;, score=0.581 total time=   0.2s\n",
            "{'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
            "SVC(C=1000, gamma=1)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.97      0.96      0.97       154\n",
            "         2.0       0.93      0.97      0.95       145\n",
            "         3.0       0.93      0.91      0.92       151\n",
            "\n",
            "    accuracy                           0.95       450\n",
            "   macro avg       0.95      0.95      0.95       450\n",
            "weighted avg       0.95      0.95      0.95       450\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_classes = 3\n",
        "NAME = \"Landsat8_DATA\"\n",
        "Model_name = \"SVM\"\n",
        "columns = ['Accuracy', 'precision', 'recall', 'F1_score', \"AUC_0\", \"AUC_1\", \"AUC_2\", \"Aggregate_AUC\"]\n",
        "df = pd.DataFrame(columns = columns)\n",
        "from sklearn.metrics import roc_curve, roc_auc_score\n",
        "model = SVC(C=100, kernel='rbf', gamma=1, probability=True)\n",
        "model.fit(train_x, train_y)\n",
        "\n",
        "yTestPredicted = model.predict(test_x)\n",
        "n_classes = 3\n",
        "Accuracy = accuracy_score(test_y, yTestPredicted)\n",
        "cMatrix = confusion_matrix(test_y, yTestPredicted)\n",
        "pScore = precision_score(test_y, yTestPredicted, average='macro')\n",
        "rScore = recall_score(test_y, yTestPredicted, average='macro')\n",
        "fscore = f1_score(test_y, yTestPredicted, average='macro')\n",
        "\n",
        "print(\"Confusion matrix:\\n\", cMatrix)\n",
        "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n",
        "\n",
        "#This function calculates all the evaluation metrics for every iteration\n",
        "roc_auc = roc(model, test_x, test_y, n_classes)\n",
        "\n",
        "sum_of_roc_scores = 0\n",
        "for i in range(n_classes):\n",
        "  sum_of_roc_scores = sum_of_roc_scores + roc_auc[i]\n",
        "\n",
        "aggregate_roc_score = sum_of_roc_scores/n_classes\n",
        "\n",
        "\n",
        "print(\"Confusion matrix:\\n\", cMatrix)\n",
        "print(\"\\nP-Score: %.3f, R-Score: %.3f, F-Score: %.3f\" % (pScore, rScore, fscore))\n",
        "\n",
        "result_dict = {'Accuracy': Accuracy, 'precision': pScore, 'recall' : rScore, 'F1_score': fscore, \"AUC_0\": roc_auc[0]\n",
        "                   , \"AUC_1\": roc_auc[1], \"AUC_2\": roc_auc[2], \"Aggregate_AUC\": aggregate_roc_score}\n",
        "df = df.append(result_dict, ignore_index = True)\n",
        "print(df)\n",
        "df.to_csv('Results_{}_{}.csv'.format(NAME, Model_name))\n",
        "\n",
        "label_names = [\"No Alteration\", \"Argillic\" , \"Iron Oxide\"]\n",
        "y_pred = model.predict_proba(test_x)\n",
        "plot_avg_AUC_ROC(y_pred, test_y, 3, label_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "lf-TrkxTKHdk",
        "outputId": "501fab7e-bada-498f-becc-9ea010f2e873"
      },
      "id": "lf-TrkxTKHdk",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matrix:\n",
            " [[148   1   5]\n",
            " [  0 143   2]\n",
            " [  3  12 136]]\n",
            "\n",
            "P-Score: 0.949, R-Score: 0.949, F-Score: 0.949\n",
            "3\n",
            "Confusion matrix:\n",
            " [[148   1   5]\n",
            " [  0 143   2]\n",
            " [  3  12 136]]\n",
            "\n",
            "P-Score: 0.949, R-Score: 0.949, F-Score: 0.949\n",
            "   Accuracy  precision    recall  F1_score     AUC_0     AUC_1     AUC_2  \\\n",
            "0  0.948889   0.949283  0.949303  0.948609  0.975452  0.971792  0.938625   \n",
            "\n",
            "   Aggregate_AUC  \n",
            "0       0.961956  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 460.8x345.6 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cnn_cx_pip",
      "language": "python",
      "name": "cnn_cx_pip"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}